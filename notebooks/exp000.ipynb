{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08317bb-fa4d-45c8-9729-46910b084d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce6b088f-2dd0-471b-8d65-5474a0047688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InputPath:\n",
    "    _prefix: str = \"../input\"\n",
    "    train: str = f\"{_prefix}/train.csv\"\n",
    "    materials: str = f\"{_prefix}/materials.csv\"\n",
    "    techniques: str = f\"{_prefix}/techniques.csv\"\n",
    "    test: str = f\"{_prefix}/test.csv\"\n",
    "    sub: str = f\"{_prefix}/atmaCup#11_sample_submission.csv\"\n",
    "    photos_prefix: str = f\"{_prefix}/photos\"\n",
    "    photos: List[str] = field(default_factory=lambda: glob(f\"../input/photos/*.jpg\"))\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class OutputPath:\n",
    "    _prefix: str = \"../output/\"\n",
    "    model: str = f\"{_prefix}/model\"\n",
    "    submission: str = f\"{_prefix}/submission\"\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Basic:\n",
    "    run_name: str = \"exp000\"\n",
    "    is_debug: bool = True\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Kfold:\n",
    "    number: int = 5\n",
    "    method: str = \"skf\"\n",
    "    shuffle: bool = True\n",
    "    columns: List[str] = field(default_factory=lambda: [\"target\"])\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Adam:\n",
    "    name: str = \"Adam\"\n",
    "    lr: float = 1e-4\n",
    "    weight_decay: float = 0\n",
    "    amsgrad: bool = False\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class ReduceLROnPlateau:\n",
    "    name: str = \"ReduceLROnPlateau\"\n",
    "    mode: str = \"min\"\n",
    "    factor: float = 0.1\n",
    "    patience: int = 5\n",
    "    verbose: bool = True\n",
    "    eps: float = 1e-8\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Params:\n",
    "    batch_size: int = 64\n",
    "    epochs: int = 3 if Basic.is_debug else 10\n",
    "    image_size: int = 224\n",
    "    max_grad_norm: int = 1000\n",
    "    num_workers: int = 0\n",
    "    print_freq: int = 10000\n",
    "    target_size: int = 1\n",
    "    # Union[Adam]\n",
    "    optimizer: Adam = Adam()\n",
    "    # Union[CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau]\n",
    "    scheduler: ReduceLROnPlateau = ReduceLROnPlateau()\n",
    "    pretrained: bool = False\n",
    "        \n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    basic: Basic = Basic()\n",
    "    kfold: Kfold = Kfold()\n",
    "    params: Params = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b0b95d9-6d21-48a4-8ef9-d085e183e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class Jbl:\n",
    "    @staticmethod\n",
    "    def load(filepath: str) -> Any:\n",
    "        return joblib.load(filepath)\n",
    "\n",
    "    @staticmethod\n",
    "    def save(obj_: Any, filepath: str) -> None:\n",
    "        joblib.dump(obj_, filepath, compress=3)\n",
    "\n",
    "\n",
    "def RMSE(y: np.array, p: np.array) -> float:\n",
    "    return metrics.mean_squared_error(y, p) ** 0.5\n",
    "\n",
    "\n",
    "def fix_seed(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    \n",
    "def time_since(since: time.time, percent: float) -> str:\n",
    "    def as_minutes(s):\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return \"%dm %ds\" % (m, s)\n",
    "\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adac7d51-f744-4349-a639-7a6661370d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def to_img_path(photo_dir: str, object_id: str) -> str:\n",
    "    return os.path.join(photo_dir, f'{object_id}.jpg')\n",
    "\n",
    "def read_image(object_id: str):\n",
    "    return Image.open(to_img_path(object_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52cc936d-6003-4e02-ba1f-d42cf039cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_csv(path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "169f341c-c861-4c5d-918c-201017c494da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    GroupKFold,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    TimeSeriesSplit,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_kf(cfg: ModelConfig) -> Generator:\n",
    "    if cfg.kfold.method == \"kf\":\n",
    "        kf = KFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"skf\":\n",
    "        kf = StratifiedKFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"gkf\":\n",
    "        kf = GroupKFold(n_splits=cfg.kfold.number)\n",
    "    elif cfg.kfold.method == \"sgkf\":\n",
    "        kf = StratifiedGroupKFold(\n",
    "            n_splits=cfg.kfold.number, random_state=cfg.basic.seed\n",
    "        )\n",
    "    elif cfg.kfold.method == \"tskf\":\n",
    "        kf = TimeSeriesSplit(n_splits=cfg.kfold.number)\n",
    "    else:\n",
    "        raise ValueError(f\"{cfg.kfold.method} is not supported\")\n",
    "    return kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e1e049a-17be-4901-a59d-8d475c180753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "\n",
    "\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "class AtmaDataset(data.Dataset):\n",
    "    \"\"\"atmaCup用にデータ読み込み等を行なうデータ・セット\"\"\"\n",
    "    object_path_key = \"object_path\"\n",
    "    label_key = \"target\"\n",
    "\n",
    "    def __init__(self, meta_df: pd.DataFrame, is_train: bool = True) -> None:\n",
    "        self.is_train = is_train\n",
    "        self.meta_df = meta_df.reset_index(drop=True)\n",
    "        self.index_to_data = self.meta_df.to_dict(orient=\"index\")\n",
    "        \n",
    "        size = (ModelConfig.params.image_size, ModelConfig.params.image_size)\n",
    "        additional_items = (\n",
    "            [T.Resize(size)]\n",
    "            if not is_train\n",
    "            else [\n",
    "                T.RandomGrayscale(p=0.2),\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.ColorJitter(\n",
    "                    brightness=0.3,\n",
    "                    contrast=0.5,\n",
    "                    saturation=[0.8, 1.3],\n",
    "                    hue=[-0.05, 0.05],\n",
    "                ),\n",
    "                T.RandomResizedCrop(size),\n",
    "            ]\n",
    "        )\n",
    "        self.transformer = T.Compose(\n",
    "            [*additional_items, T.ToTensor(), T.Normalize(mean=IMG_MEAN, std=IMG_STD)]\n",
    "        )\n",
    "        \n",
    "        self._validate_meta_df(meta_df)\n",
    "\n",
    "    def __getitem__(self, index) -> Dict[str, Any]:\n",
    "        data = self.index_to_data[index]\n",
    "        obj_path, label = data.get(self.object_path_key), data.get(self.label_key, -1)\n",
    "        img = self.transformer(Image.open(obj_path))\n",
    "        return {\"image\": img, \"label\": label}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.meta_df)\n",
    "    \n",
    "    def _validate_meta_df(self, meta_df: pd.DataFrame) -> None:\n",
    "        for k in self.meta_keys:\n",
    "            if k not in meta_df:\n",
    "                raise ValueError(f\"meta df must have {k}\")\n",
    "                \n",
    "    @property\n",
    "    def meta_keys(self) -> List[str]:\n",
    "        retval = [self.object_path_key]\n",
    "        if self.is_train:\n",
    "            retval += [self.label_key]\n",
    "        return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb29cd98-7770-4f3e-813f-461679503034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import OrderedDict\n",
    "from logging import Logger\n",
    "from typing import Dict, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def build_model(pretrained: bool = False):\n",
    "    model = models.resnet34(pretrained=pretrained)\n",
    "    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)    \n",
    "    return model\n",
    "\n",
    "\n",
    "class BaseRunner:\n",
    "    def __init__(self, cfg: ModelConfig):\n",
    "        self.cfg = cfg\n",
    "        self.params = cfg.params\n",
    "\n",
    "    def _get_scheduler(\n",
    "        self, optimizer: Union[optim.Adam]\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if self.params.scheduler.name == \"ReduceLROnPlateau\":\n",
    "            scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode=self.params.scheduler.mode,\n",
    "                factor=self.params.scheduler.factor,\n",
    "                patience=self.params.scheduler.patience,\n",
    "                verbose=self.params.scheduler.verbose,\n",
    "                eps=self.params.scheduler.eps,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.scheduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _step_scheduler(\n",
    "        self,\n",
    "        scheduler: Union[\n",
    "            lr_scheduler.ReduceLROnPlateau,\n",
    "        ],\n",
    "        avg_val_loss,\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.shceduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _evaluate(self, y_true: np.array, y_pred: np.array):\n",
    "        score = RMSE(y_true, y_pred)\n",
    "        print(f\"Score: {score:<.5f}\")\n",
    "\n",
    "\n",
    "class TrainRunner(BaseRunner):\n",
    "    def _train_batch(self, train_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        # scores = AverageMeter()\n",
    "        model.train()\n",
    "        start = end = time.time()\n",
    "        for step, image_label_dict in enumerate(train_loader):\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels.float())\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            grad_norm = nn.utils.clip_grad_norm_(\n",
    "                model.parameters(), self.params.max_grad_norm\n",
    "            )\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "#             if step % self.params.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "#                 print(\n",
    "#                     f\"\"\"\n",
    "#                     Epoch: [{epoch + 1}][{step}/{len(train_loader)}]\n",
    "#                     Batch {batch_time.val:.3f} ({batch_time.avg:.3f})\n",
    "#                     Data {data_time.val:.3f} ({data_time.avg:.3f})\n",
    "#                     Elapsed {time_since(start, float(step + 1) / len(train_loader)):s}\n",
    "#                     Loss: {losses.val:.4f}({losses.avg:.4f})\n",
    "#                     Grad: {grad_norm:.4f}\n",
    "#                     \"\"\"\n",
    "#                 )\n",
    "        return losses.avg\n",
    "\n",
    "    def _valid_batch(self, valid_loader, model, criterion):\n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        # scores = AverageMeter()\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        start = end = time.time()\n",
    "        for step, image_label_dict in enumerate(valid_loader):\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels.float())\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "#             if step % self.params.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "#                 print(\n",
    "#                     f\"\"\"\n",
    "#                     EVAL: [{step}/{len(valid_loader)}]\n",
    "#                     Batch {batch_time.val:.3f} ({batch_time.avg:.3f})\n",
    "#                     Data {data_time.val:.3f} ({data_time.avg:.3f})\n",
    "#                     Elapsed {time_since(start, float(step + 1) / len(valid_loader)):s}\n",
    "#                     Loss: {losses.val:.4f}({losses.avg:.4f})\n",
    "#                     \"\"\"\n",
    "#                 )\n",
    "        predictions = np.concatenate(preds)\n",
    "        return losses.avg, predictions\n",
    "\n",
    "    def _train(self, train: pd.DataFrame, n_fold: int):\n",
    "        print(f\"fold: {n_fold}\")\n",
    "\n",
    "        trn_idx = train[train[\"fold\"] != n_fold].index\n",
    "        val_idx = train[train[\"fold\"] == n_fold].index\n",
    "        train_folds = train.loc[trn_idx].reset_index(drop=True)\n",
    "        valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "        train_dataset = AtmaDataset(\n",
    "            train_folds,\n",
    "            is_train=True,\n",
    "#             transform=get_transforms(self.params, data=\"train\"),\n",
    "        )\n",
    "        valid_dataset = AtmaDataset(\n",
    "            valid_folds,\n",
    "            is_train=False,\n",
    "#             transform=get_transforms(self.params, data=\"valid\"),\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        model = build_model(pretrained=self.cfg.params.pretrained)\n",
    "        model.to(self.cfg.basic.device)\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=self.params.optimizer.lr,\n",
    "            weight_decay=self.params.optimizer.weight_decay,\n",
    "            amsgrad=self.params.optimizer.amsgrad,\n",
    "        )\n",
    "        scheduler = self._get_scheduler(optimizer)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        best_score = np.inf\n",
    "        # best_loss = np.inf\n",
    "        for epoch in range(self.params.epochs):\n",
    "            start_time = time.time()\n",
    "\n",
    "            avg_loss = self._train_batch(\n",
    "                train_loader, model, criterion, optimizer, scheduler, epoch\n",
    "            )\n",
    "            avg_val_loss, preds = self._valid_batch(valid_loader, model, criterion)\n",
    "            valid_labels = valid_folds[\"target\"].values\n",
    "            scheduler = self._step_scheduler(scheduler, avg_val_loss)\n",
    "            score = RMSE(valid_labels, preds)\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "            )\n",
    "            print(f\"Epoch {epoch+1} - RMSE: {score}\")\n",
    "            if best_score > score:\n",
    "                best_score = score\n",
    "                torch.save(\n",
    "                    {\"model\": model.state_dict(), \"preds\": preds},\n",
    "                    f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\",\n",
    "                )\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - Best Score: {best_score:.4f}\"\n",
    "            )\n",
    "\n",
    "        check_point: Dict[str, Union[OrderedDict, torch.Tensor]] = torch.load(\n",
    "            f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\"\n",
    "        )\n",
    "        valid_folds[\"preds\"] = check_point[\"preds\"]\n",
    "        return valid_folds\n",
    "\n",
    "    def run_cv(self, train: pd.DataFrame) -> None:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for n_fold in range(self.cfg.kfold.number):\n",
    "            _oof_df = self._train(train, n_fold)\n",
    "            print(f\"========== fold: {n_fold} result ==========\")\n",
    "            self._evaluate(_oof_df[\"target\"], _oof_df[\"preds\"])\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "        print(\"========== CV ==========\")\n",
    "        self._evaluate(oof_df[\"target\"], oof_df[\"preds\"])\n",
    "        Jbl.save(oof_df, f\"{OutputPath.model}/oof_df_{self.cfg.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eae1cb89-4ee0-4293-b935-888a14f628da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed()\n",
    "input_path = InputPath()\n",
    "model_config = ModelConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c99fafc2-2ace-488f-b2a3-1f6f3297af69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3937, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>sorting_date</th>\n",
       "      <th>art_series_id</th>\n",
       "      <th>target</th>\n",
       "      <th>object_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002bff09b09998d0be65</td>\n",
       "      <td>1631</td>\n",
       "      <td>509357f67692a6a45626</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/photos/002bff09b09998d0be65.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00309fb1ef05416f9c1f</td>\n",
       "      <td>1900</td>\n",
       "      <td>7987b47bbe5dc3039179</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/00309fb1ef05416f9c1f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003a1562e97f79ba96dc</td>\n",
       "      <td>1834</td>\n",
       "      <td>ded7c3c9636708e5b14c</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/003a1562e97f79ba96dc.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              object_id  sorting_date         art_series_id  target  \\\n",
       "0  002bff09b09998d0be65          1631  509357f67692a6a45626       1   \n",
       "1  00309fb1ef05416f9c1f          1900  7987b47bbe5dc3039179       3   \n",
       "2  003a1562e97f79ba96dc          1834  ded7c3c9636708e5b14c       3   \n",
       "\n",
       "                                object_path  \n",
       "0  ../input/photos/002bff09b09998d0be65.jpg  \n",
       "1  ../input/photos/00309fb1ef05416f9c1f.jpg  \n",
       "2  ../input/photos/003a1562e97f79ba96dc.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = load_csv(input_path.train)\n",
    "train = train.assign(object_path = train[\"object_id\"].apply(lambda x: to_img_path(input_path.photos_prefix, x)))\n",
    "print(train.shape)\n",
    "display(train.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8796a89d-9fce-49b6-8d53-3c315b65722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 - [0 1 2 3 4]~[3928 3930 3933 3934 3935]\t[ 8 14 16 19 21]~[3922 3929 3931 3932 3936]\n",
      "fold: 1 - [0 1 2 4 5]~[3931 3932 3933 3934 3936]\t[ 3  9 20 23 24]~[3899 3907 3912 3925 3935]\n",
      "fold: 2 - [0 1 2 3 5]~[3931 3932 3934 3935 3936]\t[ 4  6 10 11 12]~[3913 3915 3924 3927 3933]\n",
      "fold: 3 - [2 3 4 5 6]~[3932 3933 3934 3935 3936]\t[ 0  1  7 17 29]~[3914 3916 3919 3923 3926]\n",
      "fold: 4 - [0 1 3 4 6]~[3931 3932 3933 3935 3936]\t[ 2  5 22 31 32]~[3909 3918 3928 3930 3934]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "fold target     \n",
       "0    0        95\n",
       "     1       180\n",
       "     2       302\n",
       "     3       211\n",
       "1    0        95\n",
       "     1       179\n",
       "     2       303\n",
       "     3       211\n",
       "2    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211\n",
       "3    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211\n",
       "4    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kf = generate_kf(model_config)\n",
    "if model_config.kfold.method.endswith(\"gkf\"):\n",
    "    kf_generator = kf.split(\n",
    "        train,\n",
    "        train[self.fe_cfg.column.target],\n",
    "        groups=train[self.kfold.columns],\n",
    "    )\n",
    "else:\n",
    "    kf_generator = kf.split(train, train[\"target\"])\n",
    "for fold_i, (tr_idx, val_idx) in enumerate(kf_generator):\n",
    "    print(\n",
    "        f\"fold: {fold_i} - {tr_idx[:5]}~{tr_idx[-5:]}\\t{val_idx[:5]}~{val_idx[-5:]}\"\n",
    "    )\n",
    "    train.loc[val_idx, \"fold\"] = fold_i\n",
    "train = train.assign(fold = train[\"fold\"].astype(int))\n",
    "if model_config.kfold.method == \"skf\":\n",
    "    display(train.groupby([\"fold\", \"target\"]).size().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0af2c78d-558e-491c-b0f4-1884e1f42273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 1.2716  avg_val_loss: 0.9585  time: 24s\n",
      "Epoch 1 - RMSE: 0.9747419179642924\n",
      "Epoch 1 - Best Score: 0.9747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.9526  avg_val_loss: 0.9510  time: 23s\n",
      "Epoch 2 - RMSE: 0.9776297267342681\n",
      "Epoch 2 - Best Score: 0.9747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.9514  avg_val_loss: 0.9745  time: 23s\n",
      "Epoch 3 - RMSE: 0.9808093477136933\n",
      "Epoch 3 - Best Score: 0.9747\n",
      "========== fold: 0 result ==========\n",
      "Score: 0.97474\n",
      "fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 1.1615  avg_val_loss: 0.9555  time: 23s\n",
      "Epoch 1 - RMSE: 0.9644431926582354\n",
      "Epoch 1 - Best Score: 0.9644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.9558  avg_val_loss: 0.9542  time: 23s\n",
      "Epoch 2 - RMSE: 0.9703475994901694\n",
      "Epoch 2 - Best Score: 0.9644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.9526  avg_val_loss: 0.9482  time: 23s\n",
      "Epoch 3 - RMSE: 0.9717667394562695\n",
      "Epoch 3 - Best Score: 0.9644\n",
      "========== fold: 1 result ==========\n",
      "Score: 0.96444\n",
      "fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([19])) that is different to the input size (torch.Size([19, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 1.5570  avg_val_loss: 0.9531  time: 23s\n",
      "Epoch 1 - RMSE: 0.9782134517788872\n",
      "Epoch 1 - Best Score: 0.9782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([19])) that is different to the input size (torch.Size([19, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.9497  avg_val_loss: 0.9462  time: 23s\n",
      "Epoch 2 - RMSE: 0.9719954416317941\n",
      "Epoch 2 - Best Score: 0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([19])) that is different to the input size (torch.Size([19, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.9480  avg_val_loss: 0.9492  time: 23s\n",
      "Epoch 3 - RMSE: 0.9752254776102023\n",
      "Epoch 3 - Best Score: 0.9720\n",
      "========== fold: 2 result ==========\n",
      "Score: 0.97200\n",
      "fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([19])) that is different to the input size (torch.Size([19, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 1.5016  avg_val_loss: 0.9487  time: 23s\n",
      "Epoch 1 - RMSE: 0.9710557848641878\n",
      "Epoch 1 - Best Score: 0.9711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([19])) that is different to the input size (torch.Size([19, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.9546  avg_val_loss: 0.9469  time: 23s\n",
      "Epoch 2 - RMSE: 0.9692004516870969\n",
      "Epoch 2 - Best Score: 0.9692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([19])) that is different to the input size (torch.Size([19, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.9524  avg_val_loss: 0.9446  time: 23s\n",
      "Epoch 3 - RMSE: 0.9714790924959308\n",
      "Epoch 3 - Best Score: 0.9692\n",
      "========== fold: 3 result ==========\n",
      "Score: 0.96920\n",
      "fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([19])) that is different to the input size (torch.Size([19, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 1.5324  avg_val_loss: 0.9569  time: 23s\n",
      "Epoch 1 - RMSE: 0.9952462345863845\n",
      "Epoch 1 - Best Score: 0.9952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([19])) that is different to the input size (torch.Size([19, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.9534  avg_val_loss: 0.9416  time: 23s\n",
      "Epoch 2 - RMSE: 0.9771962467314357\n",
      "Epoch 2 - Best Score: 0.9772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.9488  avg_val_loss: 0.9421  time: 23s\n",
      "Epoch 3 - RMSE: 0.9764296241579331\n",
      "Epoch 3 - Best Score: 0.9764\n",
      "========== fold: 4 result ==========\n",
      "Score: 0.97643\n",
      "========== CV ==========\n",
      "Score: 0.97137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([19])) that is different to the input size (torch.Size([19, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "TrainRunner(model_config).run_cv(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ba9ba8b-317b-42a0-9a0b-c6bd8e07f462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>sorting_date</th>\n",
       "      <th>art_series_id</th>\n",
       "      <th>target</th>\n",
       "      <th>object_path</th>\n",
       "      <th>fold</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00bf812ffe8a62d45661</td>\n",
       "      <td>1720</td>\n",
       "      <td>3bfd41016d864e3fd8b5</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/00bf812ffe8a62d45661.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.871393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0110115b8b6036d9ab3c</td>\n",
       "      <td>1741</td>\n",
       "      <td>baa4a20f0372d74dfc80</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/0110115b8b6036d9ab3c.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.856319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01273c00c46a84c50468</td>\n",
       "      <td>1757</td>\n",
       "      <td>51024cb4c6256ccce827</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/01273c00c46a84c50468.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.623938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0160840d9a4620b08fbd</td>\n",
       "      <td>1874</td>\n",
       "      <td>a56504999a8157a25d16</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/0160840d9a4620b08fbd.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.734618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0169c493b09c8758a1b3</td>\n",
       "      <td>1734</td>\n",
       "      <td>550c62dd363fea62581c</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/0169c493b09c8758a1b3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.949838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>fe4d591332b08ab81361</td>\n",
       "      <td>1600</td>\n",
       "      <td>0782dfafa355acaf888c</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/photos/fe4d591332b08ab81361.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.799234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>fecae40c488e4c8c5ba5</td>\n",
       "      <td>1600</td>\n",
       "      <td>9ac00be75c55b1653a94</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/photos/fecae40c488e4c8c5ba5.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.749959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>ff37540e22e1ef455368</td>\n",
       "      <td>1765</td>\n",
       "      <td>9971eebf0f583a5e51da</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/ff37540e22e1ef455368.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.738409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>ff9124278e0f7086738f</td>\n",
       "      <td>1630</td>\n",
       "      <td>b4d508f53d16f7bcaf55</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/photos/ff9124278e0f7086738f.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.761165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>ffd794b7b311b7b7fd92</td>\n",
       "      <td>1789</td>\n",
       "      <td>f030a01b480b18a27be2</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/ffd794b7b311b7b7fd92.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.769561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3937 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                object_id  sorting_date         art_series_id  target  \\\n",
       "0    00bf812ffe8a62d45661          1720  3bfd41016d864e3fd8b5       2   \n",
       "1    0110115b8b6036d9ab3c          1741  baa4a20f0372d74dfc80       2   \n",
       "2    01273c00c46a84c50468          1757  51024cb4c6256ccce827       2   \n",
       "3    0160840d9a4620b08fbd          1874  a56504999a8157a25d16       3   \n",
       "4    0169c493b09c8758a1b3          1734  550c62dd363fea62581c       2   \n",
       "..                    ...           ...                   ...     ...   \n",
       "782  fe4d591332b08ab81361          1600  0782dfafa355acaf888c       0   \n",
       "783  fecae40c488e4c8c5ba5          1600  9ac00be75c55b1653a94       0   \n",
       "784  ff37540e22e1ef455368          1765  9971eebf0f583a5e51da       2   \n",
       "785  ff9124278e0f7086738f          1630  b4d508f53d16f7bcaf55       1   \n",
       "786  ffd794b7b311b7b7fd92          1789  f030a01b480b18a27be2       2   \n",
       "\n",
       "                                  object_path  fold     preds  \n",
       "0    ../input/photos/00bf812ffe8a62d45661.jpg     0  1.871393  \n",
       "1    ../input/photos/0110115b8b6036d9ab3c.jpg     0  1.856319  \n",
       "2    ../input/photos/01273c00c46a84c50468.jpg     0  1.623938  \n",
       "3    ../input/photos/0160840d9a4620b08fbd.jpg     0  1.734618  \n",
       "4    ../input/photos/0169c493b09c8758a1b3.jpg     0  1.949838  \n",
       "..                                        ...   ...       ...  \n",
       "782  ../input/photos/fe4d591332b08ab81361.jpg     4  1.799234  \n",
       "783  ../input/photos/fecae40c488e4c8c5ba5.jpg     4  1.749959  \n",
       "784  ../input/photos/ff37540e22e1ef455368.jpg     4  1.738409  \n",
       "785  ../input/photos/ff9124278e0f7086738f.jpg     4  1.761165  \n",
       "786  ../input/photos/ffd794b7b311b7b7fd92.jpg     4  1.769561  \n",
       "\n",
       "[3937 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e174df-3c50-4bae-a0be-dc59445ea40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2e35b9-f7b8-4ea9-96e4-6053d8dc537f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

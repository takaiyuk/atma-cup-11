{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08317bb-fa4d-45c8-9729-46910b084d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce6b088f-2dd0-471b-8d65-5474a0047688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InputPath:\n",
    "    _prefix: str = \"../input\"\n",
    "    train: str = f\"{_prefix}/train.csv\"\n",
    "    materials: str = f\"{_prefix}/materials.csv\"\n",
    "    techniques: str = f\"{_prefix}/techniques.csv\"\n",
    "    test: str = f\"{_prefix}/test.csv\"\n",
    "    sub: str = f\"{_prefix}/atmaCup#11_sample_submission.csv\"\n",
    "    photos_prefix: str = f\"{_prefix}/photos\"\n",
    "    photos: List[str] = field(default_factory=lambda: glob(f\"../input/photos/*.jpg\"))\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class OutputPath:\n",
    "    _prefix: str = \"../output/\"\n",
    "    model: str = f\"{_prefix}/model\"\n",
    "    submission: str = f\"{_prefix}/submission\"\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Basic:\n",
    "    run_name: str = \"exp002\"\n",
    "    is_debug: bool = False\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Kfold:\n",
    "    number: int = 5\n",
    "    method: str = \"skf\"\n",
    "    shuffle: bool = True\n",
    "    columns: List[str] = field(default_factory=lambda: [\"target\"])\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Adam:\n",
    "    name: str = \"Adam\"\n",
    "    lr: float = 1e-4\n",
    "    weight_decay: float = 0\n",
    "    amsgrad: bool = False\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class ReduceLROnPlateau:\n",
    "    name: str = \"ReduceLROnPlateau\"\n",
    "    mode: str = \"min\"\n",
    "    factor: float = 0.1\n",
    "    patience: int = 5\n",
    "    verbose: bool = True\n",
    "    eps: float = 1e-8\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Params:\n",
    "    batch_size: int = 64\n",
    "    test_batch_size: int = 256\n",
    "    epochs: int = 3 if Basic.is_debug else 10\n",
    "    image_size: int = 224\n",
    "    max_grad_norm: int = 1000\n",
    "    num_workers: int = 0\n",
    "    print_freq: int = 10000\n",
    "    target_size: int = 1\n",
    "    # Union[Adam]\n",
    "    optimizer: Adam = Adam()\n",
    "    # Union[CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau]\n",
    "    scheduler: ReduceLROnPlateau = ReduceLROnPlateau()\n",
    "    pretrained: bool = False\n",
    "        \n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    basic: Basic = Basic()\n",
    "    kfold: Kfold = Kfold()\n",
    "    params: Params = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b0b95d9-6d21-48a4-8ef9-d085e183e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class Jbl:\n",
    "    @staticmethod\n",
    "    def load(filepath: str) -> Any:\n",
    "        return joblib.load(filepath)\n",
    "\n",
    "    @staticmethod\n",
    "    def save(obj_: Any, filepath: str) -> None:\n",
    "        joblib.dump(obj_, filepath, compress=3)\n",
    "\n",
    "\n",
    "def RMSE(y: np.array, p: np.array) -> float:\n",
    "    return metrics.mean_squared_error(y, p) ** 0.5\n",
    "\n",
    "\n",
    "def fix_seed(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    \n",
    "def time_since(since: time.time, percent: float) -> str:\n",
    "    def as_minutes(s):\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return \"%dm %ds\" % (m, s)\n",
    "\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adac7d51-f744-4349-a639-7a6661370d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def to_img_path(photo_dir: str, object_id: str) -> str:\n",
    "    return os.path.join(photo_dir, f'{object_id}.jpg')\n",
    "\n",
    "def read_image(object_id: str):\n",
    "    return Image.open(to_img_path(object_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52cc936d-6003-4e02-ba1f-d42cf039cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_csv(path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "169f341c-c861-4c5d-918c-201017c494da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    GroupKFold,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    TimeSeriesSplit,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_kf(cfg: ModelConfig) -> Generator:\n",
    "    if cfg.kfold.method == \"kf\":\n",
    "        kf = KFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"skf\":\n",
    "        kf = StratifiedKFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"gkf\":\n",
    "        kf = GroupKFold(n_splits=cfg.kfold.number)\n",
    "    elif cfg.kfold.method == \"sgkf\":\n",
    "        kf = StratifiedGroupKFold(\n",
    "            n_splits=cfg.kfold.number, random_state=cfg.basic.seed\n",
    "        )\n",
    "    elif cfg.kfold.method == \"tskf\":\n",
    "        kf = TimeSeriesSplit(n_splits=cfg.kfold.number)\n",
    "    else:\n",
    "        raise ValueError(f\"{cfg.kfold.method} is not supported\")\n",
    "    return kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e1e049a-17be-4901-a59d-8d475c180753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "\n",
    "\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "class AtmaDataset(data.Dataset):\n",
    "    \"\"\"atmaCup用にデータ読み込み等を行なうデータ・セット\"\"\"\n",
    "    object_path_key = \"object_path\"\n",
    "    label_key = \"target\"\n",
    "\n",
    "    def __init__(self, meta_df: pd.DataFrame, is_train: bool = True) -> None:\n",
    "        self.is_train = is_train\n",
    "        self.meta_df = meta_df.reset_index(drop=True)\n",
    "        self.index_to_data = self.meta_df.to_dict(orient=\"index\")\n",
    "        \n",
    "        size = (ModelConfig.params.image_size, ModelConfig.params.image_size)\n",
    "        additional_items = (\n",
    "            [T.Resize(size)]\n",
    "            if not is_train\n",
    "            else [\n",
    "                T.RandomGrayscale(p=0.2),\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.ColorJitter(\n",
    "                    brightness=0.3,\n",
    "                    contrast=0.5,\n",
    "                    saturation=[0.8, 1.3],\n",
    "                    hue=[-0.05, 0.05],\n",
    "                ),\n",
    "                T.RandomResizedCrop(size),\n",
    "            ]\n",
    "        )\n",
    "        self.transformer = T.Compose(\n",
    "            [*additional_items, T.ToTensor(), T.Normalize(mean=IMG_MEAN, std=IMG_STD)]\n",
    "        )\n",
    "        \n",
    "        self._validate_meta_df(meta_df)\n",
    "\n",
    "    def __getitem__(self, index) -> Dict[str, Any]:\n",
    "        data = self.index_to_data[index]\n",
    "        obj_path, label = data.get(self.object_path_key), data.get(self.label_key, -1)\n",
    "        img = self.transformer(Image.open(obj_path))\n",
    "        return {\"image\": img, \"label\": label}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.meta_df)\n",
    "    \n",
    "    def _validate_meta_df(self, meta_df: pd.DataFrame) -> None:\n",
    "        for k in self.meta_keys:\n",
    "            if k not in meta_df:\n",
    "                raise ValueError(f\"meta df must have {k}\")\n",
    "                \n",
    "    @property\n",
    "    def meta_keys(self) -> List[str]:\n",
    "        retval = [self.object_path_key]\n",
    "        if self.is_train:\n",
    "            retval += [self.label_key]\n",
    "        return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb29cd98-7770-4f3e-813f-461679503034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import OrderedDict\n",
    "from logging import Logger\n",
    "from typing import Dict, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def build_model(pretrained: bool = False):\n",
    "    model = models.resnet34(pretrained=pretrained)\n",
    "    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)    \n",
    "    return model\n",
    "\n",
    "\n",
    "class BaseRunner:\n",
    "    def __init__(self, cfg: ModelConfig):\n",
    "        self.cfg = cfg\n",
    "        self.params = cfg.params\n",
    "\n",
    "    def _get_scheduler(\n",
    "        self, optimizer: Union[optim.Adam]\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if self.params.scheduler.name == \"ReduceLROnPlateau\":\n",
    "            scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode=self.params.scheduler.mode,\n",
    "                factor=self.params.scheduler.factor,\n",
    "                patience=self.params.scheduler.patience,\n",
    "                verbose=self.params.scheduler.verbose,\n",
    "                eps=self.params.scheduler.eps,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.scheduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _step_scheduler(\n",
    "        self,\n",
    "        scheduler: Union[\n",
    "            lr_scheduler.ReduceLROnPlateau,\n",
    "        ],\n",
    "        avg_val_loss,\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.shceduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _evaluate(self, y_true: np.array, y_pred: np.array):\n",
    "        score = RMSE(y_true, y_pred)\n",
    "        print(f\"Score: {score:<.5f}\")\n",
    "\n",
    "\n",
    "class TrainRunner(BaseRunner):\n",
    "    def _train_batch(self, train_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        # scores = AverageMeter()\n",
    "        model.train()\n",
    "        start = end = time.time()\n",
    "        for step, image_label_dict in enumerate(train_loader):\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            y_preds = model(images)\n",
    "            loss = criterion(y_preds.squeeze(), labels.float())\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            grad_norm = nn.utils.clip_grad_norm_(\n",
    "                model.parameters(), self.params.max_grad_norm\n",
    "            )\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "        return losses.avg\n",
    "\n",
    "    def _valid_batch(self, valid_loader, model, criterion):\n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        # scores = AverageMeter()\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        start = end = time.time()\n",
    "        for step, image_label_dict in enumerate(valid_loader):\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            loss = criterion(y_preds.squeeze(), labels.float())\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "        predictions = np.concatenate(preds)\n",
    "        return losses.avg, predictions\n",
    "\n",
    "    def _train(self, train: pd.DataFrame, n_fold: int):\n",
    "        print(f\"fold: {n_fold}\")\n",
    "\n",
    "        trn_idx = train[train[\"fold\"] != n_fold].index\n",
    "        val_idx = train[train[\"fold\"] == n_fold].index\n",
    "        train_folds = train.loc[trn_idx].reset_index(drop=True)\n",
    "        valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "        train_dataset = AtmaDataset(\n",
    "            train_folds,\n",
    "            is_train=True,\n",
    "#             transform=get_transforms(self.params, data=\"train\"),\n",
    "        )\n",
    "        valid_dataset = AtmaDataset(\n",
    "            valid_folds,\n",
    "            is_train=False,\n",
    "#             transform=get_transforms(self.params, data=\"valid\"),\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        model = build_model(pretrained=self.cfg.params.pretrained)\n",
    "        model.to(self.cfg.basic.device)\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=self.params.optimizer.lr,\n",
    "            weight_decay=self.params.optimizer.weight_decay,\n",
    "            amsgrad=self.params.optimizer.amsgrad,\n",
    "        )\n",
    "        scheduler = self._get_scheduler(optimizer)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        best_score = np.inf\n",
    "        # best_loss = np.inf\n",
    "        for epoch in range(self.params.epochs):\n",
    "            start_time = time.time()\n",
    "\n",
    "            avg_loss = self._train_batch(\n",
    "                train_loader, model, criterion, optimizer, scheduler, epoch\n",
    "            )\n",
    "            avg_val_loss, preds = self._valid_batch(valid_loader, model, criterion)\n",
    "            valid_labels = valid_folds[\"target\"].values\n",
    "            scheduler = self._step_scheduler(scheduler, avg_val_loss)\n",
    "            score = RMSE(valid_labels, preds)\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "            )\n",
    "            print(f\"Epoch {epoch+1} - RMSE: {score}\")\n",
    "            if best_score > score:\n",
    "                best_score = score\n",
    "                torch.save(\n",
    "                    {\"model\": model.state_dict(), \"preds\": preds},\n",
    "                    f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\",\n",
    "                )\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - Best Score: {best_score:.4f}\"\n",
    "            )\n",
    "\n",
    "        check_point: Dict[str, Union[OrderedDict, torch.Tensor]] = torch.load(\n",
    "            f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\"\n",
    "        )\n",
    "        valid_folds[\"preds\"] = check_point[\"preds\"]\n",
    "        return valid_folds\n",
    "\n",
    "    def run_cv(self, train: pd.DataFrame) -> None:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for n_fold in range(self.cfg.kfold.number):\n",
    "            _oof_df = self._train(train, n_fold)\n",
    "            print(f\"========== fold: {n_fold} result ==========\")\n",
    "            self._evaluate(_oof_df[\"target\"], _oof_df[\"preds\"])\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "        print(\"========== CV ==========\")\n",
    "        self._evaluate(oof_df[\"target\"], oof_df[\"preds\"])\n",
    "        Jbl.save(oof_df, f\"{OutputPath.model}/oof_df_{self.cfg.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9c6ec55-378b-402c-8f5b-00172c78fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceRunner(BaseRunner):\n",
    "    def _test_batch(self, test_loader, model):\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for step, image_label_dict in enumerate(test_loader):\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "        predictions = np.concatenate(preds)\n",
    "        return predictions\n",
    "\n",
    "    def _test(self, test: pd.DataFrame, n_fold: int):\n",
    "        print(f\"fold: {n_fold}\")\n",
    "        test_dataset = AtmaDataset(\n",
    "            test,\n",
    "            is_train=False,\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.params.test_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        model = build_model(pretrained=self.cfg.params.pretrained)\n",
    "        model_state = torch.load(f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\")[\"model\"]\n",
    "        model.load_state_dict(model_state)\n",
    "        model.to(self.cfg.basic.device)\n",
    "        preds = self._test_batch(test_loader, model)\n",
    "        return preds\n",
    "    \n",
    "    def _submit(self, preds: np.array) -> None:\n",
    "        df_sub = load_csv(input_path.sub)\n",
    "        df_sub = df_sub.assign(target=preds)\n",
    "        path = f\"{OutputPath.submission}/submission_{self.cfg.basic.run_name}.csv\"\n",
    "        df_sub.to_csv(path, index=False)\n",
    "        print(\"submission.csv created\")\n",
    "\n",
    "    def run_cv(self, test: pd.DataFrame) -> None:\n",
    "        oof_df = pd.DataFrame()\n",
    "        preds: List[np.array] = []\n",
    "        for n_fold in range(self.cfg.kfold.number):\n",
    "            preds_fold = self._test(test, n_fold)\n",
    "            preds.append(preds_fold)\n",
    "        Jbl.save(preds, f\"{OutputPath.model}/preds_test_{self.cfg.basic.run_name}.jbl\")\n",
    "        \n",
    "        preds_mean = np.concatenate(preds, axis=1).mean(axis=1)\n",
    "        self._submit(preds_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eae1cb89-4ee0-4293-b935-888a14f628da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed()\n",
    "input_path = InputPath()\n",
    "model_config = ModelConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c99fafc2-2ace-488f-b2a3-1f6f3297af69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3937, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>sorting_date</th>\n",
       "      <th>art_series_id</th>\n",
       "      <th>target</th>\n",
       "      <th>object_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002bff09b09998d0be65</td>\n",
       "      <td>1631</td>\n",
       "      <td>509357f67692a6a45626</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/photos/002bff09b09998d0be65.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00309fb1ef05416f9c1f</td>\n",
       "      <td>1900</td>\n",
       "      <td>7987b47bbe5dc3039179</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/00309fb1ef05416f9c1f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003a1562e97f79ba96dc</td>\n",
       "      <td>1834</td>\n",
       "      <td>ded7c3c9636708e5b14c</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/003a1562e97f79ba96dc.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              object_id  sorting_date         art_series_id  target  \\\n",
       "0  002bff09b09998d0be65          1631  509357f67692a6a45626       1   \n",
       "1  00309fb1ef05416f9c1f          1900  7987b47bbe5dc3039179       3   \n",
       "2  003a1562e97f79ba96dc          1834  ded7c3c9636708e5b14c       3   \n",
       "\n",
       "                                object_path  \n",
       "0  ../input/photos/002bff09b09998d0be65.jpg  \n",
       "1  ../input/photos/00309fb1ef05416f9c1f.jpg  \n",
       "2  ../input/photos/003a1562e97f79ba96dc.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = load_csv(input_path.train)\n",
    "train = train.assign(object_path = train[\"object_id\"].apply(lambda x: to_img_path(input_path.photos_prefix, x)))\n",
    "print(train.shape)\n",
    "display(train.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8796a89d-9fce-49b6-8d53-3c315b65722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 - [0 1 2 3 4]~[3928 3930 3933 3934 3935]\t[ 8 14 16 19 21]~[3922 3929 3931 3932 3936]\n",
      "fold: 1 - [0 1 2 4 5]~[3931 3932 3933 3934 3936]\t[ 3  9 20 23 24]~[3899 3907 3912 3925 3935]\n",
      "fold: 2 - [0 1 2 3 5]~[3931 3932 3934 3935 3936]\t[ 4  6 10 11 12]~[3913 3915 3924 3927 3933]\n",
      "fold: 3 - [2 3 4 5 6]~[3932 3933 3934 3935 3936]\t[ 0  1  7 17 29]~[3914 3916 3919 3923 3926]\n",
      "fold: 4 - [0 1 3 4 6]~[3931 3932 3933 3935 3936]\t[ 2  5 22 31 32]~[3909 3918 3928 3930 3934]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "fold target     \n",
       "0    0        95\n",
       "     1       180\n",
       "     2       302\n",
       "     3       211\n",
       "1    0        95\n",
       "     1       179\n",
       "     2       303\n",
       "     3       211\n",
       "2    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211\n",
       "3    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211\n",
       "4    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kf = generate_kf(model_config)\n",
    "if model_config.kfold.method.endswith(\"gkf\"):\n",
    "    kf_generator = kf.split(\n",
    "        train,\n",
    "        train[self.fe_cfg.column.target],\n",
    "        groups=train[self.kfold.columns],\n",
    "    )\n",
    "else:\n",
    "    kf_generator = kf.split(train, train[\"target\"])\n",
    "for fold_i, (tr_idx, val_idx) in enumerate(kf_generator):\n",
    "    print(\n",
    "        f\"fold: {fold_i} - {tr_idx[:5]}~{tr_idx[-5:]}\\t{val_idx[:5]}~{val_idx[-5:]}\"\n",
    "    )\n",
    "    train.loc[val_idx, \"fold\"] = fold_i\n",
    "train = train.assign(fold = train[\"fold\"].astype(int))\n",
    "if model_config.kfold.method == \"skf\":\n",
    "    display(train.groupby([\"fold\", \"target\"]).size().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0af2c78d-558e-491c-b0f4-1884e1f42273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "Epoch 1 - avg_train_loss: 1.1380  avg_val_loss: 0.9102  time: 23s\n",
      "Epoch 1 - RMSE: 0.9540415151897651\n",
      "Epoch 1 - Best Score: 0.9540\n",
      "Epoch 2 - avg_train_loss: 0.9536  avg_val_loss: 1.1754  time: 23s\n",
      "Epoch 2 - RMSE: 1.0841452185935734\n",
      "Epoch 2 - Best Score: 0.9540\n",
      "Epoch 3 - avg_train_loss: 0.9477  avg_val_loss: 0.8542  time: 23s\n",
      "Epoch 3 - RMSE: 0.9242206010332672\n",
      "Epoch 3 - Best Score: 0.9242\n",
      "Epoch 4 - avg_train_loss: 0.9398  avg_val_loss: 0.9576  time: 23s\n",
      "Epoch 4 - RMSE: 0.9785568615310627\n",
      "Epoch 4 - Best Score: 0.9242\n",
      "Epoch 5 - avg_train_loss: 0.9326  avg_val_loss: 0.9523  time: 23s\n",
      "Epoch 5 - RMSE: 0.9758634933292687\n",
      "Epoch 5 - Best Score: 0.9242\n",
      "Epoch 6 - avg_train_loss: 0.9312  avg_val_loss: 0.9618  time: 23s\n",
      "Epoch 6 - RMSE: 0.9807174913859086\n",
      "Epoch 6 - Best Score: 0.9242\n",
      "Epoch 7 - avg_train_loss: 0.9136  avg_val_loss: 0.7999  time: 23s\n",
      "Epoch 7 - RMSE: 0.8943863231902787\n",
      "Epoch 7 - Best Score: 0.8944\n",
      "Epoch 8 - avg_train_loss: 0.9052  avg_val_loss: 0.9643  time: 23s\n",
      "Epoch 8 - RMSE: 0.9819661289968599\n",
      "Epoch 8 - Best Score: 0.8944\n",
      "Epoch 9 - avg_train_loss: 0.9000  avg_val_loss: 0.9292  time: 23s\n",
      "Epoch 9 - RMSE: 0.9639374101045911\n",
      "Epoch 9 - Best Score: 0.8944\n",
      "Epoch 10 - avg_train_loss: 0.8964  avg_val_loss: 0.8445  time: 23s\n",
      "Epoch 10 - RMSE: 0.9189797058656726\n",
      "Epoch 10 - Best Score: 0.8944\n",
      "========== fold: 0 result ==========\n",
      "Score: 0.89439\n",
      "fold: 1\n",
      "Epoch 1 - avg_train_loss: 1.2121  avg_val_loss: 0.9491  time: 23s\n",
      "Epoch 1 - RMSE: 0.9742148167174692\n",
      "Epoch 1 - Best Score: 0.9742\n",
      "Epoch 2 - avg_train_loss: 0.9742  avg_val_loss: 1.0433  time: 23s\n",
      "Epoch 2 - RMSE: 1.021399461840899\n",
      "Epoch 2 - Best Score: 0.9742\n",
      "Epoch 3 - avg_train_loss: 0.9316  avg_val_loss: 1.4910  time: 23s\n",
      "Epoch 3 - RMSE: 1.221057540432713\n",
      "Epoch 3 - Best Score: 0.9742\n",
      "Epoch 4 - avg_train_loss: 0.9276  avg_val_loss: 0.8456  time: 23s\n",
      "Epoch 4 - RMSE: 0.9195403775766697\n",
      "Epoch 4 - Best Score: 0.9195\n",
      "Epoch 5 - avg_train_loss: 0.9112  avg_val_loss: 0.8689  time: 23s\n",
      "Epoch 5 - RMSE: 0.9321693834694722\n",
      "Epoch 5 - Best Score: 0.9195\n",
      "Epoch 6 - avg_train_loss: 0.8996  avg_val_loss: 0.8471  time: 23s\n",
      "Epoch 6 - RMSE: 0.9203921174898064\n",
      "Epoch 6 - Best Score: 0.9195\n",
      "Epoch 7 - avg_train_loss: 0.8920  avg_val_loss: 0.8639  time: 23s\n",
      "Epoch 7 - RMSE: 0.9294600319344178\n",
      "Epoch 7 - Best Score: 0.9195\n",
      "Epoch 8 - avg_train_loss: 0.9005  avg_val_loss: 0.8634  time: 23s\n",
      "Epoch 8 - RMSE: 0.9292051023724182\n",
      "Epoch 8 - Best Score: 0.9195\n",
      "Epoch 9 - avg_train_loss: 0.8826  avg_val_loss: 0.8341  time: 23s\n",
      "Epoch 9 - RMSE: 0.913304663413594\n",
      "Epoch 9 - Best Score: 0.9133\n",
      "Epoch 10 - avg_train_loss: 0.8876  avg_val_loss: 0.8055  time: 23s\n",
      "Epoch 10 - RMSE: 0.897486575059547\n",
      "Epoch 10 - Best Score: 0.8975\n",
      "========== fold: 1 result ==========\n",
      "Score: 0.89749\n",
      "fold: 2\n",
      "Epoch 1 - avg_train_loss: 1.2580  avg_val_loss: 0.9501  time: 23s\n",
      "Epoch 1 - RMSE: 0.9747057424095396\n",
      "Epoch 1 - Best Score: 0.9747\n",
      "Epoch 2 - avg_train_loss: 0.9255  avg_val_loss: 0.9613  time: 23s\n",
      "Epoch 2 - RMSE: 0.9804522882411849\n",
      "Epoch 2 - Best Score: 0.9747\n",
      "Epoch 3 - avg_train_loss: 0.9250  avg_val_loss: 0.8767  time: 23s\n",
      "Epoch 3 - RMSE: 0.9363381732093654\n",
      "Epoch 3 - Best Score: 0.9363\n",
      "Epoch 4 - avg_train_loss: 0.9312  avg_val_loss: 0.8401  time: 23s\n",
      "Epoch 4 - RMSE: 0.9165575730551073\n",
      "Epoch 4 - Best Score: 0.9166\n",
      "Epoch 5 - avg_train_loss: 0.9072  avg_val_loss: 0.8677  time: 23s\n",
      "Epoch 5 - RMSE: 0.931503981662162\n",
      "Epoch 5 - Best Score: 0.9166\n",
      "Epoch 6 - avg_train_loss: 0.9342  avg_val_loss: 0.8092  time: 23s\n",
      "Epoch 6 - RMSE: 0.899569391156752\n",
      "Epoch 6 - Best Score: 0.8996\n",
      "Epoch 7 - avg_train_loss: 0.9155  avg_val_loss: 0.8872  time: 23s\n",
      "Epoch 7 - RMSE: 0.9418961896339546\n",
      "Epoch 7 - Best Score: 0.8996\n",
      "Epoch 8 - avg_train_loss: 0.9027  avg_val_loss: 0.8693  time: 23s\n",
      "Epoch 8 - RMSE: 0.9323409819359478\n",
      "Epoch 8 - Best Score: 0.8996\n",
      "Epoch 9 - avg_train_loss: 0.8850  avg_val_loss: 0.8780  time: 23s\n",
      "Epoch 9 - RMSE: 0.9370232883735087\n",
      "Epoch 9 - Best Score: 0.8996\n",
      "Epoch 10 - avg_train_loss: 0.9069  avg_val_loss: 0.7931  time: 23s\n",
      "Epoch 10 - RMSE: 0.8905793959401808\n",
      "Epoch 10 - Best Score: 0.8906\n",
      "========== fold: 2 result ==========\n",
      "Score: 0.89058\n",
      "fold: 3\n",
      "Epoch 1 - avg_train_loss: 1.4056  avg_val_loss: 0.9854  time: 23s\n",
      "Epoch 1 - RMSE: 0.9926731743328252\n",
      "Epoch 1 - Best Score: 0.9927\n",
      "Epoch 2 - avg_train_loss: 0.9613  avg_val_loss: 1.2255  time: 23s\n",
      "Epoch 2 - RMSE: 1.1070232893576104\n",
      "Epoch 2 - Best Score: 0.9927\n",
      "Epoch 3 - avg_train_loss: 0.9655  avg_val_loss: 0.8681  time: 23s\n",
      "Epoch 3 - RMSE: 0.9317127860404874\n",
      "Epoch 3 - Best Score: 0.9317\n",
      "Epoch 4 - avg_train_loss: 0.9139  avg_val_loss: 0.8299  time: 23s\n",
      "Epoch 4 - RMSE: 0.910992880243952\n",
      "Epoch 4 - Best Score: 0.9110\n",
      "Epoch 5 - avg_train_loss: 0.8999  avg_val_loss: 0.9131  time: 23s\n",
      "Epoch 5 - RMSE: 0.9555773946406462\n",
      "Epoch 5 - Best Score: 0.9110\n",
      "Epoch 6 - avg_train_loss: 0.8971  avg_val_loss: 0.9057  time: 23s\n",
      "Epoch 6 - RMSE: 0.9516604616557297\n",
      "Epoch 6 - Best Score: 0.9110\n",
      "Epoch 7 - avg_train_loss: 0.8879  avg_val_loss: 0.8972  time: 23s\n",
      "Epoch 7 - RMSE: 0.9471910256525968\n",
      "Epoch 7 - Best Score: 0.9110\n",
      "Epoch 8 - avg_train_loss: 0.8902  avg_val_loss: 0.8070  time: 23s\n",
      "Epoch 8 - RMSE: 0.898310875763247\n",
      "Epoch 8 - Best Score: 0.8983\n",
      "Epoch 9 - avg_train_loss: 0.8869  avg_val_loss: 0.8195  time: 23s\n",
      "Epoch 9 - RMSE: 0.9052637247768475\n",
      "Epoch 9 - Best Score: 0.8983\n",
      "Epoch 10 - avg_train_loss: 0.8940  avg_val_loss: 0.8442  time: 23s\n",
      "Epoch 10 - RMSE: 0.9188104805467617\n",
      "Epoch 10 - Best Score: 0.8983\n",
      "========== fold: 3 result ==========\n",
      "Score: 0.89831\n",
      "fold: 4\n",
      "Epoch 1 - avg_train_loss: 1.3992  avg_val_loss: 0.9015  time: 23s\n",
      "Epoch 1 - RMSE: 0.9494880881390345\n",
      "Epoch 1 - Best Score: 0.9495\n",
      "Epoch 2 - avg_train_loss: 0.9313  avg_val_loss: 0.9521  time: 23s\n",
      "Epoch 2 - RMSE: 0.9757393179486586\n",
      "Epoch 2 - Best Score: 0.9495\n",
      "Epoch 3 - avg_train_loss: 0.9222  avg_val_loss: 1.0913  time: 23s\n",
      "Epoch 3 - RMSE: 1.0446605062259622\n",
      "Epoch 3 - Best Score: 0.9495\n",
      "Epoch 4 - avg_train_loss: 0.9195  avg_val_loss: 0.8490  time: 23s\n",
      "Epoch 4 - RMSE: 0.9213996600068451\n",
      "Epoch 4 - Best Score: 0.9214\n",
      "Epoch 5 - avg_train_loss: 0.9211  avg_val_loss: 0.8623  time: 23s\n",
      "Epoch 5 - RMSE: 0.9286198922353189\n",
      "Epoch 5 - Best Score: 0.9214\n",
      "Epoch 6 - avg_train_loss: 0.9250  avg_val_loss: 0.8327  time: 23s\n",
      "Epoch 6 - RMSE: 0.9125356011810881\n",
      "Epoch 6 - Best Score: 0.9125\n",
      "Epoch 7 - avg_train_loss: 0.9027  avg_val_loss: 0.8247  time: 23s\n",
      "Epoch 7 - RMSE: 0.9081446153405978\n",
      "Epoch 7 - Best Score: 0.9081\n",
      "Epoch 8 - avg_train_loss: 0.8898  avg_val_loss: 0.8718  time: 23s\n",
      "Epoch 8 - RMSE: 0.9337104434017024\n",
      "Epoch 8 - Best Score: 0.9081\n",
      "Epoch 9 - avg_train_loss: 0.9099  avg_val_loss: 0.8404  time: 23s\n",
      "Epoch 9 - RMSE: 0.9167350097112531\n",
      "Epoch 9 - Best Score: 0.9081\n",
      "Epoch 10 - avg_train_loss: 0.8871  avg_val_loss: 0.8034  time: 23s\n",
      "Epoch 10 - RMSE: 0.8963277041479778\n",
      "Epoch 10 - Best Score: 0.8963\n",
      "========== fold: 4 result ==========\n",
      "Score: 0.89633\n",
      "========== CV ==========\n",
      "Score: 0.89542\n",
      "CPU times: user 1h 40min 34s, sys: 3min 24s, total: 1h 43min 58s\n",
      "Wall time: 19min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TrainRunner(model_config).run_cv(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ba9ba8b-317b-42a0-9a0b-c6bd8e07f462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>sorting_date</th>\n",
       "      <th>art_series_id</th>\n",
       "      <th>target</th>\n",
       "      <th>object_path</th>\n",
       "      <th>fold</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00bf812ffe8a62d45661</td>\n",
       "      <td>1720</td>\n",
       "      <td>3bfd41016d864e3fd8b5</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/00bf812ffe8a62d45661.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2.024766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0110115b8b6036d9ab3c</td>\n",
       "      <td>1741</td>\n",
       "      <td>baa4a20f0372d74dfc80</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/0110115b8b6036d9ab3c.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01273c00c46a84c50468</td>\n",
       "      <td>1757</td>\n",
       "      <td>51024cb4c6256ccce827</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/01273c00c46a84c50468.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.966438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0160840d9a4620b08fbd</td>\n",
       "      <td>1874</td>\n",
       "      <td>a56504999a8157a25d16</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/0160840d9a4620b08fbd.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2.325841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0169c493b09c8758a1b3</td>\n",
       "      <td>1734</td>\n",
       "      <td>550c62dd363fea62581c</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/0169c493b09c8758a1b3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.778977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>fe4d591332b08ab81361</td>\n",
       "      <td>1600</td>\n",
       "      <td>0782dfafa355acaf888c</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/photos/fe4d591332b08ab81361.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.902615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>fecae40c488e4c8c5ba5</td>\n",
       "      <td>1600</td>\n",
       "      <td>9ac00be75c55b1653a94</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/photos/fecae40c488e4c8c5ba5.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2.105773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>ff37540e22e1ef455368</td>\n",
       "      <td>1765</td>\n",
       "      <td>9971eebf0f583a5e51da</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/ff37540e22e1ef455368.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2.107603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>ff9124278e0f7086738f</td>\n",
       "      <td>1630</td>\n",
       "      <td>b4d508f53d16f7bcaf55</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/photos/ff9124278e0f7086738f.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2.036468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>ffd794b7b311b7b7fd92</td>\n",
       "      <td>1789</td>\n",
       "      <td>f030a01b480b18a27be2</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/ffd794b7b311b7b7fd92.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2.309892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3937 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                object_id  sorting_date         art_series_id  target  \\\n",
       "0    00bf812ffe8a62d45661          1720  3bfd41016d864e3fd8b5       2   \n",
       "1    0110115b8b6036d9ab3c          1741  baa4a20f0372d74dfc80       2   \n",
       "2    01273c00c46a84c50468          1757  51024cb4c6256ccce827       2   \n",
       "3    0160840d9a4620b08fbd          1874  a56504999a8157a25d16       3   \n",
       "4    0169c493b09c8758a1b3          1734  550c62dd363fea62581c       2   \n",
       "..                    ...           ...                   ...     ...   \n",
       "782  fe4d591332b08ab81361          1600  0782dfafa355acaf888c       0   \n",
       "783  fecae40c488e4c8c5ba5          1600  9ac00be75c55b1653a94       0   \n",
       "784  ff37540e22e1ef455368          1765  9971eebf0f583a5e51da       2   \n",
       "785  ff9124278e0f7086738f          1630  b4d508f53d16f7bcaf55       1   \n",
       "786  ffd794b7b311b7b7fd92          1789  f030a01b480b18a27be2       2   \n",
       "\n",
       "                                  object_path  fold     preds  \n",
       "0    ../input/photos/00bf812ffe8a62d45661.jpg     0  2.024766  \n",
       "1    ../input/photos/0110115b8b6036d9ab3c.jpg     0  1.666041  \n",
       "2    ../input/photos/01273c00c46a84c50468.jpg     0  0.966438  \n",
       "3    ../input/photos/0160840d9a4620b08fbd.jpg     0  2.325841  \n",
       "4    ../input/photos/0169c493b09c8758a1b3.jpg     0  1.778977  \n",
       "..                                        ...   ...       ...  \n",
       "782  ../input/photos/fe4d591332b08ab81361.jpg     4  1.902615  \n",
       "783  ../input/photos/fecae40c488e4c8c5ba5.jpg     4  2.105773  \n",
       "784  ../input/photos/ff37540e22e1ef455368.jpg     4  2.107603  \n",
       "785  ../input/photos/ff9124278e0f7086738f.jpg     4  2.036468  \n",
       "786  ../input/photos/ffd794b7b311b7b7fd92.jpg     4  2.309892  \n",
       "\n",
       "[3937 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72e174df-3c50-4bae-a0be-dc59445ea40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")[\"preds\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e2e35b9-f7b8-4ea9-96e4-6053d8dc537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "fold: 1\n",
      "fold: 2\n",
      "fold: 3\n",
      "fold: 4\n",
      "submission.csv created\n"
     ]
    }
   ],
   "source": [
    "test = load_csv(input_path.test)\n",
    "test = test.assign(object_path = test[\"object_id\"].apply(lambda x: to_img_path(input_path.photos_prefix, x)))\n",
    "InferenceRunner(model_config).run_cv(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa73ab9-d584-426e-9bac-a21e3b86a54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

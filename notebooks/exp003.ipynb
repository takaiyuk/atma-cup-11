{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a9074a-5044-4ae5-a622-79637a6e0c68",
   "metadata": {},
   "source": [
    "File Changed\n",
    "- base version: exp002\n",
    "- epoch: 10 -> 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08317bb-fa4d-45c8-9729-46910b084d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce6b088f-2dd0-471b-8d65-5474a0047688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InputPath:\n",
    "    _prefix: str = \"../input\"\n",
    "    train: str = f\"{_prefix}/train.csv\"\n",
    "    materials: str = f\"{_prefix}/materials.csv\"\n",
    "    techniques: str = f\"{_prefix}/techniques.csv\"\n",
    "    test: str = f\"{_prefix}/test.csv\"\n",
    "    sub: str = f\"{_prefix}/atmaCup#11_sample_submission.csv\"\n",
    "    photos_prefix: str = f\"{_prefix}/photos\"\n",
    "    photos: List[str] = field(default_factory=lambda: glob(f\"../input/photos/*.jpg\"))\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class OutputPath:\n",
    "    _prefix: str = \"../output/\"\n",
    "    model: str = f\"{_prefix}/model\"\n",
    "    submission: str = f\"{_prefix}/submission\"\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Basic:\n",
    "    run_name: str = \"exp003\"\n",
    "    is_debug: bool = False\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Kfold:\n",
    "    number: int = 5\n",
    "    method: str = \"skf\"\n",
    "    shuffle: bool = True\n",
    "    columns: List[str] = field(default_factory=lambda: [\"target\"])\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Adam:\n",
    "    name: str = \"Adam\"\n",
    "    lr: float = 1e-4\n",
    "    weight_decay: float = 0\n",
    "    amsgrad: bool = False\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class ReduceLROnPlateau:\n",
    "    name: str = \"ReduceLROnPlateau\"\n",
    "    mode: str = \"min\"\n",
    "    factor: float = 0.1\n",
    "    patience: int = 5\n",
    "    verbose: bool = True\n",
    "    eps: float = 1e-8\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Params:\n",
    "    batch_size: int = 64\n",
    "    test_batch_size: int = 256\n",
    "    epochs: int = 3 if Basic.is_debug else 30\n",
    "    image_size: int = 224\n",
    "    max_grad_norm: int = 1000\n",
    "    num_workers: int = 0\n",
    "    print_freq: int = 10000\n",
    "    target_size: int = 1\n",
    "    # Union[Adam]\n",
    "    optimizer: Adam = Adam()\n",
    "    # Union[CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau]\n",
    "    scheduler: ReduceLROnPlateau = ReduceLROnPlateau()\n",
    "    pretrained: bool = False\n",
    "        \n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    basic: Basic = Basic()\n",
    "    kfold: Kfold = Kfold()\n",
    "    params: Params = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e688a697-6d8e-40a5-89a3-56833b01cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_sessions = [x.split(\"_\")[0] for x in os.listdir(OutputPath.model) if x.endswith(\"_0.pth\")]\n",
    "assert Basic.run_name not in past_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b0b95d9-6d21-48a4-8ef9-d085e183e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class Jbl:\n",
    "    @staticmethod\n",
    "    def load(filepath: str) -> Any:\n",
    "        return joblib.load(filepath)\n",
    "\n",
    "    @staticmethod\n",
    "    def save(obj_: Any, filepath: str) -> None:\n",
    "        joblib.dump(obj_, filepath, compress=3)\n",
    "\n",
    "\n",
    "def RMSE(y: np.array, p: np.array) -> float:\n",
    "    return metrics.mean_squared_error(y, p) ** 0.5\n",
    "\n",
    "\n",
    "def fix_seed(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    \n",
    "def time_since(since: time.time, percent: float) -> str:\n",
    "    def as_minutes(s):\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return \"%dm %ds\" % (m, s)\n",
    "\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adac7d51-f744-4349-a639-7a6661370d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def to_img_path(photo_dir: str, object_id: str) -> str:\n",
    "    return os.path.join(photo_dir, f'{object_id}.jpg')\n",
    "\n",
    "def read_image(object_id: str):\n",
    "    return Image.open(to_img_path(object_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52cc936d-6003-4e02-ba1f-d42cf039cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_csv(path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "169f341c-c861-4c5d-918c-201017c494da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    GroupKFold,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    TimeSeriesSplit,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_kf(cfg: ModelConfig) -> Generator:\n",
    "    if cfg.kfold.method == \"kf\":\n",
    "        kf = KFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"skf\":\n",
    "        kf = StratifiedKFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"gkf\":\n",
    "        kf = GroupKFold(n_splits=cfg.kfold.number)\n",
    "    elif cfg.kfold.method == \"sgkf\":\n",
    "        kf = StratifiedGroupKFold(\n",
    "            n_splits=cfg.kfold.number, random_state=cfg.basic.seed\n",
    "        )\n",
    "    elif cfg.kfold.method == \"tskf\":\n",
    "        kf = TimeSeriesSplit(n_splits=cfg.kfold.number)\n",
    "    else:\n",
    "        raise ValueError(f\"{cfg.kfold.method} is not supported\")\n",
    "    return kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e1e049a-17be-4901-a59d-8d475c180753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "\n",
    "\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "class AtmaDataset(data.Dataset):\n",
    "    \"\"\"atmaCup用にデータ読み込み等を行なうデータ・セット\"\"\"\n",
    "    object_path_key = \"object_path\"\n",
    "    label_key = \"target\"\n",
    "\n",
    "    def __init__(self, meta_df: pd.DataFrame, is_train: bool = True) -> None:\n",
    "        self.is_train = is_train\n",
    "        self.meta_df = meta_df.reset_index(drop=True)\n",
    "        self.index_to_data = self.meta_df.to_dict(orient=\"index\")\n",
    "        \n",
    "        size = (ModelConfig.params.image_size, ModelConfig.params.image_size)\n",
    "        additional_items = (\n",
    "            [T.Resize(size)]\n",
    "            if not is_train\n",
    "            else [\n",
    "                T.RandomGrayscale(p=0.2),\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.ColorJitter(\n",
    "                    brightness=0.3,\n",
    "                    contrast=0.5,\n",
    "                    saturation=[0.8, 1.3],\n",
    "                    hue=[-0.05, 0.05],\n",
    "                ),\n",
    "                T.RandomResizedCrop(size),\n",
    "            ]\n",
    "        )\n",
    "        self.transformer = T.Compose(\n",
    "            [*additional_items, T.ToTensor(), T.Normalize(mean=IMG_MEAN, std=IMG_STD)]\n",
    "        )\n",
    "        \n",
    "        self._validate_meta_df(meta_df)\n",
    "\n",
    "    def __getitem__(self, index) -> Dict[str, Any]:\n",
    "        data = self.index_to_data[index]\n",
    "        obj_path, label = data.get(self.object_path_key), data.get(self.label_key, -1)\n",
    "        img = self.transformer(Image.open(obj_path))\n",
    "        return {\"image\": img, \"label\": label}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.meta_df)\n",
    "    \n",
    "    def _validate_meta_df(self, meta_df: pd.DataFrame) -> None:\n",
    "        for k in self.meta_keys:\n",
    "            if k not in meta_df:\n",
    "                raise ValueError(f\"meta df must have {k}\")\n",
    "                \n",
    "    @property\n",
    "    def meta_keys(self) -> List[str]:\n",
    "        retval = [self.object_path_key]\n",
    "        if self.is_train:\n",
    "            retval += [self.label_key]\n",
    "        return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb29cd98-7770-4f3e-813f-461679503034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import OrderedDict\n",
    "from logging import Logger\n",
    "from typing import Dict, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def build_model(pretrained: bool = False):\n",
    "    model = models.resnet34(pretrained=pretrained)\n",
    "    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)    \n",
    "    return model\n",
    "\n",
    "\n",
    "class BaseRunner:\n",
    "    def __init__(self, cfg: ModelConfig):\n",
    "        self.cfg = cfg\n",
    "        self.params = cfg.params\n",
    "\n",
    "    def _get_scheduler(\n",
    "        self, optimizer: Union[optim.Adam]\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if self.params.scheduler.name == \"ReduceLROnPlateau\":\n",
    "            scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode=self.params.scheduler.mode,\n",
    "                factor=self.params.scheduler.factor,\n",
    "                patience=self.params.scheduler.patience,\n",
    "                verbose=self.params.scheduler.verbose,\n",
    "                eps=self.params.scheduler.eps,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.scheduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _step_scheduler(\n",
    "        self,\n",
    "        scheduler: Union[\n",
    "            lr_scheduler.ReduceLROnPlateau,\n",
    "        ],\n",
    "        avg_val_loss,\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.shceduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _evaluate(self, y_true: np.array, y_pred: np.array):\n",
    "        score = RMSE(y_true, y_pred)\n",
    "        print(f\"Score: {score:<.5f}\")\n",
    "\n",
    "\n",
    "class TrainRunner(BaseRunner):\n",
    "    def _train_batch(self, train_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        # scores = AverageMeter()\n",
    "        model.train()\n",
    "        start = end = time.time()\n",
    "        for step, image_label_dict in enumerate(train_loader):\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            y_preds = model(images)\n",
    "            loss = criterion(y_preds.squeeze(), labels.float())\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            grad_norm = nn.utils.clip_grad_norm_(\n",
    "                model.parameters(), self.params.max_grad_norm\n",
    "            )\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "        return losses.avg\n",
    "\n",
    "    def _valid_batch(self, valid_loader, model, criterion):\n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        # scores = AverageMeter()\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        start = end = time.time()\n",
    "        for step, image_label_dict in enumerate(valid_loader):\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            loss = criterion(y_preds.squeeze(), labels.float())\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "        predictions = np.concatenate(preds)\n",
    "        return losses.avg, predictions\n",
    "\n",
    "    def _train(self, train: pd.DataFrame, n_fold: int):\n",
    "        print(f\"fold: {n_fold}\")\n",
    "\n",
    "        trn_idx = train[train[\"fold\"] != n_fold].index\n",
    "        val_idx = train[train[\"fold\"] == n_fold].index\n",
    "        train_folds = train.loc[trn_idx].reset_index(drop=True)\n",
    "        valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "        train_dataset = AtmaDataset(\n",
    "            train_folds,\n",
    "            is_train=True,\n",
    "#             transform=get_transforms(self.params, data=\"train\"),\n",
    "        )\n",
    "        valid_dataset = AtmaDataset(\n",
    "            valid_folds,\n",
    "            is_train=False,\n",
    "#             transform=get_transforms(self.params, data=\"valid\"),\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        model = build_model(pretrained=self.cfg.params.pretrained)\n",
    "        model.to(self.cfg.basic.device)\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=self.params.optimizer.lr,\n",
    "            weight_decay=self.params.optimizer.weight_decay,\n",
    "            amsgrad=self.params.optimizer.amsgrad,\n",
    "        )\n",
    "        scheduler = self._get_scheduler(optimizer)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        best_score = np.inf\n",
    "        # best_loss = np.inf\n",
    "        for epoch in range(self.params.epochs):\n",
    "            start_time = time.time()\n",
    "\n",
    "            avg_loss = self._train_batch(\n",
    "                train_loader, model, criterion, optimizer, scheduler, epoch\n",
    "            )\n",
    "            avg_val_loss, preds = self._valid_batch(valid_loader, model, criterion)\n",
    "            valid_labels = valid_folds[\"target\"].values\n",
    "            scheduler = self._step_scheduler(scheduler, avg_val_loss)\n",
    "            score = RMSE(valid_labels, preds)\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "            )\n",
    "            print(f\"Epoch {epoch+1} - RMSE: {score}\")\n",
    "            if best_score > score:\n",
    "                best_score = score\n",
    "                torch.save(\n",
    "                    {\"model\": model.state_dict(), \"preds\": preds},\n",
    "                    f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\",\n",
    "                )\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - Best Score: {best_score:.4f}\"\n",
    "            )\n",
    "\n",
    "        check_point: Dict[str, Union[OrderedDict, torch.Tensor]] = torch.load(\n",
    "            f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\"\n",
    "        )\n",
    "        valid_folds[\"preds\"] = check_point[\"preds\"]\n",
    "        return valid_folds\n",
    "\n",
    "    def run_cv(self, train: pd.DataFrame) -> None:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for n_fold in range(self.cfg.kfold.number):\n",
    "            _oof_df = self._train(train, n_fold)\n",
    "            print(f\"========== fold: {n_fold} result ==========\")\n",
    "            self._evaluate(_oof_df[\"target\"], _oof_df[\"preds\"])\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "        print(\"========== CV ==========\")\n",
    "        self._evaluate(oof_df[\"target\"], oof_df[\"preds\"])\n",
    "        Jbl.save(oof_df, f\"{OutputPath.model}/oof_df_{self.cfg.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9c6ec55-378b-402c-8f5b-00172c78fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceRunner(BaseRunner):\n",
    "    def _test_batch(self, test_loader, model):\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for step, image_label_dict in enumerate(test_loader):\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "        predictions = np.concatenate(preds)\n",
    "        return predictions\n",
    "\n",
    "    def _test(self, test: pd.DataFrame, n_fold: int):\n",
    "        print(f\"fold: {n_fold}\")\n",
    "        test_dataset = AtmaDataset(\n",
    "            test,\n",
    "            is_train=False,\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.params.test_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        model = build_model(pretrained=self.cfg.params.pretrained)\n",
    "        model_state = torch.load(f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\")[\"model\"]\n",
    "        model.load_state_dict(model_state)\n",
    "        model.to(self.cfg.basic.device)\n",
    "        preds = self._test_batch(test_loader, model)\n",
    "        return preds\n",
    "    \n",
    "    def _submit(self, preds: np.array) -> None:\n",
    "        df_sub = load_csv(input_path.sub)\n",
    "        df_sub = df_sub.assign(target=preds)\n",
    "        path = f\"{OutputPath.submission}/submission_{self.cfg.basic.run_name}.csv\"\n",
    "        df_sub.to_csv(path, index=False)\n",
    "        print(\"submission.csv created\")\n",
    "\n",
    "    def run_cv(self, test: pd.DataFrame) -> None:\n",
    "        oof_df = pd.DataFrame()\n",
    "        preds: List[np.array] = []\n",
    "        for n_fold in range(self.cfg.kfold.number):\n",
    "            preds_fold = self._test(test, n_fold)\n",
    "            preds.append(preds_fold)\n",
    "        Jbl.save(preds, f\"{OutputPath.model}/preds_test_{self.cfg.basic.run_name}.jbl\")\n",
    "        \n",
    "        preds_mean = np.concatenate(preds, axis=1).mean(axis=1)\n",
    "        self._submit(preds_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eae1cb89-4ee0-4293-b935-888a14f628da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed()\n",
    "input_path = InputPath()\n",
    "model_config = ModelConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c99fafc2-2ace-488f-b2a3-1f6f3297af69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3937, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>sorting_date</th>\n",
       "      <th>art_series_id</th>\n",
       "      <th>target</th>\n",
       "      <th>object_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002bff09b09998d0be65</td>\n",
       "      <td>1631</td>\n",
       "      <td>509357f67692a6a45626</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/photos/002bff09b09998d0be65.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00309fb1ef05416f9c1f</td>\n",
       "      <td>1900</td>\n",
       "      <td>7987b47bbe5dc3039179</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/00309fb1ef05416f9c1f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003a1562e97f79ba96dc</td>\n",
       "      <td>1834</td>\n",
       "      <td>ded7c3c9636708e5b14c</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/003a1562e97f79ba96dc.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              object_id  sorting_date         art_series_id  target  \\\n",
       "0  002bff09b09998d0be65          1631  509357f67692a6a45626       1   \n",
       "1  00309fb1ef05416f9c1f          1900  7987b47bbe5dc3039179       3   \n",
       "2  003a1562e97f79ba96dc          1834  ded7c3c9636708e5b14c       3   \n",
       "\n",
       "                                object_path  \n",
       "0  ../input/photos/002bff09b09998d0be65.jpg  \n",
       "1  ../input/photos/00309fb1ef05416f9c1f.jpg  \n",
       "2  ../input/photos/003a1562e97f79ba96dc.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = load_csv(input_path.train)\n",
    "train = train.assign(object_path = train[\"object_id\"].apply(lambda x: to_img_path(input_path.photos_prefix, x)))\n",
    "print(train.shape)\n",
    "display(train.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8796a89d-9fce-49b6-8d53-3c315b65722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 - [0 1 2 3 4]~[3928 3930 3933 3934 3935]\t[ 8 14 16 19 21]~[3922 3929 3931 3932 3936]\n",
      "fold: 1 - [0 1 2 4 5]~[3931 3932 3933 3934 3936]\t[ 3  9 20 23 24]~[3899 3907 3912 3925 3935]\n",
      "fold: 2 - [0 1 2 3 5]~[3931 3932 3934 3935 3936]\t[ 4  6 10 11 12]~[3913 3915 3924 3927 3933]\n",
      "fold: 3 - [2 3 4 5 6]~[3932 3933 3934 3935 3936]\t[ 0  1  7 17 29]~[3914 3916 3919 3923 3926]\n",
      "fold: 4 - [0 1 3 4 6]~[3931 3932 3933 3935 3936]\t[ 2  5 22 31 32]~[3909 3918 3928 3930 3934]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "fold target     \n",
       "0    0        95\n",
       "     1       180\n",
       "     2       302\n",
       "     3       211\n",
       "1    0        95\n",
       "     1       179\n",
       "     2       303\n",
       "     3       211\n",
       "2    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211\n",
       "3    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211\n",
       "4    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kf = generate_kf(model_config)\n",
    "if model_config.kfold.method.endswith(\"gkf\"):\n",
    "    kf_generator = kf.split(\n",
    "        train,\n",
    "        train[self.fe_cfg.column.target],\n",
    "        groups=train[self.kfold.columns],\n",
    "    )\n",
    "else:\n",
    "    kf_generator = kf.split(train, train[\"target\"])\n",
    "for fold_i, (tr_idx, val_idx) in enumerate(kf_generator):\n",
    "    print(\n",
    "        f\"fold: {fold_i} - {tr_idx[:5]}~{tr_idx[-5:]}\\t{val_idx[:5]}~{val_idx[-5:]}\"\n",
    "    )\n",
    "    train.loc[val_idx, \"fold\"] = fold_i\n",
    "train = train.assign(fold = train[\"fold\"].astype(int))\n",
    "if model_config.kfold.method == \"skf\":\n",
    "    display(train.groupby([\"fold\", \"target\"]).size().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0af2c78d-558e-491c-b0f4-1884e1f42273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "Epoch 1 - avg_train_loss: 1.1380  avg_val_loss: 0.9102  time: 23s\n",
      "Epoch 1 - RMSE: 0.9540415151897651\n",
      "Epoch 1 - Best Score: 0.9540\n",
      "Epoch 2 - avg_train_loss: 0.9536  avg_val_loss: 1.1754  time: 23s\n",
      "Epoch 2 - RMSE: 1.0841452185935734\n",
      "Epoch 2 - Best Score: 0.9540\n",
      "Epoch 3 - avg_train_loss: 0.9477  avg_val_loss: 0.8542  time: 23s\n",
      "Epoch 3 - RMSE: 0.9242206010332672\n",
      "Epoch 3 - Best Score: 0.9242\n",
      "Epoch 4 - avg_train_loss: 0.9398  avg_val_loss: 0.9576  time: 23s\n",
      "Epoch 4 - RMSE: 0.9785568615310627\n",
      "Epoch 4 - Best Score: 0.9242\n",
      "Epoch 5 - avg_train_loss: 0.9326  avg_val_loss: 0.9523  time: 23s\n",
      "Epoch 5 - RMSE: 0.9758634933292687\n",
      "Epoch 5 - Best Score: 0.9242\n",
      "Epoch 6 - avg_train_loss: 0.9312  avg_val_loss: 0.9618  time: 23s\n",
      "Epoch 6 - RMSE: 0.9807174913859086\n",
      "Epoch 6 - Best Score: 0.9242\n",
      "Epoch 7 - avg_train_loss: 0.9136  avg_val_loss: 0.7999  time: 23s\n",
      "Epoch 7 - RMSE: 0.8943863231902787\n",
      "Epoch 7 - Best Score: 0.8944\n",
      "Epoch 8 - avg_train_loss: 0.9052  avg_val_loss: 0.9643  time: 23s\n",
      "Epoch 8 - RMSE: 0.9819661289968599\n",
      "Epoch 8 - Best Score: 0.8944\n",
      "Epoch 9 - avg_train_loss: 0.9000  avg_val_loss: 0.9292  time: 23s\n",
      "Epoch 9 - RMSE: 0.9639374101045911\n",
      "Epoch 9 - Best Score: 0.8944\n",
      "Epoch 10 - avg_train_loss: 0.8964  avg_val_loss: 0.8445  time: 23s\n",
      "Epoch 10 - RMSE: 0.9189797058656726\n",
      "Epoch 10 - Best Score: 0.8944\n",
      "Epoch 11 - avg_train_loss: 0.8940  avg_val_loss: 0.8061  time: 23s\n",
      "Epoch 11 - RMSE: 0.8978089677594272\n",
      "Epoch 11 - Best Score: 0.8944\n",
      "Epoch 12 - avg_train_loss: 0.8874  avg_val_loss: 0.8049  time: 23s\n",
      "Epoch 12 - RMSE: 0.8971403832788605\n",
      "Epoch 12 - Best Score: 0.8944\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 13 - avg_train_loss: 0.8858  avg_val_loss: 0.8835  time: 23s\n",
      "Epoch 13 - RMSE: 0.9399705716004079\n",
      "Epoch 13 - Best Score: 0.8944\n",
      "Epoch 14 - avg_train_loss: 0.8546  avg_val_loss: 0.7622  time: 23s\n",
      "Epoch 14 - RMSE: 0.8730625927095816\n",
      "Epoch 14 - Best Score: 0.8731\n",
      "Epoch 15 - avg_train_loss: 0.8499  avg_val_loss: 0.7749  time: 23s\n",
      "Epoch 15 - RMSE: 0.8802563416111022\n",
      "Epoch 15 - Best Score: 0.8731\n",
      "Epoch 16 - avg_train_loss: 0.8397  avg_val_loss: 0.7468  time: 23s\n",
      "Epoch 16 - RMSE: 0.8641957092299407\n",
      "Epoch 16 - Best Score: 0.8642\n",
      "Epoch 17 - avg_train_loss: 0.8466  avg_val_loss: 0.7494  time: 23s\n",
      "Epoch 17 - RMSE: 0.8656602930561816\n",
      "Epoch 17 - Best Score: 0.8642\n",
      "Epoch 18 - avg_train_loss: 0.8334  avg_val_loss: 0.7551  time: 23s\n",
      "Epoch 18 - RMSE: 0.8689792451047541\n",
      "Epoch 18 - Best Score: 0.8642\n",
      "Epoch 19 - avg_train_loss: 0.8240  avg_val_loss: 0.7605  time: 23s\n",
      "Epoch 19 - RMSE: 0.8720503108987655\n",
      "Epoch 19 - Best Score: 0.8642\n",
      "Epoch 20 - avg_train_loss: 0.8285  avg_val_loss: 0.7460  time: 23s\n",
      "Epoch 20 - RMSE: 0.8637206180863995\n",
      "Epoch 20 - Best Score: 0.8637\n",
      "Epoch 21 - avg_train_loss: 0.8450  avg_val_loss: 0.7481  time: 23s\n",
      "Epoch 21 - RMSE: 0.8649132481355302\n",
      "Epoch 21 - Best Score: 0.8637\n",
      "Epoch 22 - avg_train_loss: 0.8239  avg_val_loss: 0.7376  time: 24s\n",
      "Epoch 22 - RMSE: 0.8588600385416078\n",
      "Epoch 22 - Best Score: 0.8589\n",
      "Epoch 23 - avg_train_loss: 0.8237  avg_val_loss: 0.7450  time: 23s\n",
      "Epoch 23 - RMSE: 0.8631096189538199\n",
      "Epoch 23 - Best Score: 0.8589\n",
      "Epoch 24 - avg_train_loss: 0.8253  avg_val_loss: 0.7380  time: 23s\n",
      "Epoch 24 - RMSE: 0.8590712337786327\n",
      "Epoch 24 - Best Score: 0.8589\n",
      "Epoch 25 - avg_train_loss: 0.8146  avg_val_loss: 0.7250  time: 23s\n",
      "Epoch 25 - RMSE: 0.8514404842783575\n",
      "Epoch 25 - Best Score: 0.8514\n",
      "Epoch 26 - avg_train_loss: 0.8259  avg_val_loss: 0.7310  time: 23s\n",
      "Epoch 26 - RMSE: 0.854959131095189\n",
      "Epoch 26 - Best Score: 0.8514\n",
      "Epoch 27 - avg_train_loss: 0.8304  avg_val_loss: 0.7262  time: 23s\n",
      "Epoch 27 - RMSE: 0.8521666406840269\n",
      "Epoch 27 - Best Score: 0.8514\n",
      "Epoch 28 - avg_train_loss: 0.8349  avg_val_loss: 0.7250  time: 23s\n",
      "Epoch 28 - RMSE: 0.8514442586618917\n",
      "Epoch 28 - Best Score: 0.8514\n",
      "Epoch 29 - avg_train_loss: 0.8200  avg_val_loss: 0.7342  time: 23s\n",
      "Epoch 29 - RMSE: 0.8568334404455871\n",
      "Epoch 29 - Best Score: 0.8514\n",
      "Epoch 30 - avg_train_loss: 0.8152  avg_val_loss: 0.7459  time: 23s\n",
      "Epoch 30 - RMSE: 0.8636795603807267\n",
      "Epoch 30 - Best Score: 0.8514\n",
      "========== fold: 0 result ==========\n",
      "Score: 0.85144\n",
      "fold: 1\n",
      "Epoch 1 - avg_train_loss: 1.1330  avg_val_loss: 0.9971  time: 23s\n",
      "Epoch 1 - RMSE: 0.9985425869646631\n",
      "Epoch 1 - Best Score: 0.9985\n",
      "Epoch 2 - avg_train_loss: 0.9460  avg_val_loss: 0.9059  time: 23s\n",
      "Epoch 2 - RMSE: 0.9517757250007879\n",
      "Epoch 2 - Best Score: 0.9518\n",
      "Epoch 3 - avg_train_loss: 0.9275  avg_val_loss: 0.8633  time: 23s\n",
      "Epoch 3 - RMSE: 0.9291257282713139\n",
      "Epoch 3 - Best Score: 0.9291\n",
      "Epoch 4 - avg_train_loss: 0.9623  avg_val_loss: 1.0448  time: 23s\n",
      "Epoch 4 - RMSE: 1.022131914673164\n",
      "Epoch 4 - Best Score: 0.9291\n",
      "Epoch 5 - avg_train_loss: 0.9134  avg_val_loss: 0.8830  time: 23s\n",
      "Epoch 5 - RMSE: 0.9397001734471204\n",
      "Epoch 5 - Best Score: 0.9291\n",
      "Epoch 6 - avg_train_loss: 0.9106  avg_val_loss: 0.8658  time: 23s\n",
      "Epoch 6 - RMSE: 0.9304572847305457\n",
      "Epoch 6 - Best Score: 0.9291\n",
      "Epoch 7 - avg_train_loss: 0.9071  avg_val_loss: 0.8473  time: 23s\n",
      "Epoch 7 - RMSE: 0.920481494787731\n",
      "Epoch 7 - Best Score: 0.9205\n",
      "Epoch 8 - avg_train_loss: 0.8843  avg_val_loss: 0.9272  time: 23s\n",
      "Epoch 8 - RMSE: 0.9629352061810206\n",
      "Epoch 8 - Best Score: 0.9205\n",
      "Epoch 9 - avg_train_loss: 0.8984  avg_val_loss: 0.8179  time: 23s\n",
      "Epoch 9 - RMSE: 0.9043637883248627\n",
      "Epoch 9 - Best Score: 0.9044\n",
      "Epoch 10 - avg_train_loss: 0.8853  avg_val_loss: 0.8176  time: 23s\n",
      "Epoch 10 - RMSE: 0.9042038750091196\n",
      "Epoch 10 - Best Score: 0.9042\n",
      "Epoch 11 - avg_train_loss: 0.8964  avg_val_loss: 0.8127  time: 23s\n",
      "Epoch 11 - RMSE: 0.9014989182100511\n",
      "Epoch 11 - Best Score: 0.9015\n",
      "Epoch 12 - avg_train_loss: 0.8782  avg_val_loss: 0.7876  time: 23s\n",
      "Epoch 12 - RMSE: 0.8874769916302497\n",
      "Epoch 12 - Best Score: 0.8875\n",
      "Epoch 13 - avg_train_loss: 0.8879  avg_val_loss: 0.8102  time: 23s\n",
      "Epoch 13 - RMSE: 0.9001041603631732\n",
      "Epoch 13 - Best Score: 0.8875\n",
      "Epoch 14 - avg_train_loss: 0.8717  avg_val_loss: 0.8051  time: 23s\n",
      "Epoch 14 - RMSE: 0.8972944736624203\n",
      "Epoch 14 - Best Score: 0.8875\n",
      "Epoch 15 - avg_train_loss: 0.8834  avg_val_loss: 0.8425  time: 23s\n",
      "Epoch 15 - RMSE: 0.9178693013505264\n",
      "Epoch 15 - Best Score: 0.8875\n",
      "Epoch 16 - avg_train_loss: 0.8844  avg_val_loss: 0.8203  time: 23s\n",
      "Epoch 16 - RMSE: 0.9057195236976778\n",
      "Epoch 16 - Best Score: 0.8875\n",
      "Epoch 17 - avg_train_loss: 0.8766  avg_val_loss: 0.7977  time: 23s\n",
      "Epoch 17 - RMSE: 0.893150749091688\n",
      "Epoch 17 - Best Score: 0.8875\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 18 - avg_train_loss: 0.8618  avg_val_loss: 0.7924  time: 23s\n",
      "Epoch 18 - RMSE: 0.8901411575706435\n",
      "Epoch 18 - Best Score: 0.8875\n",
      "Epoch 19 - avg_train_loss: 0.8511  avg_val_loss: 0.7878  time: 23s\n",
      "Epoch 19 - RMSE: 0.88758874727881\n",
      "Epoch 19 - Best Score: 0.8875\n",
      "Epoch 20 - avg_train_loss: 0.8374  avg_val_loss: 0.7993  time: 23s\n",
      "Epoch 20 - RMSE: 0.8940162805130842\n",
      "Epoch 20 - Best Score: 0.8875\n",
      "Epoch 21 - avg_train_loss: 0.8345  avg_val_loss: 0.7994  time: 23s\n",
      "Epoch 21 - RMSE: 0.8941059884959548\n",
      "Epoch 21 - Best Score: 0.8875\n",
      "Epoch 22 - avg_train_loss: 0.8430  avg_val_loss: 0.7871  time: 23s\n",
      "Epoch 22 - RMSE: 0.8871854784732559\n",
      "Epoch 22 - Best Score: 0.8872\n",
      "Epoch 23 - avg_train_loss: 0.8259  avg_val_loss: 0.8029  time: 23s\n",
      "Epoch 23 - RMSE: 0.8960736797162765\n",
      "Epoch 23 - Best Score: 0.8872\n",
      "Epoch 24 - avg_train_loss: 0.8371  avg_val_loss: 0.7798  time: 23s\n",
      "Epoch 24 - RMSE: 0.883078209952483\n",
      "Epoch 24 - Best Score: 0.8831\n",
      "Epoch 25 - avg_train_loss: 0.8347  avg_val_loss: 0.7854  time: 23s\n",
      "Epoch 25 - RMSE: 0.8862420909690158\n",
      "Epoch 25 - Best Score: 0.8831\n",
      "Epoch 26 - avg_train_loss: 0.8325  avg_val_loss: 0.7803  time: 23s\n",
      "Epoch 26 - RMSE: 0.8833357432181896\n",
      "Epoch 26 - Best Score: 0.8831\n",
      "Epoch 27 - avg_train_loss: 0.8327  avg_val_loss: 0.7909  time: 23s\n",
      "Epoch 27 - RMSE: 0.8893353108150693\n",
      "Epoch 27 - Best Score: 0.8831\n",
      "Epoch 28 - avg_train_loss: 0.8238  avg_val_loss: 0.7733  time: 23s\n",
      "Epoch 28 - RMSE: 0.8793658854295205\n",
      "Epoch 28 - Best Score: 0.8794\n",
      "Epoch 29 - avg_train_loss: 0.8168  avg_val_loss: 0.7832  time: 23s\n",
      "Epoch 29 - RMSE: 0.8849766958491986\n",
      "Epoch 29 - Best Score: 0.8794\n",
      "Epoch 30 - avg_train_loss: 0.8210  avg_val_loss: 0.7804  time: 23s\n",
      "Epoch 30 - RMSE: 0.883428722831353\n",
      "Epoch 30 - Best Score: 0.8794\n",
      "========== fold: 1 result ==========\n",
      "Score: 0.87937\n",
      "fold: 2\n",
      "Epoch 1 - avg_train_loss: 1.2527  avg_val_loss: 0.9057  time: 23s\n",
      "Epoch 1 - RMSE: 0.951656745393345\n",
      "Epoch 1 - Best Score: 0.9517\n",
      "Epoch 2 - avg_train_loss: 0.9339  avg_val_loss: 1.0490  time: 23s\n",
      "Epoch 2 - RMSE: 1.0242129219386735\n",
      "Epoch 2 - Best Score: 0.9517\n",
      "Epoch 3 - avg_train_loss: 0.9469  avg_val_loss: 0.9098  time: 23s\n",
      "Epoch 3 - RMSE: 0.9538200721867123\n",
      "Epoch 3 - Best Score: 0.9517\n",
      "Epoch 4 - avg_train_loss: 0.9460  avg_val_loss: 0.8575  time: 23s\n",
      "Epoch 4 - RMSE: 0.9260003947251142\n",
      "Epoch 4 - Best Score: 0.9260\n",
      "Epoch 5 - avg_train_loss: 0.9200  avg_val_loss: 0.9019  time: 23s\n",
      "Epoch 5 - RMSE: 0.949687181931071\n",
      "Epoch 5 - Best Score: 0.9260\n",
      "Epoch 6 - avg_train_loss: 0.9182  avg_val_loss: 0.8180  time: 23s\n",
      "Epoch 6 - RMSE: 0.904442054022248\n",
      "Epoch 6 - Best Score: 0.9044\n",
      "Epoch 7 - avg_train_loss: 0.8976  avg_val_loss: 0.9028  time: 23s\n",
      "Epoch 7 - RMSE: 0.9501322430023396\n",
      "Epoch 7 - Best Score: 0.9044\n",
      "Epoch 8 - avg_train_loss: 0.9009  avg_val_loss: 0.8239  time: 23s\n",
      "Epoch 8 - RMSE: 0.907669698141627\n",
      "Epoch 8 - Best Score: 0.9044\n",
      "Epoch 9 - avg_train_loss: 0.9156  avg_val_loss: 0.8628  time: 23s\n",
      "Epoch 9 - RMSE: 0.9288756285953295\n",
      "Epoch 9 - Best Score: 0.9044\n",
      "Epoch 10 - avg_train_loss: 0.8801  avg_val_loss: 0.8776  time: 23s\n",
      "Epoch 10 - RMSE: 0.9368269276462332\n",
      "Epoch 10 - Best Score: 0.9044\n",
      "Epoch 11 - avg_train_loss: 0.8885  avg_val_loss: 0.8375  time: 23s\n",
      "Epoch 11 - RMSE: 0.9151584340373561\n",
      "Epoch 11 - Best Score: 0.9044\n",
      "Epoch 12 - avg_train_loss: 0.8906  avg_val_loss: 0.7977  time: 23s\n",
      "Epoch 12 - RMSE: 0.8931511031200965\n",
      "Epoch 12 - Best Score: 0.8932\n",
      "Epoch 13 - avg_train_loss: 0.9003  avg_val_loss: 0.8060  time: 23s\n",
      "Epoch 13 - RMSE: 0.8977860783126603\n",
      "Epoch 13 - Best Score: 0.8932\n",
      "Epoch 14 - avg_train_loss: 0.8886  avg_val_loss: 0.8365  time: 23s\n",
      "Epoch 14 - RMSE: 0.9146026101347163\n",
      "Epoch 14 - Best Score: 0.8932\n",
      "Epoch 15 - avg_train_loss: 0.8711  avg_val_loss: 0.7933  time: 23s\n",
      "Epoch 15 - RMSE: 0.8906898765629846\n",
      "Epoch 15 - Best Score: 0.8907\n",
      "Epoch 16 - avg_train_loss: 0.8938  avg_val_loss: 0.8239  time: 23s\n",
      "Epoch 16 - RMSE: 0.907709386878844\n",
      "Epoch 16 - Best Score: 0.8907\n",
      "Epoch 17 - avg_train_loss: 0.8863  avg_val_loss: 0.8179  time: 23s\n",
      "Epoch 17 - RMSE: 0.9043999089182007\n",
      "Epoch 17 - Best Score: 0.8907\n",
      "Epoch 18 - avg_train_loss: 0.8720  avg_val_loss: 0.7795  time: 23s\n",
      "Epoch 18 - RMSE: 0.8828768189779752\n",
      "Epoch 18 - Best Score: 0.8829\n",
      "Epoch 19 - avg_train_loss: 0.8596  avg_val_loss: 0.7717  time: 23s\n",
      "Epoch 19 - RMSE: 0.8784487908745463\n",
      "Epoch 19 - Best Score: 0.8784\n",
      "Epoch 20 - avg_train_loss: 0.8657  avg_val_loss: 0.8071  time: 23s\n",
      "Epoch 20 - RMSE: 0.8983714676761398\n",
      "Epoch 20 - Best Score: 0.8784\n",
      "Epoch 21 - avg_train_loss: 0.8515  avg_val_loss: 1.0088  time: 23s\n",
      "Epoch 21 - RMSE: 1.0043849459060394\n",
      "Epoch 21 - Best Score: 0.8784\n",
      "Epoch 22 - avg_train_loss: 0.8426  avg_val_loss: 0.8118  time: 23s\n",
      "Epoch 22 - RMSE: 0.9010066510541577\n",
      "Epoch 22 - Best Score: 0.8784\n",
      "Epoch 23 - avg_train_loss: 0.8660  avg_val_loss: 0.8645  time: 23s\n",
      "Epoch 23 - RMSE: 0.9298037340771278\n",
      "Epoch 23 - Best Score: 0.8784\n",
      "Epoch 24 - avg_train_loss: 0.8446  avg_val_loss: 1.0973  time: 23s\n",
      "Epoch 24 - RMSE: 1.0474992658465505\n",
      "Epoch 24 - Best Score: 0.8784\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 25 - avg_train_loss: 0.8491  avg_val_loss: 0.7791  time: 23s\n",
      "Epoch 25 - RMSE: 0.8826453931770666\n",
      "Epoch 25 - Best Score: 0.8784\n",
      "Epoch 26 - avg_train_loss: 0.8063  avg_val_loss: 0.7512  time: 23s\n",
      "Epoch 26 - RMSE: 0.8666919972972457\n",
      "Epoch 26 - Best Score: 0.8667\n",
      "Epoch 27 - avg_train_loss: 0.8140  avg_val_loss: 0.7497  time: 23s\n",
      "Epoch 27 - RMSE: 0.8658315109251162\n",
      "Epoch 27 - Best Score: 0.8658\n",
      "Epoch 28 - avg_train_loss: 0.8103  avg_val_loss: 0.7552  time: 23s\n",
      "Epoch 28 - RMSE: 0.8690377632973927\n",
      "Epoch 28 - Best Score: 0.8658\n",
      "Epoch 29 - avg_train_loss: 0.7962  avg_val_loss: 0.7511  time: 23s\n",
      "Epoch 29 - RMSE: 0.8666845174677451\n",
      "Epoch 29 - Best Score: 0.8658\n",
      "Epoch 30 - avg_train_loss: 0.7891  avg_val_loss: 0.7338  time: 23s\n",
      "Epoch 30 - RMSE: 0.8566383880166495\n",
      "Epoch 30 - Best Score: 0.8566\n",
      "========== fold: 2 result ==========\n",
      "Score: 0.85664\n",
      "fold: 3\n",
      "Epoch 1 - avg_train_loss: 1.3575  avg_val_loss: 0.8680  time: 23s\n",
      "Epoch 1 - RMSE: 0.931655985859218\n",
      "Epoch 1 - Best Score: 0.9317\n",
      "Epoch 2 - avg_train_loss: 0.9533  avg_val_loss: 0.9227  time: 23s\n",
      "Epoch 2 - RMSE: 0.9605663374928123\n",
      "Epoch 2 - Best Score: 0.9317\n",
      "Epoch 3 - avg_train_loss: 0.9564  avg_val_loss: 0.9353  time: 23s\n",
      "Epoch 3 - RMSE: 0.9670845370752003\n",
      "Epoch 3 - Best Score: 0.9317\n",
      "Epoch 4 - avg_train_loss: 0.9161  avg_val_loss: 0.9504  time: 23s\n",
      "Epoch 4 - RMSE: 0.974905156924623\n",
      "Epoch 4 - Best Score: 0.9317\n",
      "Epoch 5 - avg_train_loss: 0.9168  avg_val_loss: 0.8903  time: 23s\n",
      "Epoch 5 - RMSE: 0.9435799705960127\n",
      "Epoch 5 - Best Score: 0.9317\n",
      "Epoch 6 - avg_train_loss: 0.9124  avg_val_loss: 0.8608  time: 23s\n",
      "Epoch 6 - RMSE: 0.9277680965423593\n",
      "Epoch 6 - Best Score: 0.9278\n",
      "Epoch 7 - avg_train_loss: 0.9259  avg_val_loss: 0.8511  time: 23s\n",
      "Epoch 7 - RMSE: 0.922559692877932\n",
      "Epoch 7 - Best Score: 0.9226\n",
      "Epoch 8 - avg_train_loss: 0.9242  avg_val_loss: 0.8282  time: 23s\n",
      "Epoch 8 - RMSE: 0.9100603765337457\n",
      "Epoch 8 - Best Score: 0.9101\n",
      "Epoch 9 - avg_train_loss: 0.9024  avg_val_loss: 0.8019  time: 23s\n",
      "Epoch 9 - RMSE: 0.8954813407566242\n",
      "Epoch 9 - Best Score: 0.8955\n",
      "Epoch 10 - avg_train_loss: 0.9058  avg_val_loss: 0.8612  time: 23s\n",
      "Epoch 10 - RMSE: 0.9280339211171085\n",
      "Epoch 10 - Best Score: 0.8955\n",
      "Epoch 11 - avg_train_loss: 0.9063  avg_val_loss: 0.8153  time: 23s\n",
      "Epoch 11 - RMSE: 0.9029541765756066\n",
      "Epoch 11 - Best Score: 0.8955\n",
      "Epoch 12 - avg_train_loss: 0.9064  avg_val_loss: 0.8589  time: 23s\n",
      "Epoch 12 - RMSE: 0.9267625443046195\n",
      "Epoch 12 - Best Score: 0.8955\n",
      "Epoch 13 - avg_train_loss: 0.8715  avg_val_loss: 0.8445  time: 23s\n",
      "Epoch 13 - RMSE: 0.91898056252744\n",
      "Epoch 13 - Best Score: 0.8955\n",
      "Epoch 14 - avg_train_loss: 0.8768  avg_val_loss: 0.8161  time: 23s\n",
      "Epoch 14 - RMSE: 0.9034029266712174\n",
      "Epoch 14 - Best Score: 0.8955\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 15 - avg_train_loss: 0.8821  avg_val_loss: 0.8361  time: 23s\n",
      "Epoch 15 - RMSE: 0.9143766017821888\n",
      "Epoch 15 - Best Score: 0.8955\n",
      "Epoch 16 - avg_train_loss: 0.8489  avg_val_loss: 0.7766  time: 23s\n",
      "Epoch 16 - RMSE: 0.8812765183977507\n",
      "Epoch 16 - Best Score: 0.8813\n",
      "Epoch 17 - avg_train_loss: 0.8353  avg_val_loss: 0.7686  time: 23s\n",
      "Epoch 17 - RMSE: 0.8766776323103839\n",
      "Epoch 17 - Best Score: 0.8767\n",
      "Epoch 18 - avg_train_loss: 0.8433  avg_val_loss: 0.7815  time: 23s\n",
      "Epoch 18 - RMSE: 0.8840424262877548\n",
      "Epoch 18 - Best Score: 0.8767\n",
      "Epoch 19 - avg_train_loss: 0.8452  avg_val_loss: 0.7694  time: 23s\n",
      "Epoch 19 - RMSE: 0.8771328227013945\n",
      "Epoch 19 - Best Score: 0.8767\n",
      "Epoch 20 - avg_train_loss: 0.8311  avg_val_loss: 0.7794  time: 23s\n",
      "Epoch 20 - RMSE: 0.8828597473530284\n",
      "Epoch 20 - Best Score: 0.8767\n",
      "Epoch 21 - avg_train_loss: 0.8426  avg_val_loss: 0.7929  time: 23s\n",
      "Epoch 21 - RMSE: 0.8904729976837327\n",
      "Epoch 21 - Best Score: 0.8767\n",
      "Epoch 22 - avg_train_loss: 0.8323  avg_val_loss: 0.7777  time: 23s\n",
      "Epoch 22 - RMSE: 0.8818466823041444\n",
      "Epoch 22 - Best Score: 0.8767\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 23 - avg_train_loss: 0.8178  avg_val_loss: 0.7872  time: 23s\n",
      "Epoch 23 - RMSE: 0.8872549526000296\n",
      "Epoch 23 - Best Score: 0.8767\n",
      "Epoch 24 - avg_train_loss: 0.8267  avg_val_loss: 0.7777  time: 23s\n",
      "Epoch 24 - RMSE: 0.8818643083263364\n",
      "Epoch 24 - Best Score: 0.8767\n",
      "Epoch 25 - avg_train_loss: 0.8122  avg_val_loss: 0.7815  time: 23s\n",
      "Epoch 25 - RMSE: 0.8840031895148779\n",
      "Epoch 25 - Best Score: 0.8767\n",
      "Epoch 26 - avg_train_loss: 0.8220  avg_val_loss: 0.7769  time: 23s\n",
      "Epoch 26 - RMSE: 0.88143014414261\n",
      "Epoch 26 - Best Score: 0.8767\n",
      "Epoch 27 - avg_train_loss: 0.8205  avg_val_loss: 0.7777  time: 24s\n",
      "Epoch 27 - RMSE: 0.8818923987457105\n",
      "Epoch 27 - Best Score: 0.8767\n",
      "Epoch 28 - avg_train_loss: 0.8181  avg_val_loss: 0.7763  time: 23s\n",
      "Epoch 28 - RMSE: 0.8810727271060342\n",
      "Epoch 28 - Best Score: 0.8767\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch 29 - avg_train_loss: 0.8207  avg_val_loss: 0.7803  time: 23s\n",
      "Epoch 29 - RMSE: 0.8833364671052409\n",
      "Epoch 29 - Best Score: 0.8767\n",
      "Epoch 30 - avg_train_loss: 0.8053  avg_val_loss: 0.7768  time: 23s\n",
      "Epoch 30 - RMSE: 0.881379659749749\n",
      "Epoch 30 - Best Score: 0.8767\n",
      "========== fold: 3 result ==========\n",
      "Score: 0.87668\n",
      "fold: 4\n",
      "Epoch 1 - avg_train_loss: 1.2518  avg_val_loss: 0.8778  time: 23s\n",
      "Epoch 1 - RMSE: 0.93693190833399\n",
      "Epoch 1 - Best Score: 0.9369\n",
      "Epoch 2 - avg_train_loss: 0.9274  avg_val_loss: 0.8662  time: 23s\n",
      "Epoch 2 - RMSE: 0.9307249707150057\n",
      "Epoch 2 - Best Score: 0.9307\n",
      "Epoch 3 - avg_train_loss: 0.9208  avg_val_loss: 0.8872  time: 23s\n",
      "Epoch 3 - RMSE: 0.9419309538111261\n",
      "Epoch 3 - Best Score: 0.9307\n",
      "Epoch 4 - avg_train_loss: 0.9030  avg_val_loss: 0.9470  time: 23s\n",
      "Epoch 4 - RMSE: 0.9731539741397623\n",
      "Epoch 4 - Best Score: 0.9307\n",
      "Epoch 5 - avg_train_loss: 0.9232  avg_val_loss: 0.8450  time: 23s\n",
      "Epoch 5 - RMSE: 0.9192242371014745\n",
      "Epoch 5 - Best Score: 0.9192\n",
      "Epoch 6 - avg_train_loss: 0.9012  avg_val_loss: 0.8664  time: 23s\n",
      "Epoch 6 - RMSE: 0.9308112831412728\n",
      "Epoch 6 - Best Score: 0.9192\n",
      "Epoch 7 - avg_train_loss: 0.9072  avg_val_loss: 0.8680  time: 23s\n",
      "Epoch 7 - RMSE: 0.9316541435382906\n",
      "Epoch 7 - Best Score: 0.9192\n",
      "Epoch 8 - avg_train_loss: 0.9112  avg_val_loss: 0.8208  time: 23s\n",
      "Epoch 8 - RMSE: 0.9059565240840369\n",
      "Epoch 8 - Best Score: 0.9060\n",
      "Epoch 9 - avg_train_loss: 0.8970  avg_val_loss: 0.8472  time: 23s\n",
      "Epoch 9 - RMSE: 0.9204080664859359\n",
      "Epoch 9 - Best Score: 0.9060\n",
      "Epoch 10 - avg_train_loss: 0.9049  avg_val_loss: 0.8690  time: 23s\n",
      "Epoch 10 - RMSE: 0.932182710323029\n",
      "Epoch 10 - Best Score: 0.9060\n",
      "Epoch 11 - avg_train_loss: 0.8961  avg_val_loss: 0.9503  time: 23s\n",
      "Epoch 11 - RMSE: 0.9748427997552794\n",
      "Epoch 11 - Best Score: 0.9060\n",
      "Epoch 12 - avg_train_loss: 0.8987  avg_val_loss: 0.7789  time: 23s\n",
      "Epoch 12 - RMSE: 0.8825268807957608\n",
      "Epoch 12 - Best Score: 0.8825\n",
      "Epoch 13 - avg_train_loss: 0.8860  avg_val_loss: 0.8512  time: 23s\n",
      "Epoch 13 - RMSE: 0.9225906178279425\n",
      "Epoch 13 - Best Score: 0.8825\n",
      "Epoch 14 - avg_train_loss: 0.8847  avg_val_loss: 0.8157  time: 23s\n",
      "Epoch 14 - RMSE: 0.903157902677297\n",
      "Epoch 14 - Best Score: 0.8825\n",
      "Epoch 15 - avg_train_loss: 0.9016  avg_val_loss: 0.7830  time: 23s\n",
      "Epoch 15 - RMSE: 0.8848819735402692\n",
      "Epoch 15 - Best Score: 0.8825\n",
      "Epoch 16 - avg_train_loss: 0.8637  avg_val_loss: 0.8949  time: 23s\n",
      "Epoch 16 - RMSE: 0.9460098302333908\n",
      "Epoch 16 - Best Score: 0.8825\n",
      "Epoch 17 - avg_train_loss: 0.8778  avg_val_loss: 0.8313  time: 23s\n",
      "Epoch 17 - RMSE: 0.9117807548753326\n",
      "Epoch 17 - Best Score: 0.8825\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 18 - avg_train_loss: 0.8770  avg_val_loss: 0.8359  time: 23s\n",
      "Epoch 18 - RMSE: 0.9142493759597716\n",
      "Epoch 18 - Best Score: 0.8825\n",
      "Epoch 19 - avg_train_loss: 0.8493  avg_val_loss: 0.7729  time: 23s\n",
      "Epoch 19 - RMSE: 0.8791377756892913\n",
      "Epoch 19 - Best Score: 0.8791\n",
      "Epoch 20 - avg_train_loss: 0.8444  avg_val_loss: 0.7957  time: 23s\n",
      "Epoch 20 - RMSE: 0.8920213297607817\n",
      "Epoch 20 - Best Score: 0.8791\n",
      "Epoch 21 - avg_train_loss: 0.8376  avg_val_loss: 0.7619  time: 23s\n",
      "Epoch 21 - RMSE: 0.8728565401749317\n",
      "Epoch 21 - Best Score: 0.8729\n",
      "Epoch 22 - avg_train_loss: 0.8466  avg_val_loss: 0.7683  time: 23s\n",
      "Epoch 22 - RMSE: 0.8765454644400147\n",
      "Epoch 22 - Best Score: 0.8729\n",
      "Epoch 23 - avg_train_loss: 0.8424  avg_val_loss: 0.7709  time: 23s\n",
      "Epoch 23 - RMSE: 0.8779836174449306\n",
      "Epoch 23 - Best Score: 0.8729\n",
      "Epoch 24 - avg_train_loss: 0.8347  avg_val_loss: 0.7777  time: 23s\n",
      "Epoch 24 - RMSE: 0.881875782676264\n",
      "Epoch 24 - Best Score: 0.8729\n",
      "Epoch 25 - avg_train_loss: 0.8262  avg_val_loss: 0.7818  time: 23s\n",
      "Epoch 25 - RMSE: 0.8841721984235853\n",
      "Epoch 25 - Best Score: 0.8729\n",
      "Epoch 26 - avg_train_loss: 0.8277  avg_val_loss: 0.7696  time: 23s\n",
      "Epoch 26 - RMSE: 0.8772413110812193\n",
      "Epoch 26 - Best Score: 0.8729\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 27 - avg_train_loss: 0.8477  avg_val_loss: 0.7712  time: 23s\n",
      "Epoch 27 - RMSE: 0.8781874076719152\n",
      "Epoch 27 - Best Score: 0.8729\n",
      "Epoch 28 - avg_train_loss: 0.8267  avg_val_loss: 0.7725  time: 23s\n",
      "Epoch 28 - RMSE: 0.8789219690969335\n",
      "Epoch 28 - Best Score: 0.8729\n",
      "Epoch 29 - avg_train_loss: 0.8371  avg_val_loss: 0.7738  time: 23s\n",
      "Epoch 29 - RMSE: 0.8796868734118535\n",
      "Epoch 29 - Best Score: 0.8729\n",
      "Epoch 30 - avg_train_loss: 0.8238  avg_val_loss: 0.7756  time: 23s\n",
      "Epoch 30 - RMSE: 0.8806553158289335\n",
      "Epoch 30 - Best Score: 0.8729\n",
      "========== fold: 4 result ==========\n",
      "Score: 0.87286\n",
      "========== CV ==========\n",
      "Score: 0.86747\n",
      "CPU times: user 5h 2min 46s, sys: 10min 2s, total: 5h 12min 49s\n",
      "Wall time: 58min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TrainRunner(model_config).run_cv(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ba9ba8b-317b-42a0-9a0b-c6bd8e07f462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>sorting_date</th>\n",
       "      <th>art_series_id</th>\n",
       "      <th>target</th>\n",
       "      <th>object_path</th>\n",
       "      <th>fold</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00bf812ffe8a62d45661</td>\n",
       "      <td>1720</td>\n",
       "      <td>3bfd41016d864e3fd8b5</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/00bf812ffe8a62d45661.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2.340764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0110115b8b6036d9ab3c</td>\n",
       "      <td>1741</td>\n",
       "      <td>baa4a20f0372d74dfc80</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/0110115b8b6036d9ab3c.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.828573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01273c00c46a84c50468</td>\n",
       "      <td>1757</td>\n",
       "      <td>51024cb4c6256ccce827</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/01273c00c46a84c50468.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.141364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0160840d9a4620b08fbd</td>\n",
       "      <td>1874</td>\n",
       "      <td>a56504999a8157a25d16</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/0160840d9a4620b08fbd.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2.495556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0169c493b09c8758a1b3</td>\n",
       "      <td>1734</td>\n",
       "      <td>550c62dd363fea62581c</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/0169c493b09c8758a1b3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.848377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>fe4d591332b08ab81361</td>\n",
       "      <td>1600</td>\n",
       "      <td>0782dfafa355acaf888c</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/photos/fe4d591332b08ab81361.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.542081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>fecae40c488e4c8c5ba5</td>\n",
       "      <td>1600</td>\n",
       "      <td>9ac00be75c55b1653a94</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/photos/fecae40c488e4c8c5ba5.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.754523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>ff37540e22e1ef455368</td>\n",
       "      <td>1765</td>\n",
       "      <td>9971eebf0f583a5e51da</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/ff37540e22e1ef455368.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2.019901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>ff9124278e0f7086738f</td>\n",
       "      <td>1630</td>\n",
       "      <td>b4d508f53d16f7bcaf55</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/photos/ff9124278e0f7086738f.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.683382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>ffd794b7b311b7b7fd92</td>\n",
       "      <td>1789</td>\n",
       "      <td>f030a01b480b18a27be2</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/ffd794b7b311b7b7fd92.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.984593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3937 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                object_id  sorting_date         art_series_id  target  \\\n",
       "0    00bf812ffe8a62d45661          1720  3bfd41016d864e3fd8b5       2   \n",
       "1    0110115b8b6036d9ab3c          1741  baa4a20f0372d74dfc80       2   \n",
       "2    01273c00c46a84c50468          1757  51024cb4c6256ccce827       2   \n",
       "3    0160840d9a4620b08fbd          1874  a56504999a8157a25d16       3   \n",
       "4    0169c493b09c8758a1b3          1734  550c62dd363fea62581c       2   \n",
       "..                    ...           ...                   ...     ...   \n",
       "782  fe4d591332b08ab81361          1600  0782dfafa355acaf888c       0   \n",
       "783  fecae40c488e4c8c5ba5          1600  9ac00be75c55b1653a94       0   \n",
       "784  ff37540e22e1ef455368          1765  9971eebf0f583a5e51da       2   \n",
       "785  ff9124278e0f7086738f          1630  b4d508f53d16f7bcaf55       1   \n",
       "786  ffd794b7b311b7b7fd92          1789  f030a01b480b18a27be2       2   \n",
       "\n",
       "                                  object_path  fold     preds  \n",
       "0    ../input/photos/00bf812ffe8a62d45661.jpg     0  2.340764  \n",
       "1    ../input/photos/0110115b8b6036d9ab3c.jpg     0  1.828573  \n",
       "2    ../input/photos/01273c00c46a84c50468.jpg     0  1.141364  \n",
       "3    ../input/photos/0160840d9a4620b08fbd.jpg     0  2.495556  \n",
       "4    ../input/photos/0169c493b09c8758a1b3.jpg     0  1.848377  \n",
       "..                                        ...   ...       ...  \n",
       "782  ../input/photos/fe4d591332b08ab81361.jpg     4  1.542081  \n",
       "783  ../input/photos/fecae40c488e4c8c5ba5.jpg     4  1.754523  \n",
       "784  ../input/photos/ff37540e22e1ef455368.jpg     4  2.019901  \n",
       "785  ../input/photos/ff9124278e0f7086738f.jpg     4  1.683382  \n",
       "786  ../input/photos/ffd794b7b311b7b7fd92.jpg     4  1.984593  \n",
       "\n",
       "[3937 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72e174df-3c50-4bae-a0be-dc59445ea40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")[\"preds\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e2e35b9-f7b8-4ea9-96e4-6053d8dc537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "fold: 1\n",
      "fold: 2\n",
      "fold: 3\n",
      "fold: 4\n",
      "submission.csv created\n"
     ]
    }
   ],
   "source": [
    "test = load_csv(input_path.test)\n",
    "test = test.assign(object_path = test[\"object_id\"].apply(lambda x: to_img_path(input_path.photos_prefix, x)))\n",
    "InferenceRunner(model_config).run_cv(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa73ab9-d584-426e-9bac-a21e3b86a54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a9074a-5044-4ae5-a622-79637a6e0c68",
   "metadata": {},
   "source": [
    "File Changed\n",
    "- base version: exp003\n",
    "- test time augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a08317bb-fa4d-45c8-9729-46910b084d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce6b088f-2dd0-471b-8d65-5474a0047688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InputPath:\n",
    "    _prefix: str = \"../input\"\n",
    "    train: str = f\"{_prefix}/train.csv\"\n",
    "    materials: str = f\"{_prefix}/materials.csv\"\n",
    "    techniques: str = f\"{_prefix}/techniques.csv\"\n",
    "    test: str = f\"{_prefix}/test.csv\"\n",
    "    sub: str = f\"{_prefix}/atmaCup#11_sample_submission.csv\"\n",
    "    photos_prefix: str = f\"{_prefix}/photos\"\n",
    "    photos: List[str] = field(default_factory=lambda: glob(f\"../input/photos/*.jpg\"))\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class OutputPath:\n",
    "    _prefix: str = \"../output/\"\n",
    "    model: str = f\"{_prefix}/model\"\n",
    "    submission: str = f\"{_prefix}/submission\"\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Basic:\n",
    "    run_name: str = \"exp004\"\n",
    "    is_debug: bool = False\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Kfold:\n",
    "    number: int = 5\n",
    "    method: str = \"skf\"\n",
    "    shuffle: bool = True\n",
    "    columns: List[str] = field(default_factory=lambda: [\"target\"])\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Adam:\n",
    "    name: str = \"Adam\"\n",
    "    lr: float = 1e-4\n",
    "    weight_decay: float = 0\n",
    "    amsgrad: bool = False\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class ReduceLROnPlateau:\n",
    "    name: str = \"ReduceLROnPlateau\"\n",
    "    mode: str = \"min\"\n",
    "    factor: float = 0.1\n",
    "    patience: int = 5\n",
    "    verbose: bool = True\n",
    "    eps: float = 1e-8\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Params:\n",
    "    batch_size: int = 64\n",
    "    test_batch_size: int = 256\n",
    "    epochs: int = 3 if Basic.is_debug else 30\n",
    "    image_size: int = 224\n",
    "    max_grad_norm: int = 1000\n",
    "    num_workers: int = 0\n",
    "    print_freq: int = 10000\n",
    "    target_size: int = 1\n",
    "    # Union[Adam]\n",
    "    optimizer: Adam = Adam()\n",
    "    # Union[CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau]\n",
    "    scheduler: ReduceLROnPlateau = ReduceLROnPlateau()\n",
    "    pretrained: bool = False\n",
    "    num_aug: int = 5\n",
    "    num_tta: int = 10\n",
    "        \n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    basic: Basic = Basic()\n",
    "    kfold: Kfold = Kfold()\n",
    "    params: Params = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72fec5d5-f634-46bc-9cb6-437c0f3b4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in os.listdir(OutputPath.model) if x.startswith(\"exp???_\"):\n",
    "#     os.remove(f\"{OutputPath.model}/{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e688a697-6d8e-40a5-89a3-56833b01cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_sessions = [x.split(\"_\")[0] for x in os.listdir(OutputPath.model) if x.endswith(\"_0.pth\")]\n",
    "assert Basic.run_name not in past_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b0b95d9-6d21-48a4-8ef9-d085e183e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class Jbl:\n",
    "    @staticmethod\n",
    "    def load(filepath: str) -> Any:\n",
    "        return joblib.load(filepath)\n",
    "\n",
    "    @staticmethod\n",
    "    def save(obj_: Any, filepath: str) -> None:\n",
    "        joblib.dump(obj_, filepath, compress=3)\n",
    "\n",
    "\n",
    "def RMSE(y: np.array, p: np.array) -> float:\n",
    "    return metrics.mean_squared_error(y, p) ** 0.5\n",
    "\n",
    "\n",
    "def fix_seed(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    \n",
    "def time_since(since: time.time, percent: float) -> str:\n",
    "    def as_minutes(s):\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return \"%dm %ds\" % (m, s)\n",
    "\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adac7d51-f744-4349-a639-7a6661370d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def to_img_path(photo_dir: str, object_id: str) -> str:\n",
    "    return os.path.join(photo_dir, f'{object_id}.jpg')\n",
    "\n",
    "def read_image(object_id: str):\n",
    "    return Image.open(to_img_path(object_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52cc936d-6003-4e02-ba1f-d42cf039cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_csv(path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "169f341c-c861-4c5d-918c-201017c494da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    GroupKFold,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    TimeSeriesSplit,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_kf(cfg: ModelConfig) -> Generator:\n",
    "    if cfg.kfold.method == \"kf\":\n",
    "        kf = KFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"skf\":\n",
    "        kf = StratifiedKFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"gkf\":\n",
    "        kf = GroupKFold(n_splits=cfg.kfold.number)\n",
    "    elif cfg.kfold.method == \"sgkf\":\n",
    "        kf = StratifiedGroupKFold(\n",
    "            n_splits=cfg.kfold.number, random_state=cfg.basic.seed\n",
    "        )\n",
    "    elif cfg.kfold.method == \"tskf\":\n",
    "        kf = TimeSeriesSplit(n_splits=cfg.kfold.number)\n",
    "    else:\n",
    "        raise ValueError(f\"{cfg.kfold.method} is not supported\")\n",
    "    return kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e1e049a-17be-4901-a59d-8d475c180753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "\n",
    "\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "class AtmaDataset(data.Dataset):\n",
    "    \"\"\"atmaCup用にデータ読み込み等を行なうデータ・セット\"\"\"\n",
    "    object_path_key = \"object_path\"\n",
    "    label_key = \"target\"\n",
    "\n",
    "    def __init__(self, meta_df: pd.DataFrame, is_train: bool = True) -> None:\n",
    "        self.is_train = is_train\n",
    "        self.meta_df = meta_df.reset_index(drop=True)\n",
    "        self.index_to_data = self.meta_df.to_dict(orient=\"index\")\n",
    "        \n",
    "        size = (ModelConfig.params.image_size, ModelConfig.params.image_size)\n",
    "        additional_items = (\n",
    "            [T.Resize(size)]\n",
    "            if not is_train\n",
    "            else [\n",
    "                T.RandomGrayscale(p=0.2),\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.ColorJitter(\n",
    "                    brightness=0.3,\n",
    "                    contrast=0.5,\n",
    "                    saturation=[0.8, 1.3],\n",
    "                    hue=[-0.05, 0.05],\n",
    "                ),\n",
    "                T.RandomResizedCrop(size),\n",
    "            ]\n",
    "        )\n",
    "        self.transformer = T.Compose(\n",
    "            [*additional_items, T.ToTensor(), T.Normalize(mean=IMG_MEAN, std=IMG_STD)]\n",
    "        )\n",
    "        \n",
    "        self._validate_meta_df(meta_df)\n",
    "\n",
    "    def __getitem__(self, index) -> Dict[str, Any]:\n",
    "        data = self.index_to_data[index]\n",
    "        obj_path, label = data.get(self.object_path_key), data.get(self.label_key, -1)\n",
    "        img = self.transformer(Image.open(obj_path))\n",
    "        return {\"image\": img, \"label\": label}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.meta_df)\n",
    "    \n",
    "    def _validate_meta_df(self, meta_df: pd.DataFrame) -> None:\n",
    "        for k in self.meta_keys:\n",
    "            if k not in meta_df:\n",
    "                raise ValueError(f\"meta df must have {k}\")\n",
    "                \n",
    "    @property\n",
    "    def meta_keys(self) -> List[str]:\n",
    "        retval = [self.object_path_key]\n",
    "        if self.is_train:\n",
    "            retval += [self.label_key]\n",
    "        return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb29cd98-7770-4f3e-813f-461679503034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from logging import Logger\n",
    "from typing import Dict, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def build_model(pretrained: bool = False):\n",
    "    model = models.resnet34(pretrained=pretrained)\n",
    "    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)    \n",
    "    return model\n",
    "\n",
    "\n",
    "class BaseRunner:\n",
    "    def __init__(self, cfg: ModelConfig):\n",
    "        self.cfg = cfg\n",
    "        self.params = cfg.params\n",
    "\n",
    "    def _get_scheduler(\n",
    "        self, optimizer: Union[optim.Adam]\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if self.params.scheduler.name == \"ReduceLROnPlateau\":\n",
    "            scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode=self.params.scheduler.mode,\n",
    "                factor=self.params.scheduler.factor,\n",
    "                patience=self.params.scheduler.patience,\n",
    "                verbose=self.params.scheduler.verbose,\n",
    "                eps=self.params.scheduler.eps,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.scheduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _step_scheduler(\n",
    "        self,\n",
    "        scheduler: Union[\n",
    "            lr_scheduler.ReduceLROnPlateau,\n",
    "        ],\n",
    "        avg_val_loss,\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.shceduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _evaluate(self, y_true: np.array, y_pred: np.array):\n",
    "        score = RMSE(y_true, y_pred)\n",
    "        print(f\"Score: {score:<.5f}\")\n",
    "\n",
    "\n",
    "class TrainRunner(BaseRunner):\n",
    "    def _train_batch(self, train_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        model.train()\n",
    "        start = end = time.time()\n",
    "        for step, image_label_dict in enumerate(train_loader):\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            y_preds = model(images)\n",
    "            loss = criterion(y_preds.squeeze(), labels.float())\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            grad_norm = nn.utils.clip_grad_norm_(\n",
    "                model.parameters(), self.params.max_grad_norm\n",
    "            )\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "        return losses.avg\n",
    "\n",
    "    def _valid_batch(self, valid_loader, model, criterion):\n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        start = end = time.time()\n",
    "        \n",
    "        for _, image_label_dict in enumerate(valid_loader):\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            loss = criterion(y_preds.squeeze(), labels.float())\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "        predictions = np.concatenate(preds)\n",
    "        return losses.avg, predictions\n",
    "\n",
    "    def _train(self, train: pd.DataFrame, n_fold: int):\n",
    "        print(f\"fold: {n_fold}\")\n",
    "        \n",
    "        is_tta_mode = self.params.num_tta > 0\n",
    "        num_times_tta = 1 if not is_tta_mode else self.params.num_tta\n",
    "\n",
    "        trn_idx = train[train[\"fold\"] != n_fold].index\n",
    "        val_idx = train[train[\"fold\"] == n_fold].index\n",
    "        train_folds = train.loc[trn_idx].reset_index(drop=True)\n",
    "        valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "        train_dataset = AtmaDataset(\n",
    "            train_folds,\n",
    "            is_train=True,\n",
    "#             transform=get_transforms(self.params, data=\"train\"),\n",
    "        )\n",
    "        valid_dataset = AtmaDataset(\n",
    "            valid_folds,\n",
    "            is_train=is_tta_mode,\n",
    "#             transform=get_transforms(self.params, data=\"valid\"),\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        model = build_model(pretrained=self.cfg.params.pretrained)\n",
    "        model.to(self.cfg.basic.device)\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=self.params.optimizer.lr,\n",
    "            weight_decay=self.params.optimizer.weight_decay,\n",
    "            amsgrad=self.params.optimizer.amsgrad,\n",
    "        )\n",
    "        scheduler = self._get_scheduler(optimizer)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        best_score = np.inf\n",
    "        for epoch in range(self.params.epochs):\n",
    "            start_time = time.time()\n",
    "\n",
    "            avg_loss = self._train_batch(\n",
    "                train_loader, model, criterion, optimizer, scheduler, epoch\n",
    "            )\n",
    "            avg_val_loss_list: List[float] = []\n",
    "            preds_list: List[np.array] = []\n",
    "            for _ in range(num_times_tta):\n",
    "                avg_val_loss, preds = self._valid_batch(valid_loader, model, criterion)\n",
    "                avg_val_loss_list.append(avg_val_loss)\n",
    "                preds_list.append(preds)\n",
    "            avg_val_loss = np.mean(avg_val_loss_list)\n",
    "            preds = np.concatenate(preds_list, axis=1).mean(axis=1)\n",
    "            valid_labels = valid_folds[\"target\"].values\n",
    "            scheduler = self._step_scheduler(scheduler, avg_val_loss)\n",
    "            score = RMSE(valid_labels, preds)\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "            )\n",
    "            print(f\"Epoch {epoch+1} - RMSE: {score}\")\n",
    "            if best_score > score:\n",
    "                best_score = score\n",
    "                torch.save(\n",
    "                    {\"model\": model.state_dict(), \"preds\": preds, \"score\": score},\n",
    "                    f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\",\n",
    "                )\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - Best Score: {best_score:.4f}\"\n",
    "            )\n",
    "\n",
    "        check_point: Dict[str, Union[OrderedDict, torch.Tensor]] = torch.load(\n",
    "            f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\"\n",
    "        )\n",
    "        valid_folds[\"preds\"] = check_point[\"preds\"]\n",
    "        return valid_folds\n",
    "\n",
    "    def run_cv(self, train: pd.DataFrame) -> None:\n",
    "        print(f\"debug mode: {self.cfg.basic.is_debug}\")\n",
    "        print(f\"start time: {datetime.datetime.now()}\")\n",
    "        oof_df = pd.DataFrame()\n",
    "        for n_fold in range(self.cfg.kfold.number):\n",
    "            _oof_df = self._train(train, n_fold)\n",
    "            print(f\"========== fold: {n_fold} result ==========\")\n",
    "            self._evaluate(_oof_df[\"target\"], _oof_df[\"preds\"])\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "        print(\"========== CV ==========\")\n",
    "        self._evaluate(oof_df[\"target\"], oof_df[\"preds\"])\n",
    "        Jbl.save(oof_df, f\"{OutputPath.model}/oof_df_{self.cfg.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9c6ec55-378b-402c-8f5b-00172c78fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceRunner(BaseRunner):\n",
    "    def _test_batch(self, test_loader, model):\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for step, image_label_dict in enumerate(test_loader):\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "        predictions = np.concatenate(preds)\n",
    "        return predictions\n",
    "\n",
    "    def _test(self, test: pd.DataFrame, n_fold: int):\n",
    "        print(f\"fold: {n_fold}\")\n",
    "        test_dataset = AtmaDataset(\n",
    "            test,\n",
    "            is_train=False,\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.params.test_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        model = build_model(pretrained=self.cfg.params.pretrained)\n",
    "        model_state = torch.load(f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\")[\"model\"]\n",
    "        model.load_state_dict(model_state)\n",
    "        model.to(self.cfg.basic.device)\n",
    "        preds = self._test_batch(test_loader, model)\n",
    "        return preds\n",
    "    \n",
    "    def _submit(self, preds: np.array) -> None:\n",
    "        df_sub = load_csv(input_path.sub)\n",
    "        df_sub = df_sub.assign(target=preds)\n",
    "        path = f\"{OutputPath.submission}/submission_{self.cfg.basic.run_name}.csv\"\n",
    "        df_sub.to_csv(path, index=False)\n",
    "        print(\"submission.csv created\")\n",
    "\n",
    "    def run_cv(self, test: pd.DataFrame) -> None:\n",
    "        oof_df = pd.DataFrame()\n",
    "        preds: List[np.array] = []\n",
    "        for n_fold in range(self.cfg.kfold.number):\n",
    "            preds_fold = self._test(test, n_fold)\n",
    "            preds.append(preds_fold)\n",
    "        Jbl.save(preds, f\"{OutputPath.model}/preds_test_{self.cfg.basic.run_name}.jbl\")\n",
    "        \n",
    "        preds_mean = np.concatenate(preds, axis=1).mean(axis=1)\n",
    "        self._submit(preds_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eae1cb89-4ee0-4293-b935-888a14f628da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed()\n",
    "input_path = InputPath()\n",
    "model_config = ModelConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c99fafc2-2ace-488f-b2a3-1f6f3297af69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3937, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>sorting_date</th>\n",
       "      <th>art_series_id</th>\n",
       "      <th>target</th>\n",
       "      <th>object_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002bff09b09998d0be65</td>\n",
       "      <td>1631</td>\n",
       "      <td>509357f67692a6a45626</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/photos/002bff09b09998d0be65.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00309fb1ef05416f9c1f</td>\n",
       "      <td>1900</td>\n",
       "      <td>7987b47bbe5dc3039179</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/00309fb1ef05416f9c1f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003a1562e97f79ba96dc</td>\n",
       "      <td>1834</td>\n",
       "      <td>ded7c3c9636708e5b14c</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/003a1562e97f79ba96dc.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              object_id  sorting_date         art_series_id  target  \\\n",
       "0  002bff09b09998d0be65          1631  509357f67692a6a45626       1   \n",
       "1  00309fb1ef05416f9c1f          1900  7987b47bbe5dc3039179       3   \n",
       "2  003a1562e97f79ba96dc          1834  ded7c3c9636708e5b14c       3   \n",
       "\n",
       "                                object_path  \n",
       "0  ../input/photos/002bff09b09998d0be65.jpg  \n",
       "1  ../input/photos/00309fb1ef05416f9c1f.jpg  \n",
       "2  ../input/photos/003a1562e97f79ba96dc.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = load_csv(input_path.train)\n",
    "train = train.assign(object_path = train[\"object_id\"].apply(lambda x: to_img_path(input_path.photos_prefix, x)))\n",
    "print(train.shape)\n",
    "display(train.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8796a89d-9fce-49b6-8d53-3c315b65722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 - [0 1 2 3 4]~[3928 3930 3933 3934 3935]\t[ 8 14 16 19 21]~[3922 3929 3931 3932 3936]\n",
      "fold: 1 - [0 1 2 4 5]~[3931 3932 3933 3934 3936]\t[ 3  9 20 23 24]~[3899 3907 3912 3925 3935]\n",
      "fold: 2 - [0 1 2 3 5]~[3931 3932 3934 3935 3936]\t[ 4  6 10 11 12]~[3913 3915 3924 3927 3933]\n",
      "fold: 3 - [2 3 4 5 6]~[3932 3933 3934 3935 3936]\t[ 0  1  7 17 29]~[3914 3916 3919 3923 3926]\n",
      "fold: 4 - [0 1 3 4 6]~[3931 3932 3933 3935 3936]\t[ 2  5 22 31 32]~[3909 3918 3928 3930 3934]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "fold target     \n",
       "0    0        95\n",
       "     1       180\n",
       "     2       302\n",
       "     3       211\n",
       "1    0        95\n",
       "     1       179\n",
       "     2       303\n",
       "     3       211\n",
       "2    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211\n",
       "3    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211\n",
       "4    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kf = generate_kf(model_config)\n",
    "if model_config.kfold.method.endswith(\"gkf\"):\n",
    "    kf_generator = kf.split(\n",
    "        train,\n",
    "        train[self.fe_cfg.column.target],\n",
    "        groups=train[self.kfold.columns],\n",
    "    )\n",
    "else:\n",
    "    kf_generator = kf.split(train, train[\"target\"])\n",
    "for fold_i, (tr_idx, val_idx) in enumerate(kf_generator):\n",
    "    print(\n",
    "        f\"fold: {fold_i} - {tr_idx[:5]}~{tr_idx[-5:]}\\t{val_idx[:5]}~{val_idx[-5:]}\"\n",
    "    )\n",
    "    train.loc[val_idx, \"fold\"] = fold_i\n",
    "train = train.assign(fold = train[\"fold\"].astype(int))\n",
    "if model_config.kfold.method == \"skf\":\n",
    "    display(train.groupby([\"fold\", \"target\"]).size().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af2c78d-558e-491c-b0f4-1884e1f42273",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "TrainRunner(model_config).run_cv(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ba9ba8b-317b-42a0-9a0b-c6bd8e07f462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== CV ==========\n",
      "Score: 0.87831\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>sorting_date</th>\n",
       "      <th>art_series_id</th>\n",
       "      <th>target</th>\n",
       "      <th>object_path</th>\n",
       "      <th>fold</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00bf812ffe8a62d45661</td>\n",
       "      <td>1720</td>\n",
       "      <td>3bfd41016d864e3fd8b5</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/00bf812ffe8a62d45661.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2.095212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0110115b8b6036d9ab3c</td>\n",
       "      <td>1741</td>\n",
       "      <td>baa4a20f0372d74dfc80</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/0110115b8b6036d9ab3c.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.974639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01273c00c46a84c50468</td>\n",
       "      <td>1757</td>\n",
       "      <td>51024cb4c6256ccce827</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/01273c00c46a84c50468.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.194608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0160840d9a4620b08fbd</td>\n",
       "      <td>1874</td>\n",
       "      <td>a56504999a8157a25d16</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/0160840d9a4620b08fbd.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2.219047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0169c493b09c8758a1b3</td>\n",
       "      <td>1734</td>\n",
       "      <td>550c62dd363fea62581c</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/0169c493b09c8758a1b3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.815809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>fe4d591332b08ab81361</td>\n",
       "      <td>1600</td>\n",
       "      <td>0782dfafa355acaf888c</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/photos/fe4d591332b08ab81361.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.842777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>fecae40c488e4c8c5ba5</td>\n",
       "      <td>1600</td>\n",
       "      <td>9ac00be75c55b1653a94</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/photos/fecae40c488e4c8c5ba5.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.928848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>ff37540e22e1ef455368</td>\n",
       "      <td>1765</td>\n",
       "      <td>9971eebf0f583a5e51da</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/ff37540e22e1ef455368.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.635049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>ff9124278e0f7086738f</td>\n",
       "      <td>1630</td>\n",
       "      <td>b4d508f53d16f7bcaf55</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/photos/ff9124278e0f7086738f.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2.021390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>ffd794b7b311b7b7fd92</td>\n",
       "      <td>1789</td>\n",
       "      <td>f030a01b480b18a27be2</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/ffd794b7b311b7b7fd92.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2.122827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3937 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                object_id  sorting_date         art_series_id  target  \\\n",
       "0    00bf812ffe8a62d45661          1720  3bfd41016d864e3fd8b5       2   \n",
       "1    0110115b8b6036d9ab3c          1741  baa4a20f0372d74dfc80       2   \n",
       "2    01273c00c46a84c50468          1757  51024cb4c6256ccce827       2   \n",
       "3    0160840d9a4620b08fbd          1874  a56504999a8157a25d16       3   \n",
       "4    0169c493b09c8758a1b3          1734  550c62dd363fea62581c       2   \n",
       "..                    ...           ...                   ...     ...   \n",
       "782  fe4d591332b08ab81361          1600  0782dfafa355acaf888c       0   \n",
       "783  fecae40c488e4c8c5ba5          1600  9ac00be75c55b1653a94       0   \n",
       "784  ff37540e22e1ef455368          1765  9971eebf0f583a5e51da       2   \n",
       "785  ff9124278e0f7086738f          1630  b4d508f53d16f7bcaf55       1   \n",
       "786  ffd794b7b311b7b7fd92          1789  f030a01b480b18a27be2       2   \n",
       "\n",
       "                                  object_path  fold     preds  \n",
       "0    ../input/photos/00bf812ffe8a62d45661.jpg     0  2.095212  \n",
       "1    ../input/photos/0110115b8b6036d9ab3c.jpg     0  1.974639  \n",
       "2    ../input/photos/01273c00c46a84c50468.jpg     0  1.194608  \n",
       "3    ../input/photos/0160840d9a4620b08fbd.jpg     0  2.219047  \n",
       "4    ../input/photos/0169c493b09c8758a1b3.jpg     0  1.815809  \n",
       "..                                        ...   ...       ...  \n",
       "782  ../input/photos/fe4d591332b08ab81361.jpg     4  1.842777  \n",
       "783  ../input/photos/fecae40c488e4c8c5ba5.jpg     4  1.928848  \n",
       "784  ../input/photos/ff37540e22e1ef455368.jpg     4  1.635049  \n",
       "785  ../input/photos/ff9124278e0f7086738f.jpg     4  2.021390  \n",
       "786  ../input/photos/ffd794b7b311b7b7fd92.jpg     4  2.122827  \n",
       "\n",
       "[3937 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_df = Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")\n",
    "print(\"========== CV ==========\")\n",
    "TrainRunner(model_config)._evaluate(oof_df[\"target\"], oof_df[\"preds\"])\n",
    "\n",
    "Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72e174df-3c50-4bae-a0be-dc59445ea40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")[\"preds\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e2e35b9-f7b8-4ea9-96e4-6053d8dc537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "fold: 1\n",
      "fold: 2\n",
      "fold: 3\n",
      "fold: 4\n",
      "submission.csv created\n"
     ]
    }
   ],
   "source": [
    "test = load_csv(input_path.test)\n",
    "test = test.assign(object_path = test[\"object_id\"].apply(lambda x: to_img_path(input_path.photos_prefix, x)))\n",
    "InferenceRunner(model_config).run_cv(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa73ab9-d584-426e-9bac-a21e3b86a54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a9074a-5044-4ae5-a622-79637a6e0c68",
   "metadata": {},
   "source": [
    "File Changed\n",
    "- base version: exp004\n",
    "- train time augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08317bb-fa4d-45c8-9729-46910b084d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce6b088f-2dd0-471b-8d65-5474a0047688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InputPath:\n",
    "    _prefix: str = \"../input\"\n",
    "    train: str = f\"{_prefix}/train.csv\"\n",
    "    materials: str = f\"{_prefix}/materials.csv\"\n",
    "    techniques: str = f\"{_prefix}/techniques.csv\"\n",
    "    test: str = f\"{_prefix}/test.csv\"\n",
    "    sub: str = f\"{_prefix}/atmaCup#11_sample_submission.csv\"\n",
    "    photos_prefix: str = f\"{_prefix}/photos\"\n",
    "    photos: List[str] = field(default_factory=lambda: glob(f\"../input/photos/*.jpg\"))\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class OutputPath:\n",
    "    _prefix: str = \"../output/\"\n",
    "    model: str = f\"{_prefix}/model\"\n",
    "    submission: str = f\"{_prefix}/submission\"\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Basic:\n",
    "    run_name: str = \"exp005\"\n",
    "    is_debug: bool = False\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Kfold:\n",
    "    number: int = 5\n",
    "    method: str = \"skf\"\n",
    "    shuffle: bool = True\n",
    "    columns: List[str] = field(default_factory=lambda: [\"target\"])\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Adam:\n",
    "    name: str = \"Adam\"\n",
    "    lr: float = 1e-4\n",
    "    weight_decay: float = 0\n",
    "    amsgrad: bool = False\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class ReduceLROnPlateau:\n",
    "    name: str = \"ReduceLROnPlateau\"\n",
    "    mode: str = \"min\"\n",
    "    factor: float = 0.1\n",
    "    patience: int = 5\n",
    "    verbose: bool = True\n",
    "    eps: float = 1e-8\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Params:\n",
    "    batch_size: int = 64\n",
    "    test_batch_size: int = 256\n",
    "    epochs: int = 3 if Basic.is_debug else 30\n",
    "    image_size: int = 224\n",
    "    max_grad_norm: int = 1000\n",
    "    num_workers: int = 0\n",
    "    print_freq: int = 10000\n",
    "    target_size: int = 1\n",
    "    # Union[Adam]\n",
    "    optimizer: Adam = Adam()\n",
    "    # Union[CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau]\n",
    "    scheduler: ReduceLROnPlateau = ReduceLROnPlateau()\n",
    "    pretrained: bool = False\n",
    "    num_aug: int = 5\n",
    "    num_tta: int = 10\n",
    "        \n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    basic: Basic = Basic()\n",
    "    kfold: Kfold = Kfold()\n",
    "    params: Params = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72fec5d5-f634-46bc-9cb6-437c0f3b4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in os.listdir(OutputPath.model) if x.startswith(\"exp???_\"):\n",
    "#     os.remove(f\"{OutputPath.model}/{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e688a697-6d8e-40a5-89a3-56833b01cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_sessions = [x.split(\"_\")[0] for x in os.listdir(OutputPath.model) if x.endswith(\"_0.pth\")]\n",
    "assert Basic.run_name not in past_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b0b95d9-6d21-48a4-8ef9-d085e183e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class Jbl:\n",
    "    @staticmethod\n",
    "    def load(filepath: str) -> Any:\n",
    "        return joblib.load(filepath)\n",
    "\n",
    "    @staticmethod\n",
    "    def save(obj_: Any, filepath: str) -> None:\n",
    "        joblib.dump(obj_, filepath, compress=3)\n",
    "\n",
    "\n",
    "def RMSE(y: np.array, p: np.array) -> float:\n",
    "    return metrics.mean_squared_error(y, p) ** 0.5\n",
    "\n",
    "\n",
    "def fix_seed(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    \n",
    "def time_since(since: time.time, percent: float) -> str:\n",
    "    def as_minutes(s):\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return \"%dm %ds\" % (m, s)\n",
    "\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adac7d51-f744-4349-a639-7a6661370d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def to_img_path(photo_dir: str, object_id: str) -> str:\n",
    "    return os.path.join(photo_dir, f'{object_id}.jpg')\n",
    "\n",
    "def read_image(object_id: str):\n",
    "    return Image.open(to_img_path(object_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52cc936d-6003-4e02-ba1f-d42cf039cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_csv(path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "169f341c-c861-4c5d-918c-201017c494da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    GroupKFold,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    TimeSeriesSplit,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_kf(cfg: ModelConfig) -> Generator:\n",
    "    if cfg.kfold.method == \"kf\":\n",
    "        kf = KFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"skf\":\n",
    "        kf = StratifiedKFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"gkf\":\n",
    "        kf = GroupKFold(n_splits=cfg.kfold.number)\n",
    "    elif cfg.kfold.method == \"sgkf\":\n",
    "        kf = StratifiedGroupKFold(\n",
    "            n_splits=cfg.kfold.number, random_state=cfg.basic.seed\n",
    "        )\n",
    "    elif cfg.kfold.method == \"tskf\":\n",
    "        kf = TimeSeriesSplit(n_splits=cfg.kfold.number)\n",
    "    else:\n",
    "        raise ValueError(f\"{cfg.kfold.method} is not supported\")\n",
    "    return kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e1e049a-17be-4901-a59d-8d475c180753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "\n",
    "\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "class AtmaDataset(data.Dataset):\n",
    "    \"\"\"atmaCup用にデータ読み込み等を行なうデータ・セット\"\"\"\n",
    "    object_path_key = \"object_path\"\n",
    "    label_key = \"target\"\n",
    "\n",
    "    def __init__(self, meta_df: pd.DataFrame, is_train: bool = True) -> None:\n",
    "        self.is_train = is_train\n",
    "        self.meta_df = meta_df.reset_index(drop=True)\n",
    "        self.index_to_data = self.meta_df.to_dict(orient=\"index\")\n",
    "        \n",
    "        size = (ModelConfig.params.image_size, ModelConfig.params.image_size)\n",
    "        additional_items = (\n",
    "            [T.Resize(size)]\n",
    "            if not is_train\n",
    "            else [\n",
    "                T.RandomGrayscale(p=0.2),\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.ColorJitter(\n",
    "                    brightness=0.3,\n",
    "                    contrast=0.5,\n",
    "                    saturation=[0.8, 1.3],\n",
    "                    hue=[-0.05, 0.05],\n",
    "                ),\n",
    "                T.RandomResizedCrop(size),\n",
    "            ]\n",
    "        )\n",
    "        self.transformer = T.Compose(\n",
    "            [*additional_items, T.ToTensor(), T.Normalize(mean=IMG_MEAN, std=IMG_STD)]\n",
    "        )\n",
    "        \n",
    "        self._validate_meta_df(meta_df)\n",
    "\n",
    "    def __getitem__(self, index) -> Dict[str, Any]:\n",
    "        data = self.index_to_data[index]\n",
    "        obj_path, label = data.get(self.object_path_key), data.get(self.label_key, -1)\n",
    "        img = self.transformer(Image.open(obj_path))\n",
    "        return {\"image\": img, \"label\": label}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.meta_df)\n",
    "    \n",
    "    def _validate_meta_df(self, meta_df: pd.DataFrame) -> None:\n",
    "        for k in self.meta_keys:\n",
    "            if k not in meta_df:\n",
    "                raise ValueError(f\"meta df must have {k}\")\n",
    "                \n",
    "    @property\n",
    "    def meta_keys(self) -> List[str]:\n",
    "        retval = [self.object_path_key]\n",
    "        if self.is_train:\n",
    "            retval += [self.label_key]\n",
    "        return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb29cd98-7770-4f3e-813f-461679503034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from logging import Logger\n",
    "from typing import Dict, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def build_model(pretrained: bool = False):\n",
    "    model = models.resnet34(pretrained=pretrained)\n",
    "    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)    \n",
    "    return model\n",
    "\n",
    "\n",
    "class BaseRunner:\n",
    "    def __init__(self, cfg: ModelConfig):\n",
    "        self.cfg = cfg\n",
    "        self.params = cfg.params\n",
    "\n",
    "    def _get_scheduler(\n",
    "        self, optimizer: Union[optim.Adam]\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if self.params.scheduler.name == \"ReduceLROnPlateau\":\n",
    "            scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode=self.params.scheduler.mode,\n",
    "                factor=self.params.scheduler.factor,\n",
    "                patience=self.params.scheduler.patience,\n",
    "                verbose=self.params.scheduler.verbose,\n",
    "                eps=self.params.scheduler.eps,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.scheduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _step_scheduler(\n",
    "        self,\n",
    "        scheduler: Union[\n",
    "            lr_scheduler.ReduceLROnPlateau,\n",
    "        ],\n",
    "        avg_val_loss,\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.shceduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _evaluate(self, y_true: np.array, y_pred: np.array):\n",
    "        score = RMSE(y_true, y_pred)\n",
    "        print(f\"Score: {score:<.5f}\")\n",
    "\n",
    "\n",
    "class TrainRunner(BaseRunner):\n",
    "    def _train_batch(self, train_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "        losses = AverageMeter()\n",
    "        model.train()\n",
    "        for _ in range(self.cfg.params.num_aug):\n",
    "            for step, image_label_dict in enumerate(train_loader):\n",
    "                images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "                labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "                batch_size = labels.size(0)\n",
    "\n",
    "                y_preds = model(images)\n",
    "                loss = criterion(y_preds.squeeze(), labels.float())\n",
    "                losses.update(loss.item(), batch_size)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        return losses.avg\n",
    "\n",
    "    def _valid_batch(self, valid_loader, model, criterion):\n",
    "        losses = AverageMeter()\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for _, image_label_dict in enumerate(valid_loader):\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            loss = criterion(y_preds.squeeze(), labels.float())\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "        predictions = np.concatenate(preds)\n",
    "        return losses.avg, predictions\n",
    "\n",
    "    def _train(self, train: pd.DataFrame, n_fold: int):\n",
    "        print(f\"fold: {n_fold}\")\n",
    "        \n",
    "        is_tta_mode = self.params.num_tta > 0\n",
    "        num_times_tta = 1 if not is_tta_mode else self.params.num_tta\n",
    "\n",
    "        trn_idx = train[train[\"fold\"] != n_fold].index\n",
    "        val_idx = train[train[\"fold\"] == n_fold].index\n",
    "        train_folds = train.loc[trn_idx].reset_index(drop=True)\n",
    "        valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "        train_dataset = AtmaDataset(\n",
    "            train_folds,\n",
    "            is_train=True,\n",
    "#             transform=get_transforms(self.params, data=\"train\"),\n",
    "        )\n",
    "        valid_dataset = AtmaDataset(\n",
    "            valid_folds,\n",
    "            is_train=is_tta_mode,\n",
    "#             transform=get_transforms(self.params, data=\"valid\"),\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        model = build_model(pretrained=self.cfg.params.pretrained)\n",
    "        model.to(self.cfg.basic.device)\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=self.params.optimizer.lr,\n",
    "            weight_decay=self.params.optimizer.weight_decay,\n",
    "            amsgrad=self.params.optimizer.amsgrad,\n",
    "        )\n",
    "        scheduler = self._get_scheduler(optimizer)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        best_score = np.inf\n",
    "        for epoch in range(self.params.epochs):\n",
    "            start_time = time.time()\n",
    "\n",
    "            avg_loss = self._train_batch(\n",
    "                train_loader, model, criterion, optimizer, scheduler, epoch\n",
    "            )\n",
    "            avg_val_loss_list: List[float] = []\n",
    "            preds_list: List[np.array] = []\n",
    "            for _ in range(num_times_tta):\n",
    "                avg_val_loss, preds = self._valid_batch(valid_loader, model, criterion)\n",
    "                avg_val_loss_list.append(avg_val_loss)\n",
    "                preds_list.append(preds)\n",
    "            avg_val_loss = np.mean(avg_val_loss_list)\n",
    "            preds = np.concatenate(preds_list, axis=1).mean(axis=1)\n",
    "            valid_labels = valid_folds[\"target\"].values\n",
    "            scheduler = self._step_scheduler(scheduler, avg_val_loss)\n",
    "            score = RMSE(valid_labels, preds)\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "            )\n",
    "            print(f\"Epoch {epoch+1} - RMSE: {score}\")\n",
    "            if best_score > score:\n",
    "                best_score = score\n",
    "                torch.save(\n",
    "                    {\"model\": model.state_dict(), \"preds\": preds, \"score\": score},\n",
    "                    f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\",\n",
    "                )\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - Best Score: {best_score:.4f}\"\n",
    "            )\n",
    "\n",
    "        check_point: Dict[str, Union[OrderedDict, torch.Tensor]] = torch.load(\n",
    "            f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\"\n",
    "        )\n",
    "        valid_folds[\"preds\"] = check_point[\"preds\"]\n",
    "        return valid_folds\n",
    "\n",
    "    def run_cv(self, train: pd.DataFrame) -> None:\n",
    "        print(f\"debug mode: {self.cfg.basic.is_debug}\")\n",
    "        print(f\"start time: {datetime.datetime.now()}\")\n",
    "        oof_df = pd.DataFrame()\n",
    "        for n_fold in range(self.cfg.kfold.number):\n",
    "            _oof_df = self._train(train, n_fold)\n",
    "            print(f\"========== fold: {n_fold} result ==========\")\n",
    "            self._evaluate(_oof_df[\"target\"], _oof_df[\"preds\"])\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "        print(\"========== CV ==========\")\n",
    "        self._evaluate(oof_df[\"target\"], oof_df[\"preds\"])\n",
    "        Jbl.save(oof_df, f\"{OutputPath.model}/oof_df_{self.cfg.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9c6ec55-378b-402c-8f5b-00172c78fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceRunner(BaseRunner):\n",
    "    def _test_batch(self, test_loader, model):\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for step, image_label_dict in enumerate(test_loader):\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "        predictions = np.concatenate(preds)\n",
    "        return predictions\n",
    "\n",
    "    def _test(self, test: pd.DataFrame, n_fold: int):\n",
    "        print(f\"fold: {n_fold}\")\n",
    "        test_dataset = AtmaDataset(\n",
    "            test,\n",
    "            is_train=False,\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.params.test_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        model = build_model(pretrained=self.cfg.params.pretrained)\n",
    "        model_state = torch.load(f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\")[\"model\"]\n",
    "        model.load_state_dict(model_state)\n",
    "        model.to(self.cfg.basic.device)\n",
    "        preds = self._test_batch(test_loader, model)\n",
    "        return preds\n",
    "    \n",
    "    def _submit(self, preds: np.array) -> None:\n",
    "        df_sub = load_csv(input_path.sub)\n",
    "        df_sub = df_sub.assign(target=preds)\n",
    "        path = f\"{OutputPath.submission}/submission_{self.cfg.basic.run_name}.csv\"\n",
    "        df_sub.to_csv(path, index=False)\n",
    "        print(\"submission.csv created\")\n",
    "\n",
    "    def run_cv(self, test: pd.DataFrame) -> None:\n",
    "        oof_df = pd.DataFrame()\n",
    "        preds: List[np.array] = []\n",
    "        for n_fold in range(self.cfg.kfold.number):\n",
    "            preds_fold = self._test(test, n_fold)\n",
    "            preds.append(preds_fold)\n",
    "        Jbl.save(preds, f\"{OutputPath.model}/preds_test_{self.cfg.basic.run_name}.jbl\")\n",
    "        \n",
    "        preds_mean = np.concatenate(preds, axis=1).mean(axis=1)\n",
    "        self._submit(preds_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae1cb89-4ee0-4293-b935-888a14f628da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed()\n",
    "input_path = InputPath()\n",
    "model_config = ModelConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c99fafc2-2ace-488f-b2a3-1f6f3297af69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3937, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>sorting_date</th>\n",
       "      <th>art_series_id</th>\n",
       "      <th>target</th>\n",
       "      <th>object_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002bff09b09998d0be65</td>\n",
       "      <td>1631</td>\n",
       "      <td>509357f67692a6a45626</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/photos/002bff09b09998d0be65.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00309fb1ef05416f9c1f</td>\n",
       "      <td>1900</td>\n",
       "      <td>7987b47bbe5dc3039179</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/00309fb1ef05416f9c1f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003a1562e97f79ba96dc</td>\n",
       "      <td>1834</td>\n",
       "      <td>ded7c3c9636708e5b14c</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/003a1562e97f79ba96dc.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              object_id  sorting_date         art_series_id  target  \\\n",
       "0  002bff09b09998d0be65          1631  509357f67692a6a45626       1   \n",
       "1  00309fb1ef05416f9c1f          1900  7987b47bbe5dc3039179       3   \n",
       "2  003a1562e97f79ba96dc          1834  ded7c3c9636708e5b14c       3   \n",
       "\n",
       "                                object_path  \n",
       "0  ../input/photos/002bff09b09998d0be65.jpg  \n",
       "1  ../input/photos/00309fb1ef05416f9c1f.jpg  \n",
       "2  ../input/photos/003a1562e97f79ba96dc.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = load_csv(input_path.train)\n",
    "train = train.assign(object_path = train[\"object_id\"].apply(lambda x: to_img_path(input_path.photos_prefix, x)))\n",
    "print(train.shape)\n",
    "display(train.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8796a89d-9fce-49b6-8d53-3c315b65722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 - [0 1 2 3 4]~[3928 3930 3933 3934 3935]\t[ 8 14 16 19 21]~[3922 3929 3931 3932 3936]\n",
      "fold: 1 - [0 1 2 4 5]~[3931 3932 3933 3934 3936]\t[ 3  9 20 23 24]~[3899 3907 3912 3925 3935]\n",
      "fold: 2 - [0 1 2 3 5]~[3931 3932 3934 3935 3936]\t[ 4  6 10 11 12]~[3913 3915 3924 3927 3933]\n",
      "fold: 3 - [2 3 4 5 6]~[3932 3933 3934 3935 3936]\t[ 0  1  7 17 29]~[3914 3916 3919 3923 3926]\n",
      "fold: 4 - [0 1 3 4 6]~[3931 3932 3933 3935 3936]\t[ 2  5 22 31 32]~[3909 3918 3928 3930 3934]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "fold target     \n",
       "0    0        95\n",
       "     1       180\n",
       "     2       302\n",
       "     3       211\n",
       "1    0        95\n",
       "     1       179\n",
       "     2       303\n",
       "     3       211\n",
       "2    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211\n",
       "3    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211\n",
       "4    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kf = generate_kf(model_config)\n",
    "if model_config.kfold.method.endswith(\"gkf\"):\n",
    "    kf_generator = kf.split(\n",
    "        train,\n",
    "        train[self.fe_cfg.column.target],\n",
    "        groups=train[self.kfold.columns],\n",
    "    )\n",
    "else:\n",
    "    kf_generator = kf.split(train, train[\"target\"])\n",
    "for fold_i, (tr_idx, val_idx) in enumerate(kf_generator):\n",
    "    print(\n",
    "        f\"fold: {fold_i} - {tr_idx[:5]}~{tr_idx[-5:]}\\t{val_idx[:5]}~{val_idx[-5:]}\"\n",
    "    )\n",
    "    train.loc[val_idx, \"fold\"] = fold_i\n",
    "train = train.assign(fold = train[\"fold\"].astype(int))\n",
    "if model_config.kfold.method == \"skf\":\n",
    "    display(train.groupby([\"fold\", \"target\"]).size().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0af2c78d-558e-491c-b0f4-1884e1f42273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug mode: False\n",
      "start time: 2021-07-21 11:39:36.408826\n",
      "fold: 0\n",
      "Epoch 1 - avg_train_loss: 0.9796  avg_val_loss: 0.9067  time: 136s\n",
      "Epoch 1 - RMSE: 0.9292506604597778\n",
      "Epoch 1 - Best Score: 0.9293\n",
      "Epoch 2 - avg_train_loss: 0.9106  avg_val_loss: 0.9136  time: 135s\n",
      "Epoch 2 - RMSE: 0.9298241807177972\n",
      "Epoch 2 - Best Score: 0.9293\n",
      "Epoch 3 - avg_train_loss: 0.8871  avg_val_loss: 0.8845  time: 136s\n",
      "Epoch 3 - RMSE: 0.9207498550457983\n",
      "Epoch 3 - Best Score: 0.9207\n",
      "Epoch 4 - avg_train_loss: 0.8713  avg_val_loss: 0.8962  time: 136s\n",
      "Epoch 4 - RMSE: 0.9025363738617468\n",
      "Epoch 4 - Best Score: 0.9025\n",
      "Epoch 5 - avg_train_loss: 0.8494  avg_val_loss: 0.9597  time: 136s\n",
      "Epoch 5 - RMSE: 0.9319679154380064\n",
      "Epoch 5 - Best Score: 0.9025\n",
      "Epoch 6 - avg_train_loss: 0.8416  avg_val_loss: 0.8298  time: 136s\n",
      "Epoch 6 - RMSE: 0.8851288927835704\n",
      "Epoch 6 - Best Score: 0.8851\n",
      "Epoch 7 - avg_train_loss: 0.8308  avg_val_loss: 0.8334  time: 136s\n",
      "Epoch 7 - RMSE: 0.8832937678100297\n",
      "Epoch 7 - Best Score: 0.8833\n",
      "Epoch 8 - avg_train_loss: 0.8168  avg_val_loss: 0.8126  time: 136s\n",
      "Epoch 8 - RMSE: 0.869543744095725\n",
      "Epoch 8 - Best Score: 0.8695\n",
      "Epoch 9 - avg_train_loss: 0.8113  avg_val_loss: 0.8275  time: 135s\n",
      "Epoch 9 - RMSE: 0.8707520646079417\n",
      "Epoch 9 - Best Score: 0.8695\n",
      "Epoch 10 - avg_train_loss: 0.8033  avg_val_loss: 0.8167  time: 136s\n",
      "Epoch 10 - RMSE: 0.8765191990179226\n",
      "Epoch 10 - Best Score: 0.8695\n",
      "Epoch 11 - avg_train_loss: 0.7947  avg_val_loss: 0.7819  time: 136s\n",
      "Epoch 11 - RMSE: 0.8501783199694122\n",
      "Epoch 11 - Best Score: 0.8502\n",
      "Epoch 12 - avg_train_loss: 0.7893  avg_val_loss: 0.8015  time: 136s\n",
      "Epoch 12 - RMSE: 0.8658139332629093\n",
      "Epoch 12 - Best Score: 0.8502\n",
      "Epoch 13 - avg_train_loss: 0.7726  avg_val_loss: 0.8167  time: 136s\n",
      "Epoch 13 - RMSE: 0.8709355069338647\n",
      "Epoch 13 - Best Score: 0.8502\n",
      "Epoch 14 - avg_train_loss: 0.7784  avg_val_loss: 0.8088  time: 136s\n",
      "Epoch 14 - RMSE: 0.8745235832212317\n",
      "Epoch 14 - Best Score: 0.8502\n",
      "Epoch 15 - avg_train_loss: 0.7640  avg_val_loss: 0.8100  time: 136s\n",
      "Epoch 15 - RMSE: 0.860138894139762\n",
      "Epoch 15 - Best Score: 0.8502\n",
      "Epoch 16 - avg_train_loss: 0.7594  avg_val_loss: 0.8786  time: 136s\n",
      "Epoch 16 - RMSE: 0.9052755034662434\n",
      "Epoch 16 - Best Score: 0.8502\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 17 - avg_train_loss: 0.7519  avg_val_loss: 0.7947  time: 136s\n",
      "Epoch 17 - RMSE: 0.8553998831351648\n",
      "Epoch 17 - Best Score: 0.8502\n",
      "Epoch 18 - avg_train_loss: 0.7126  avg_val_loss: 0.7485  time: 136s\n",
      "Epoch 18 - RMSE: 0.827047582448856\n",
      "Epoch 18 - Best Score: 0.8270\n",
      "Epoch 19 - avg_train_loss: 0.6954  avg_val_loss: 0.7474  time: 136s\n",
      "Epoch 19 - RMSE: 0.8215778245076061\n",
      "Epoch 19 - Best Score: 0.8216\n",
      "Epoch 20 - avg_train_loss: 0.6817  avg_val_loss: 0.7461  time: 135s\n",
      "Epoch 20 - RMSE: 0.8215485815705178\n",
      "Epoch 20 - Best Score: 0.8215\n",
      "Epoch 21 - avg_train_loss: 0.6780  avg_val_loss: 0.7458  time: 135s\n",
      "Epoch 21 - RMSE: 0.8181954487505091\n",
      "Epoch 21 - Best Score: 0.8182\n",
      "Epoch 22 - avg_train_loss: 0.6718  avg_val_loss: 0.7355  time: 135s\n",
      "Epoch 22 - RMSE: 0.8063781943053874\n",
      "Epoch 22 - Best Score: 0.8064\n",
      "Epoch 23 - avg_train_loss: 0.6668  avg_val_loss: 0.7363  time: 136s\n",
      "Epoch 23 - RMSE: 0.8101593457218783\n",
      "Epoch 23 - Best Score: 0.8064\n",
      "Epoch 24 - avg_train_loss: 0.6657  avg_val_loss: 0.7338  time: 136s\n",
      "Epoch 24 - RMSE: 0.8105297025061243\n",
      "Epoch 24 - Best Score: 0.8064\n",
      "Epoch 25 - avg_train_loss: 0.6656  avg_val_loss: 0.7338  time: 135s\n",
      "Epoch 25 - RMSE: 0.8097922038452702\n",
      "Epoch 25 - Best Score: 0.8064\n",
      "Epoch 26 - avg_train_loss: 0.6601  avg_val_loss: 0.7326  time: 135s\n",
      "Epoch 26 - RMSE: 0.8081096849204058\n",
      "Epoch 26 - Best Score: 0.8064\n",
      "Epoch 27 - avg_train_loss: 0.6503  avg_val_loss: 0.7284  time: 136s\n",
      "Epoch 27 - RMSE: 0.8011488682296268\n",
      "Epoch 27 - Best Score: 0.8011\n",
      "Epoch 28 - avg_train_loss: 0.6476  avg_val_loss: 0.7381  time: 135s\n",
      "Epoch 28 - RMSE: 0.807619182319338\n",
      "Epoch 28 - Best Score: 0.8011\n",
      "Epoch 29 - avg_train_loss: 0.6441  avg_val_loss: 0.7408  time: 136s\n",
      "Epoch 29 - RMSE: 0.8054345305079974\n",
      "Epoch 29 - Best Score: 0.8011\n",
      "Epoch 30 - avg_train_loss: 0.6410  avg_val_loss: 0.7261  time: 136s\n",
      "Epoch 30 - RMSE: 0.8019264449627116\n",
      "Epoch 30 - Best Score: 0.8011\n",
      "========== fold: 0 result ==========\n",
      "Score: 0.80115\n",
      "fold: 1\n",
      "Epoch 1 - avg_train_loss: 0.9824  avg_val_loss: 0.9369  time: 136s\n",
      "Epoch 1 - RMSE: 0.9555282047413786\n",
      "Epoch 1 - Best Score: 0.9555\n",
      "Epoch 2 - avg_train_loss: 0.9125  avg_val_loss: 0.8968  time: 136s\n",
      "Epoch 2 - RMSE: 0.9254745724719111\n",
      "Epoch 2 - Best Score: 0.9255\n",
      "Epoch 3 - avg_train_loss: 0.8904  avg_val_loss: 0.8900  time: 136s\n",
      "Epoch 3 - RMSE: 0.9241529845838279\n",
      "Epoch 3 - Best Score: 0.9242\n",
      "Epoch 4 - avg_train_loss: 0.8711  avg_val_loss: 0.8603  time: 136s\n",
      "Epoch 4 - RMSE: 0.9104718451576707\n",
      "Epoch 4 - Best Score: 0.9105\n",
      "Epoch 5 - avg_train_loss: 0.8588  avg_val_loss: 0.9688  time: 136s\n",
      "Epoch 5 - RMSE: 0.9603628651242658\n",
      "Epoch 5 - Best Score: 0.9105\n",
      "Epoch 6 - avg_train_loss: 0.8480  avg_val_loss: 0.8617  time: 136s\n",
      "Epoch 6 - RMSE: 0.9062966728437053\n",
      "Epoch 6 - Best Score: 0.9063\n",
      "Epoch 7 - avg_train_loss: 0.8427  avg_val_loss: 0.9692  time: 136s\n",
      "Epoch 7 - RMSE: 0.9536273451787671\n",
      "Epoch 7 - Best Score: 0.9063\n",
      "Epoch 8 - avg_train_loss: 0.8279  avg_val_loss: 0.8521  time: 136s\n",
      "Epoch 8 - RMSE: 0.8958305946949632\n",
      "Epoch 8 - Best Score: 0.8958\n",
      "Epoch 9 - avg_train_loss: 0.8098  avg_val_loss: 0.8343  time: 136s\n",
      "Epoch 9 - RMSE: 0.8850318338973777\n",
      "Epoch 9 - Best Score: 0.8850\n",
      "Epoch 10 - avg_train_loss: 0.7996  avg_val_loss: 0.8349  time: 136s\n",
      "Epoch 10 - RMSE: 0.875311282521882\n",
      "Epoch 10 - Best Score: 0.8753\n",
      "Epoch 11 - avg_train_loss: 0.8057  avg_val_loss: 0.8433  time: 136s\n",
      "Epoch 11 - RMSE: 0.8934442609440644\n",
      "Epoch 11 - Best Score: 0.8753\n",
      "Epoch 12 - avg_train_loss: 0.7814  avg_val_loss: 0.8328  time: 136s\n",
      "Epoch 12 - RMSE: 0.8820424552169897\n",
      "Epoch 12 - Best Score: 0.8753\n",
      "Epoch 13 - avg_train_loss: 0.7708  avg_val_loss: 0.8681  time: 136s\n",
      "Epoch 13 - RMSE: 0.8956420299651349\n",
      "Epoch 13 - Best Score: 0.8753\n",
      "Epoch 14 - avg_train_loss: 0.7740  avg_val_loss: 0.8072  time: 136s\n",
      "Epoch 14 - RMSE: 0.85771622936857\n",
      "Epoch 14 - Best Score: 0.8577\n",
      "Epoch 15 - avg_train_loss: 0.7554  avg_val_loss: 0.7905  time: 136s\n",
      "Epoch 15 - RMSE: 0.8478381497379248\n",
      "Epoch 15 - Best Score: 0.8478\n",
      "Epoch 16 - avg_train_loss: 0.7437  avg_val_loss: 0.7945  time: 136s\n",
      "Epoch 16 - RMSE: 0.8485628121157807\n",
      "Epoch 16 - Best Score: 0.8478\n",
      "Epoch 17 - avg_train_loss: 0.7378  avg_val_loss: 0.7944  time: 136s\n",
      "Epoch 17 - RMSE: 0.8489285316085863\n",
      "Epoch 17 - Best Score: 0.8478\n",
      "Epoch 18 - avg_train_loss: 0.7294  avg_val_loss: 1.0006  time: 136s\n",
      "Epoch 18 - RMSE: 0.9444822633190487\n",
      "Epoch 18 - Best Score: 0.8478\n",
      "Epoch 19 - avg_train_loss: 0.7218  avg_val_loss: 0.7584  time: 136s\n",
      "Epoch 19 - RMSE: 0.8225841743659948\n",
      "Epoch 19 - Best Score: 0.8226\n",
      "Epoch 20 - avg_train_loss: 0.7138  avg_val_loss: 0.8394  time: 136s\n",
      "Epoch 20 - RMSE: 0.8734329967679015\n",
      "Epoch 20 - Best Score: 0.8226\n",
      "Epoch 21 - avg_train_loss: 0.7135  avg_val_loss: 0.7741  time: 136s\n",
      "Epoch 21 - RMSE: 0.8300445046390574\n",
      "Epoch 21 - Best Score: 0.8226\n",
      "Epoch 22 - avg_train_loss: 0.7003  avg_val_loss: 0.7661  time: 136s\n",
      "Epoch 22 - RMSE: 0.8369251661174013\n",
      "Epoch 22 - Best Score: 0.8226\n",
      "Epoch 23 - avg_train_loss: 0.6950  avg_val_loss: 0.8248  time: 136s\n",
      "Epoch 23 - RMSE: 0.8640528579759341\n",
      "Epoch 23 - Best Score: 0.8226\n",
      "Epoch 24 - avg_train_loss: 0.6839  avg_val_loss: 0.8808  time: 136s\n",
      "Epoch 24 - RMSE: 0.9014727635493629\n",
      "Epoch 24 - Best Score: 0.8226\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 25 - avg_train_loss: 0.6763  avg_val_loss: 0.7999  time: 136s\n",
      "Epoch 25 - RMSE: 0.8384740951747797\n",
      "Epoch 25 - Best Score: 0.8226\n",
      "Epoch 26 - avg_train_loss: 0.6265  avg_val_loss: 0.7195  time: 136s\n",
      "Epoch 26 - RMSE: 0.7928667302898658\n",
      "Epoch 26 - Best Score: 0.7929\n",
      "Epoch 27 - avg_train_loss: 0.6083  avg_val_loss: 0.7213  time: 136s\n",
      "Epoch 27 - RMSE: 0.7934694876384055\n",
      "Epoch 27 - Best Score: 0.7929\n",
      "Epoch 28 - avg_train_loss: 0.5922  avg_val_loss: 0.7138  time: 136s\n",
      "Epoch 28 - RMSE: 0.7881205251964314\n",
      "Epoch 28 - Best Score: 0.7881\n",
      "Epoch 29 - avg_train_loss: 0.5866  avg_val_loss: 0.7240  time: 136s\n",
      "Epoch 29 - RMSE: 0.7907096470219058\n",
      "Epoch 29 - Best Score: 0.7881\n",
      "Epoch 30 - avg_train_loss: 0.5804  avg_val_loss: 0.7145  time: 136s\n",
      "Epoch 30 - RMSE: 0.781430829658381\n",
      "Epoch 30 - Best Score: 0.7814\n",
      "========== fold: 1 result ==========\n",
      "Score: 0.78143\n",
      "fold: 2\n",
      "Epoch 1 - avg_train_loss: 0.9821  avg_val_loss: 0.9415  time: 136s\n",
      "Epoch 1 - RMSE: 0.9524274057821902\n",
      "Epoch 1 - Best Score: 0.9524\n",
      "Epoch 2 - avg_train_loss: 0.8947  avg_val_loss: 0.9066  time: 136s\n",
      "Epoch 2 - RMSE: 0.9328494861753681\n",
      "Epoch 2 - Best Score: 0.9328\n",
      "Epoch 3 - avg_train_loss: 0.8681  avg_val_loss: 0.8883  time: 136s\n",
      "Epoch 3 - RMSE: 0.9077775800470007\n",
      "Epoch 3 - Best Score: 0.9078\n",
      "Epoch 4 - avg_train_loss: 0.8555  avg_val_loss: 0.8634  time: 136s\n",
      "Epoch 4 - RMSE: 0.9095705050389579\n",
      "Epoch 4 - Best Score: 0.9078\n",
      "Epoch 5 - avg_train_loss: 0.8432  avg_val_loss: 0.8635  time: 136s\n",
      "Epoch 5 - RMSE: 0.9086680986632545\n",
      "Epoch 5 - Best Score: 0.9078\n",
      "Epoch 6 - avg_train_loss: 0.8288  avg_val_loss: 1.2549  time: 136s\n",
      "Epoch 6 - RMSE: 1.0744872561371501\n",
      "Epoch 6 - Best Score: 0.9078\n",
      "Epoch 7 - avg_train_loss: 0.8157  avg_val_loss: 1.0141  time: 136s\n",
      "Epoch 7 - RMSE: 0.946890267358418\n",
      "Epoch 7 - Best Score: 0.9078\n",
      "Epoch 8 - avg_train_loss: 0.8090  avg_val_loss: 0.8553  time: 136s\n",
      "Epoch 8 - RMSE: 0.889574265585723\n",
      "Epoch 8 - Best Score: 0.8896\n",
      "Epoch 9 - avg_train_loss: 0.8031  avg_val_loss: 0.8632  time: 136s\n",
      "Epoch 9 - RMSE: 0.8942492431907534\n",
      "Epoch 9 - Best Score: 0.8896\n",
      "Epoch 10 - avg_train_loss: 0.8064  avg_val_loss: 0.8143  time: 136s\n",
      "Epoch 10 - RMSE: 0.8726911168111443\n",
      "Epoch 10 - Best Score: 0.8727\n",
      "Epoch 11 - avg_train_loss: 0.7813  avg_val_loss: 0.8369  time: 136s\n",
      "Epoch 11 - RMSE: 0.8813859940661196\n",
      "Epoch 11 - Best Score: 0.8727\n",
      "Epoch 12 - avg_train_loss: 0.7755  avg_val_loss: 0.9055  time: 136s\n",
      "Epoch 12 - RMSE: 0.9076845183622635\n",
      "Epoch 12 - Best Score: 0.8727\n",
      "Epoch 13 - avg_train_loss: 0.7818  avg_val_loss: 0.8460  time: 136s\n",
      "Epoch 13 - RMSE: 0.8755466490224044\n",
      "Epoch 13 - Best Score: 0.8727\n",
      "Epoch 14 - avg_train_loss: 0.7640  avg_val_loss: 0.8516  time: 136s\n",
      "Epoch 14 - RMSE: 0.8939045245752139\n",
      "Epoch 14 - Best Score: 0.8727\n",
      "Epoch 15 - avg_train_loss: 0.7559  avg_val_loss: 0.8118  time: 136s\n",
      "Epoch 15 - RMSE: 0.864308866813112\n",
      "Epoch 15 - Best Score: 0.8643\n",
      "Epoch 16 - avg_train_loss: 0.7529  avg_val_loss: 0.8425  time: 136s\n",
      "Epoch 16 - RMSE: 0.8875113297375502\n",
      "Epoch 16 - Best Score: 0.8643\n",
      "Epoch 17 - avg_train_loss: 0.7454  avg_val_loss: 0.7884  time: 136s\n",
      "Epoch 17 - RMSE: 0.850687731931163\n",
      "Epoch 17 - Best Score: 0.8507\n",
      "Epoch 18 - avg_train_loss: 0.7357  avg_val_loss: 0.7858  time: 136s\n",
      "Epoch 18 - RMSE: 0.8499155525017317\n",
      "Epoch 18 - Best Score: 0.8499\n",
      "Epoch 19 - avg_train_loss: 0.7271  avg_val_loss: 0.7826  time: 136s\n",
      "Epoch 19 - RMSE: 0.8345517051533142\n",
      "Epoch 19 - Best Score: 0.8346\n",
      "Epoch 20 - avg_train_loss: 0.7223  avg_val_loss: 0.7857  time: 136s\n",
      "Epoch 20 - RMSE: 0.8428150578159235\n",
      "Epoch 20 - Best Score: 0.8346\n",
      "Epoch 21 - avg_train_loss: 0.7150  avg_val_loss: 0.8250  time: 136s\n",
      "Epoch 21 - RMSE: 0.8649606681840148\n",
      "Epoch 21 - Best Score: 0.8346\n",
      "Epoch 22 - avg_train_loss: 0.7098  avg_val_loss: 0.8184  time: 136s\n",
      "Epoch 22 - RMSE: 0.8591536837408343\n",
      "Epoch 22 - Best Score: 0.8346\n",
      "Epoch 23 - avg_train_loss: 0.7014  avg_val_loss: 0.7927  time: 136s\n",
      "Epoch 23 - RMSE: 0.8454737654803931\n",
      "Epoch 23 - Best Score: 0.8346\n",
      "Epoch 24 - avg_train_loss: 0.6982  avg_val_loss: 0.7595  time: 136s\n",
      "Epoch 24 - RMSE: 0.8267002078902175\n",
      "Epoch 24 - Best Score: 0.8267\n",
      "Epoch 25 - avg_train_loss: 0.6828  avg_val_loss: 0.7817  time: 136s\n",
      "Epoch 25 - RMSE: 0.8340907669691028\n",
      "Epoch 25 - Best Score: 0.8267\n",
      "Epoch 26 - avg_train_loss: 0.6773  avg_val_loss: 0.7870  time: 136s\n",
      "Epoch 26 - RMSE: 0.8406760461038899\n",
      "Epoch 26 - Best Score: 0.8267\n",
      "Epoch 27 - avg_train_loss: 0.6702  avg_val_loss: 0.7885  time: 136s\n",
      "Epoch 27 - RMSE: 0.8264040398449967\n",
      "Epoch 27 - Best Score: 0.8264\n",
      "Epoch 28 - avg_train_loss: 0.6708  avg_val_loss: 0.7689  time: 136s\n",
      "Epoch 28 - RMSE: 0.8294906326696438\n",
      "Epoch 28 - Best Score: 0.8264\n",
      "Epoch 29 - avg_train_loss: 0.6661  avg_val_loss: 0.7819  time: 136s\n",
      "Epoch 29 - RMSE: 0.8246266502667795\n",
      "Epoch 29 - Best Score: 0.8246\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 30 - avg_train_loss: 0.6492  avg_val_loss: 0.7799  time: 136s\n",
      "Epoch 30 - RMSE: 0.8250297963349414\n",
      "Epoch 30 - Best Score: 0.8246\n",
      "========== fold: 2 result ==========\n",
      "Score: 0.82463\n",
      "fold: 3\n",
      "Epoch 1 - avg_train_loss: 0.9648  avg_val_loss: 0.8953  time: 136s\n",
      "Epoch 1 - RMSE: 0.9252592460385549\n",
      "Epoch 1 - Best Score: 0.9253\n",
      "Epoch 2 - avg_train_loss: 0.9022  avg_val_loss: 1.0179  time: 136s\n",
      "Epoch 2 - RMSE: 0.9435615271378751\n",
      "Epoch 2 - Best Score: 0.9253\n",
      "Epoch 3 - avg_train_loss: 0.8812  avg_val_loss: 0.8599  time: 136s\n",
      "Epoch 3 - RMSE: 0.9119262871136564\n",
      "Epoch 3 - Best Score: 0.9119\n",
      "Epoch 4 - avg_train_loss: 0.8525  avg_val_loss: 0.9325  time: 136s\n",
      "Epoch 4 - RMSE: 0.9200059639868519\n",
      "Epoch 4 - Best Score: 0.9119\n",
      "Epoch 5 - avg_train_loss: 0.8382  avg_val_loss: 0.8718  time: 136s\n",
      "Epoch 5 - RMSE: 0.9064831712675716\n",
      "Epoch 5 - Best Score: 0.9065\n",
      "Epoch 6 - avg_train_loss: 0.8225  avg_val_loss: 0.8652  time: 136s\n",
      "Epoch 6 - RMSE: 0.8965939878366952\n",
      "Epoch 6 - Best Score: 0.8966\n",
      "Epoch 7 - avg_train_loss: 0.8224  avg_val_loss: 0.8411  time: 136s\n",
      "Epoch 7 - RMSE: 0.8886783916239849\n",
      "Epoch 7 - Best Score: 0.8887\n",
      "Epoch 8 - avg_train_loss: 0.8174  avg_val_loss: 0.8632  time: 136s\n",
      "Epoch 8 - RMSE: 0.8976593242070343\n",
      "Epoch 8 - Best Score: 0.8887\n",
      "Epoch 9 - avg_train_loss: 0.7967  avg_val_loss: 0.8246  time: 135s\n",
      "Epoch 9 - RMSE: 0.8711900235075564\n",
      "Epoch 9 - Best Score: 0.8712\n",
      "Epoch 10 - avg_train_loss: 0.7901  avg_val_loss: 0.8157  time: 136s\n",
      "Epoch 10 - RMSE: 0.8771817895016246\n",
      "Epoch 10 - Best Score: 0.8712\n",
      "Epoch 11 - avg_train_loss: 0.7826  avg_val_loss: 0.8336  time: 136s\n",
      "Epoch 11 - RMSE: 0.8856878396640195\n",
      "Epoch 11 - Best Score: 0.8712\n",
      "Epoch 12 - avg_train_loss: 0.7754  avg_val_loss: 0.8017  time: 136s\n",
      "Epoch 12 - RMSE: 0.8606610896248712\n",
      "Epoch 12 - Best Score: 0.8607\n",
      "Epoch 13 - avg_train_loss: 0.7675  avg_val_loss: 0.8016  time: 136s\n",
      "Epoch 13 - RMSE: 0.8493172582452625\n",
      "Epoch 13 - Best Score: 0.8493\n",
      "Epoch 14 - avg_train_loss: 0.7670  avg_val_loss: 0.7998  time: 136s\n",
      "Epoch 14 - RMSE: 0.8580912870848522\n",
      "Epoch 14 - Best Score: 0.8493\n",
      "Epoch 15 - avg_train_loss: 0.7596  avg_val_loss: 0.8191  time: 136s\n",
      "Epoch 15 - RMSE: 0.8697528381018174\n",
      "Epoch 15 - Best Score: 0.8493\n",
      "Epoch 16 - avg_train_loss: 0.7493  avg_val_loss: 0.7992  time: 136s\n",
      "Epoch 16 - RMSE: 0.8437342159097005\n",
      "Epoch 16 - Best Score: 0.8437\n",
      "Epoch 17 - avg_train_loss: 0.7449  avg_val_loss: 0.8243  time: 136s\n",
      "Epoch 17 - RMSE: 0.8811672410355404\n",
      "Epoch 17 - Best Score: 0.8437\n",
      "Epoch 18 - avg_train_loss: 0.7327  avg_val_loss: 0.8069  time: 136s\n",
      "Epoch 18 - RMSE: 0.8520708073214881\n",
      "Epoch 18 - Best Score: 0.8437\n",
      "Epoch 19 - avg_train_loss: 0.7223  avg_val_loss: 0.7878  time: 136s\n",
      "Epoch 19 - RMSE: 0.8468220635564077\n",
      "Epoch 19 - Best Score: 0.8437\n",
      "Epoch 20 - avg_train_loss: 0.7073  avg_val_loss: 0.8044  time: 136s\n",
      "Epoch 20 - RMSE: 0.8509368510758639\n",
      "Epoch 20 - Best Score: 0.8437\n",
      "Epoch 21 - avg_train_loss: 0.7051  avg_val_loss: 0.7735  time: 136s\n",
      "Epoch 21 - RMSE: 0.839374957944627\n",
      "Epoch 21 - Best Score: 0.8394\n",
      "Epoch 22 - avg_train_loss: 0.7010  avg_val_loss: 0.8217  time: 136s\n",
      "Epoch 22 - RMSE: 0.8702203702076189\n",
      "Epoch 22 - Best Score: 0.8394\n",
      "Epoch 23 - avg_train_loss: 0.6819  avg_val_loss: 0.7976  time: 136s\n",
      "Epoch 23 - RMSE: 0.8460021860129343\n",
      "Epoch 23 - Best Score: 0.8394\n",
      "Epoch 24 - avg_train_loss: 0.6765  avg_val_loss: 0.7863  time: 136s\n",
      "Epoch 24 - RMSE: 0.8447023891332738\n",
      "Epoch 24 - Best Score: 0.8394\n",
      "Epoch 25 - avg_train_loss: 0.6787  avg_val_loss: 0.7570  time: 136s\n",
      "Epoch 25 - RMSE: 0.8257255581975852\n",
      "Epoch 25 - Best Score: 0.8257\n",
      "Epoch 26 - avg_train_loss: 0.6653  avg_val_loss: 0.8312  time: 136s\n",
      "Epoch 26 - RMSE: 0.8653480175255001\n",
      "Epoch 26 - Best Score: 0.8257\n",
      "Epoch 27 - avg_train_loss: 0.6618  avg_val_loss: 0.7710  time: 136s\n",
      "Epoch 27 - RMSE: 0.8235386545893522\n",
      "Epoch 27 - Best Score: 0.8235\n",
      "Epoch 28 - avg_train_loss: 0.6604  avg_val_loss: 0.7496  time: 136s\n",
      "Epoch 28 - RMSE: 0.8075620946461006\n",
      "Epoch 28 - Best Score: 0.8076\n",
      "Epoch 29 - avg_train_loss: 0.6510  avg_val_loss: 0.7792  time: 136s\n",
      "Epoch 29 - RMSE: 0.8247322088407602\n",
      "Epoch 29 - Best Score: 0.8076\n",
      "Epoch 30 - avg_train_loss: 0.6367  avg_val_loss: 0.7515  time: 136s\n",
      "Epoch 30 - RMSE: 0.8030351784761286\n",
      "Epoch 30 - Best Score: 0.8030\n",
      "========== fold: 3 result ==========\n",
      "Score: 0.80304\n",
      "fold: 4\n",
      "Epoch 1 - avg_train_loss: 0.9757  avg_val_loss: 0.9324  time: 136s\n",
      "Epoch 1 - RMSE: 0.9410062429593467\n",
      "Epoch 1 - Best Score: 0.9410\n",
      "Epoch 2 - avg_train_loss: 0.9087  avg_val_loss: 0.9196  time: 136s\n",
      "Epoch 2 - RMSE: 0.9298360506980495\n",
      "Epoch 2 - Best Score: 0.9298\n",
      "Epoch 3 - avg_train_loss: 0.8988  avg_val_loss: 0.8968  time: 136s\n",
      "Epoch 3 - RMSE: 0.9326103667180079\n",
      "Epoch 3 - Best Score: 0.9298\n",
      "Epoch 4 - avg_train_loss: 0.8784  avg_val_loss: 0.9420  time: 136s\n",
      "Epoch 4 - RMSE: 0.9288615084897452\n",
      "Epoch 4 - Best Score: 0.9289\n",
      "Epoch 5 - avg_train_loss: 0.8630  avg_val_loss: 0.8936  time: 136s\n",
      "Epoch 5 - RMSE: 0.9131434966153391\n",
      "Epoch 5 - Best Score: 0.9131\n",
      "Epoch 6 - avg_train_loss: 0.8480  avg_val_loss: 0.8841  time: 136s\n",
      "Epoch 6 - RMSE: 0.9270715061948469\n",
      "Epoch 6 - Best Score: 0.9131\n",
      "Epoch 7 - avg_train_loss: 0.8390  avg_val_loss: 0.8537  time: 136s\n",
      "Epoch 7 - RMSE: 0.8923474631306223\n",
      "Epoch 7 - Best Score: 0.8923\n",
      "Epoch 8 - avg_train_loss: 0.8243  avg_val_loss: 0.8355  time: 136s\n",
      "Epoch 8 - RMSE: 0.878643943615054\n",
      "Epoch 8 - Best Score: 0.8786\n",
      "Epoch 9 - avg_train_loss: 0.8231  avg_val_loss: 0.8426  time: 136s\n",
      "Epoch 9 - RMSE: 0.8832671759660744\n",
      "Epoch 9 - Best Score: 0.8786\n",
      "Epoch 10 - avg_train_loss: 0.8178  avg_val_loss: 0.8465  time: 136s\n",
      "Epoch 10 - RMSE: 0.8931610164531769\n",
      "Epoch 10 - Best Score: 0.8786\n",
      "Epoch 11 - avg_train_loss: 0.8048  avg_val_loss: 0.8286  time: 136s\n",
      "Epoch 11 - RMSE: 0.8762635369654183\n",
      "Epoch 11 - Best Score: 0.8763\n",
      "Epoch 12 - avg_train_loss: 0.8040  avg_val_loss: 0.8300  time: 136s\n",
      "Epoch 12 - RMSE: 0.8820179404904392\n",
      "Epoch 12 - Best Score: 0.8763\n",
      "Epoch 13 - avg_train_loss: 0.7837  avg_val_loss: 0.8610  time: 136s\n",
      "Epoch 13 - RMSE: 0.8922967429584048\n",
      "Epoch 13 - Best Score: 0.8763\n",
      "Epoch 14 - avg_train_loss: 0.7876  avg_val_loss: 0.8719  time: 136s\n",
      "Epoch 14 - RMSE: 0.9014361303942452\n",
      "Epoch 14 - Best Score: 0.8763\n",
      "Epoch 15 - avg_train_loss: 0.7745  avg_val_loss: 0.8039  time: 136s\n",
      "Epoch 15 - RMSE: 0.8638721516942309\n",
      "Epoch 15 - Best Score: 0.8639\n",
      "Epoch 16 - avg_train_loss: 0.7661  avg_val_loss: 0.8120  time: 136s\n",
      "Epoch 16 - RMSE: 0.8645255544820186\n",
      "Epoch 16 - Best Score: 0.8639\n",
      "Epoch 17 - avg_train_loss: 0.7575  avg_val_loss: 0.7972  time: 136s\n",
      "Epoch 17 - RMSE: 0.8510447318552885\n",
      "Epoch 17 - Best Score: 0.8510\n",
      "Epoch 18 - avg_train_loss: 0.7521  avg_val_loss: 0.7739  time: 136s\n",
      "Epoch 18 - RMSE: 0.8349566188272748\n",
      "Epoch 18 - Best Score: 0.8350\n",
      "Epoch 19 - avg_train_loss: 0.7435  avg_val_loss: 0.7778  time: 136s\n",
      "Epoch 19 - RMSE: 0.8421936484435747\n",
      "Epoch 19 - Best Score: 0.8350\n",
      "Epoch 20 - avg_train_loss: 0.7334  avg_val_loss: 0.8002  time: 136s\n",
      "Epoch 20 - RMSE: 0.8526070668486819\n",
      "Epoch 20 - Best Score: 0.8350\n",
      "Epoch 21 - avg_train_loss: 0.7271  avg_val_loss: 0.8975  time: 136s\n",
      "Epoch 21 - RMSE: 0.8906455722207811\n",
      "Epoch 21 - Best Score: 0.8350\n",
      "Epoch 22 - avg_train_loss: 0.7141  avg_val_loss: 0.7934  time: 136s\n",
      "Epoch 22 - RMSE: 0.8573063878664643\n",
      "Epoch 22 - Best Score: 0.8350\n",
      "Epoch 23 - avg_train_loss: 0.7085  avg_val_loss: 0.7984  time: 136s\n",
      "Epoch 23 - RMSE: 0.8597495945311726\n",
      "Epoch 23 - Best Score: 0.8350\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 24 - avg_train_loss: 0.7007  avg_val_loss: 0.7849  time: 136s\n",
      "Epoch 24 - RMSE: 0.8479462687629166\n",
      "Epoch 24 - Best Score: 0.8350\n",
      "Epoch 25 - avg_train_loss: 0.6637  avg_val_loss: 0.7251  time: 136s\n",
      "Epoch 25 - RMSE: 0.8007246969259217\n",
      "Epoch 25 - Best Score: 0.8007\n",
      "Epoch 26 - avg_train_loss: 0.6393  avg_val_loss: 0.7317  time: 136s\n",
      "Epoch 26 - RMSE: 0.8028145125518671\n",
      "Epoch 26 - Best Score: 0.8007\n",
      "Epoch 27 - avg_train_loss: 0.6244  avg_val_loss: 0.7266  time: 136s\n",
      "Epoch 27 - RMSE: 0.7959518789480271\n",
      "Epoch 27 - Best Score: 0.7960\n",
      "Epoch 28 - avg_train_loss: 0.6310  avg_val_loss: 0.7241  time: 136s\n",
      "Epoch 28 - RMSE: 0.8010271938549312\n",
      "Epoch 28 - Best Score: 0.7960\n",
      "Epoch 29 - avg_train_loss: 0.6172  avg_val_loss: 0.7156  time: 136s\n",
      "Epoch 29 - RMSE: 0.7836860431108953\n",
      "Epoch 29 - Best Score: 0.7837\n",
      "Epoch 30 - avg_train_loss: 0.6148  avg_val_loss: 0.7422  time: 136s\n",
      "Epoch 30 - RMSE: 0.8051132865668654\n",
      "Epoch 30 - Best Score: 0.7837\n",
      "========== fold: 4 result ==========\n",
      "Score: 0.78369\n",
      "========== CV ==========\n",
      "Score: 0.79893\n",
      "CPU times: user 1d 10h 33min 47s, sys: 41min 31s, total: 1d 11h 15min 19s\n",
      "Wall time: 5h 39min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TrainRunner(model_config).run_cv(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ba9ba8b-317b-42a0-9a0b-c6bd8e07f462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>sorting_date</th>\n",
       "      <th>art_series_id</th>\n",
       "      <th>target</th>\n",
       "      <th>object_path</th>\n",
       "      <th>fold</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00bf812ffe8a62d45661</td>\n",
       "      <td>1720</td>\n",
       "      <td>3bfd41016d864e3fd8b5</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/00bf812ffe8a62d45661.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2.120352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0110115b8b6036d9ab3c</td>\n",
       "      <td>1741</td>\n",
       "      <td>baa4a20f0372d74dfc80</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/0110115b8b6036d9ab3c.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.989248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01273c00c46a84c50468</td>\n",
       "      <td>1757</td>\n",
       "      <td>51024cb4c6256ccce827</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/01273c00c46a84c50468.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.792500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0160840d9a4620b08fbd</td>\n",
       "      <td>1874</td>\n",
       "      <td>a56504999a8157a25d16</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/0160840d9a4620b08fbd.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2.381627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0169c493b09c8758a1b3</td>\n",
       "      <td>1734</td>\n",
       "      <td>550c62dd363fea62581c</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/0169c493b09c8758a1b3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.729081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>fe4d591332b08ab81361</td>\n",
       "      <td>1600</td>\n",
       "      <td>0782dfafa355acaf888c</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/photos/fe4d591332b08ab81361.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.259540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>fecae40c488e4c8c5ba5</td>\n",
       "      <td>1600</td>\n",
       "      <td>9ac00be75c55b1653a94</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/photos/fecae40c488e4c8c5ba5.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2.069784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>ff37540e22e1ef455368</td>\n",
       "      <td>1765</td>\n",
       "      <td>9971eebf0f583a5e51da</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/ff37540e22e1ef455368.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2.441424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>ff9124278e0f7086738f</td>\n",
       "      <td>1630</td>\n",
       "      <td>b4d508f53d16f7bcaf55</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/photos/ff9124278e0f7086738f.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2.080990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>ffd794b7b311b7b7fd92</td>\n",
       "      <td>1789</td>\n",
       "      <td>f030a01b480b18a27be2</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/ffd794b7b311b7b7fd92.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2.168762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3937 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                object_id  sorting_date         art_series_id  target  \\\n",
       "0    00bf812ffe8a62d45661          1720  3bfd41016d864e3fd8b5       2   \n",
       "1    0110115b8b6036d9ab3c          1741  baa4a20f0372d74dfc80       2   \n",
       "2    01273c00c46a84c50468          1757  51024cb4c6256ccce827       2   \n",
       "3    0160840d9a4620b08fbd          1874  a56504999a8157a25d16       3   \n",
       "4    0169c493b09c8758a1b3          1734  550c62dd363fea62581c       2   \n",
       "..                    ...           ...                   ...     ...   \n",
       "782  fe4d591332b08ab81361          1600  0782dfafa355acaf888c       0   \n",
       "783  fecae40c488e4c8c5ba5          1600  9ac00be75c55b1653a94       0   \n",
       "784  ff37540e22e1ef455368          1765  9971eebf0f583a5e51da       2   \n",
       "785  ff9124278e0f7086738f          1630  b4d508f53d16f7bcaf55       1   \n",
       "786  ffd794b7b311b7b7fd92          1789  f030a01b480b18a27be2       2   \n",
       "\n",
       "                                  object_path  fold     preds  \n",
       "0    ../input/photos/00bf812ffe8a62d45661.jpg     0  2.120352  \n",
       "1    ../input/photos/0110115b8b6036d9ab3c.jpg     0  1.989248  \n",
       "2    ../input/photos/01273c00c46a84c50468.jpg     0  1.792500  \n",
       "3    ../input/photos/0160840d9a4620b08fbd.jpg     0  2.381627  \n",
       "4    ../input/photos/0169c493b09c8758a1b3.jpg     0  1.729081  \n",
       "..                                        ...   ...       ...  \n",
       "782  ../input/photos/fe4d591332b08ab81361.jpg     4  1.259540  \n",
       "783  ../input/photos/fecae40c488e4c8c5ba5.jpg     4  2.069784  \n",
       "784  ../input/photos/ff37540e22e1ef455368.jpg     4  2.441424  \n",
       "785  ../input/photos/ff9124278e0f7086738f.jpg     4  2.080990  \n",
       "786  ../input/photos/ffd794b7b311b7b7fd92.jpg     4  2.168762  \n",
       "\n",
       "[3937 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oof_df = Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")\n",
    "# print(\"========== CV ==========\")\n",
    "# TrainRunner(model_config)._evaluate(oof_df[\"target\"], oof_df[\"preds\"])\n",
    "\n",
    "Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72e174df-3c50-4bae-a0be-dc59445ea40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")[\"preds\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2e35b9-f7b8-4ea9-96e4-6053d8dc537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "fold: 1\n",
      "fold: 2\n",
      "fold: 3\n",
      "fold: 4\n"
     ]
    }
   ],
   "source": [
    "test = load_csv(input_path.test)\n",
    "test = test.assign(object_path = test[\"object_id\"].apply(lambda x: to_img_path(input_path.photos_prefix, x)))\n",
    "InferenceRunner(model_config).run_cv(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa73ab9-d584-426e-9bac-a21e3b86a54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

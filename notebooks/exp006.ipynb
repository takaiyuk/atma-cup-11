{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a9074a-5044-4ae5-a622-79637a6e0c68",
   "metadata": {},
   "source": [
    "File Changed\n",
    "- base version: exp005\n",
    "- self-supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83dbbca5-3503-42b9-ba05-3926de5ecee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/venv/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lightly > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a08317bb-fa4d-45c8-9729-46910b084d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce6b088f-2dd0-471b-8d65-5474a0047688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InputPath:\n",
    "    _prefix: str = \"../input\"\n",
    "    train: str = f\"{_prefix}/train.csv\"\n",
    "    materials: str = f\"{_prefix}/materials.csv\"\n",
    "    techniques: str = f\"{_prefix}/techniques.csv\"\n",
    "    test: str = f\"{_prefix}/test.csv\"\n",
    "    sub: str = f\"{_prefix}/atmaCup#11_sample_submission.csv\"\n",
    "    photos_prefix: str = f\"{_prefix}/photos\"\n",
    "    photos: List[str] = field(default_factory=lambda: glob(f\"../input/photos/*.jpg\"))\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class OutputPath:\n",
    "    _prefix: str = \"../output/\"\n",
    "    model: str = f\"{_prefix}/model\"\n",
    "    submission: str = f\"{_prefix}/submission\"\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Basic:\n",
    "    run_name: str = \"exp006\"\n",
    "    is_debug: bool = False\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Kfold:\n",
    "    number: int = 5\n",
    "    method: str = \"skf\"\n",
    "    shuffle: bool = True\n",
    "    columns: List[str] = field(default_factory=lambda: [\"target\"])\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Adam:\n",
    "    name: str = \"Adam\"\n",
    "    lr: float = 1e-4\n",
    "    weight_decay: float = 0\n",
    "    amsgrad: bool = False\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class ReduceLROnPlateau:\n",
    "    name: str = \"ReduceLROnPlateau\"\n",
    "    mode: str = \"min\"\n",
    "    factor: float = 0.1\n",
    "    patience: int = 5\n",
    "    verbose: bool = True\n",
    "    eps: float = 1e-8\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Params:\n",
    "    batch_size: int = 256\n",
    "    ssl_batch_size: int =128\n",
    "    test_batch_size: int = 1024\n",
    "    epochs: int = 3 if Basic.is_debug else 30\n",
    "    image_size: int = 224\n",
    "#     max_grad_norm: int = 1000\n",
    "    num_workers: int = 0\n",
    "#     print_freq: int = 10000\n",
    "    target_size: int = 1\n",
    "    # Union[Adam]\n",
    "    optimizer: Adam = Adam()\n",
    "    # Union[CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau]\n",
    "    scheduler: ReduceLROnPlateau = ReduceLROnPlateau()\n",
    "    pretrained: bool = False\n",
    "    num_aug: int = 5\n",
    "    num_tta: int = 10\n",
    "    is_use_simsiam: bool = True\n",
    "        \n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    basic: Basic = Basic()\n",
    "    kfold: Kfold = Kfold()\n",
    "    params: Params = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72fec5d5-f634-46bc-9cb6-437c0f3b4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in os.listdir(OutputPath.model) if x.startswith(\"exp???_\"):\n",
    "#     os.remove(f\"{OutputPath.model}/{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e688a697-6d8e-40a5-89a3-56833b01cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_sessions = [x.split(\"_\")[0] for x in os.listdir(OutputPath.model) if x.endswith(\"_0.pth\")]\n",
    "assert Basic.run_name not in past_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b0b95d9-6d21-48a4-8ef9-d085e183e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class Jbl:\n",
    "    @staticmethod\n",
    "    def load(filepath: str) -> Any:\n",
    "        return joblib.load(filepath)\n",
    "\n",
    "    @staticmethod\n",
    "    def save(obj_: Any, filepath: str) -> None:\n",
    "        joblib.dump(obj_, filepath, compress=3)\n",
    "\n",
    "\n",
    "def RMSE(y: np.array, p: np.array) -> float:\n",
    "    return metrics.mean_squared_error(y, p) ** 0.5\n",
    "\n",
    "\n",
    "def fix_seed(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    \n",
    "def time_since(since: time.time, percent: float) -> str:\n",
    "    def as_minutes(s):\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return \"%dm %ds\" % (m, s)\n",
    "\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adac7d51-f744-4349-a639-7a6661370d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def to_img_path(photo_dir: str, object_id: str) -> str:\n",
    "    return os.path.join(photo_dir, f'{object_id}.jpg')\n",
    "\n",
    "def read_image(object_id: str):\n",
    "    return Image.open(to_img_path(object_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52cc936d-6003-4e02-ba1f-d42cf039cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_csv(path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "169f341c-c861-4c5d-918c-201017c494da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    GroupKFold,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    TimeSeriesSplit,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_kf(cfg: ModelConfig) -> Generator:\n",
    "    if cfg.kfold.method == \"kf\":\n",
    "        kf = KFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"skf\":\n",
    "        kf = StratifiedKFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"gkf\":\n",
    "        kf = GroupKFold(n_splits=cfg.kfold.number)\n",
    "    elif cfg.kfold.method == \"sgkf\":\n",
    "        kf = StratifiedGroupKFold(\n",
    "            n_splits=cfg.kfold.number, random_state=cfg.basic.seed\n",
    "        )\n",
    "    elif cfg.kfold.method == \"tskf\":\n",
    "        kf = TimeSeriesSplit(n_splits=cfg.kfold.number)\n",
    "    else:\n",
    "        raise ValueError(f\"{cfg.kfold.method} is not supported\")\n",
    "    return kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e1e049a-17be-4901-a59d-8d475c180753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "\n",
    "\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "class AtmaDataset(data.Dataset):\n",
    "    \"\"\"atmaCup用にデータ読み込み等を行なうデータ・セット\"\"\"\n",
    "    object_path_key = \"object_path\"\n",
    "    label_key = \"target\"\n",
    "\n",
    "    def __init__(self, meta_df: pd.DataFrame, is_train: bool = True) -> None:\n",
    "        self.is_train = is_train\n",
    "        self.meta_df = meta_df.reset_index(drop=True)\n",
    "        self.index_to_data = self.meta_df.to_dict(orient=\"index\")\n",
    "        \n",
    "        size = (ModelConfig.params.image_size, ModelConfig.params.image_size)\n",
    "        additional_items = (\n",
    "            [T.Resize(size)]\n",
    "            if not is_train\n",
    "            else [\n",
    "                T.RandomGrayscale(p=0.2),\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.ColorJitter(\n",
    "                    brightness=0.3,\n",
    "                    contrast=0.5,\n",
    "                    saturation=[0.8, 1.3],\n",
    "                    hue=[-0.05, 0.05],\n",
    "                ),\n",
    "                T.RandomResizedCrop(size),\n",
    "            ]\n",
    "        )\n",
    "        self.transformer = T.Compose(\n",
    "            [*additional_items, T.ToTensor(), T.Normalize(mean=IMG_MEAN, std=IMG_STD)]\n",
    "        )\n",
    "        \n",
    "        self._validate_meta_df(meta_df)\n",
    "\n",
    "    def __getitem__(self, index) -> Dict[str, Any]:\n",
    "        data = self.index_to_data[index]\n",
    "        obj_path, label = data.get(self.object_path_key), data.get(self.label_key, -1)\n",
    "        img = self.transformer(Image.open(obj_path))\n",
    "        return {\"image\": img, \"label\": label}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.meta_df)\n",
    "    \n",
    "    def _validate_meta_df(self, meta_df: pd.DataFrame) -> None:\n",
    "        for k in self.meta_keys:\n",
    "            if k not in meta_df:\n",
    "                raise ValueError(f\"meta df must have {k}\")\n",
    "                \n",
    "    @property\n",
    "    def meta_keys(self) -> List[str]:\n",
    "        retval = [self.object_path_key]\n",
    "        if self.is_train:\n",
    "            retval += [self.label_key]\n",
    "        return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb29cd98-7770-4f3e-813f-461679503034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from logging import Logger\n",
    "from typing import Dict, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def build_model(model_config: ModelConfig, is_use_simsiam: bool):\n",
    "    model = models.resnet34(pretrained=model_config.params.pretrained)\n",
    "    if is_use_simsiam:\n",
    "        model_state = torch.load(f\"{OutputPath.model}/{model_config.basic.run_name}_simsiam.pth\")\n",
    "        model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "        model.load_state_dict(model_state)\n",
    "        model.flatten = nn.Flatten()\n",
    "    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "class BaseRunner:\n",
    "    def __init__(self, cfg: ModelConfig):\n",
    "        self.cfg = cfg\n",
    "        self.params = cfg.params\n",
    "\n",
    "    def _get_scheduler(\n",
    "        self, optimizer: Union[optim.Adam]\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if self.params.scheduler.name == \"ReduceLROnPlateau\":\n",
    "            scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode=self.params.scheduler.mode,\n",
    "                factor=self.params.scheduler.factor,\n",
    "                patience=self.params.scheduler.patience,\n",
    "                verbose=self.params.scheduler.verbose,\n",
    "                eps=self.params.scheduler.eps,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.scheduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _step_scheduler(\n",
    "        self,\n",
    "        scheduler: Union[\n",
    "            lr_scheduler.ReduceLROnPlateau,\n",
    "        ],\n",
    "        avg_val_loss,\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.shceduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _evaluate(self, y_true: np.array, y_pred: np.array):\n",
    "        score = RMSE(y_true, y_pred)\n",
    "        print(f\"Score: {score:<.5f}\")\n",
    "\n",
    "\n",
    "class TrainRunner(BaseRunner):\n",
    "    def _train_batch(self, train_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "        losses = AverageMeter()\n",
    "        model.train()\n",
    "        for _ in range(self.cfg.params.num_aug):\n",
    "            for step, image_label_dict in enumerate(train_loader):\n",
    "                images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "                labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "                batch_size = labels.size(0)\n",
    "\n",
    "                y_preds = model(images)\n",
    "                loss = criterion(y_preds.squeeze(), labels.float())\n",
    "                losses.update(loss.item(), batch_size)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        return losses.avg\n",
    "\n",
    "    def _valid_batch(self, valid_loader, model, criterion):\n",
    "        losses = AverageMeter()\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for _, image_label_dict in enumerate(valid_loader):\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            loss = criterion(y_preds.squeeze(), labels.float())\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "        predictions = np.concatenate(preds)\n",
    "        return losses.avg, predictions\n",
    "\n",
    "    def _train(self, train: pd.DataFrame, n_fold: int) -> pd.DataFrame:\n",
    "        print(f\"fold: {n_fold}\")\n",
    "        \n",
    "        is_tta_mode = self.params.num_tta > 0\n",
    "        num_times_tta = 1 if not is_tta_mode else self.params.num_tta\n",
    "\n",
    "        trn_idx = train[train[\"fold\"] != n_fold].index\n",
    "        val_idx = train[train[\"fold\"] == n_fold].index\n",
    "        train_folds = train.loc[trn_idx].reset_index(drop=True)\n",
    "        valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "        train_dataset = AtmaDataset(\n",
    "            train_folds,\n",
    "            is_train=True,\n",
    "#             transform=get_transforms(self.params, data=\"train\"),\n",
    "        )\n",
    "        valid_dataset = AtmaDataset(\n",
    "            valid_folds,\n",
    "            is_train=is_tta_mode,\n",
    "#             transform=get_transforms(self.params, data=\"valid\"),\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        model = build_model(model_config=self.cfg, is_use_simsiam=self.params.is_use_simsiam)\n",
    "        model.to(self.cfg.basic.device)\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=self.params.optimizer.lr,\n",
    "            weight_decay=self.params.optimizer.weight_decay,\n",
    "            amsgrad=self.params.optimizer.amsgrad,\n",
    "        )\n",
    "        scheduler = self._get_scheduler(optimizer)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        best_model = None\n",
    "        best_score = np.inf\n",
    "        scores: List[float] = []\n",
    "        for epoch in range(self.params.epochs):\n",
    "            start_time = time.time()\n",
    "\n",
    "            avg_loss = self._train_batch(\n",
    "                train_loader, model, criterion, optimizer, scheduler, epoch\n",
    "            )\n",
    "            avg_val_loss_list: List[float] = []\n",
    "            preds_list: List[np.array] = []\n",
    "            for _ in range(num_times_tta):\n",
    "                avg_val_loss, preds = self._valid_batch(valid_loader, model, criterion)\n",
    "                avg_val_loss_list.append(avg_val_loss)\n",
    "                preds_list.append(preds)\n",
    "            avg_val_loss = np.mean(avg_val_loss_list)\n",
    "            preds = np.concatenate(preds_list, axis=1).mean(axis=1)\n",
    "            valid_labels = valid_folds[\"target\"].values\n",
    "            scheduler = self._step_scheduler(scheduler, avg_val_loss)\n",
    "            score = RMSE(valid_labels, preds)\n",
    "\n",
    "            scores.append(score)\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "            )\n",
    "            print(f\"Epoch {epoch+1} - RMSE: {score}\")\n",
    "            if best_score > score:\n",
    "                best_model = model\n",
    "                best_score = score\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - Best Score: {best_score:.4f}\"\n",
    "            )\n",
    "\n",
    "        torch.save(\n",
    "            {\"model\": best_model.state_dict(), \"preds\": preds, \"best_score\": best_score, \"scores\": scores},\n",
    "            f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\",\n",
    "        )\n",
    "        check_point: Dict[str, Union[OrderedDict, torch.Tensor]] = torch.load(\n",
    "            f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\"\n",
    "        )\n",
    "        valid_folds[\"preds\"] = check_point[\"preds\"]\n",
    "        return valid_folds\n",
    "\n",
    "    def run_cv(self, train: pd.DataFrame) -> None:\n",
    "        print(f\"debug mode: {self.cfg.basic.is_debug}\")\n",
    "        print(f\"start time: {datetime.datetime.now()}\")\n",
    "        oof_df = pd.DataFrame()\n",
    "        for n_fold in range(self.cfg.kfold.number):\n",
    "            _oof_df = self._train(train, n_fold)\n",
    "            print(f\"========== fold: {n_fold} result ==========\")\n",
    "            self._evaluate(_oof_df[\"target\"], _oof_df[\"preds\"])\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "        print(\"========== CV ==========\")\n",
    "        self._evaluate(oof_df[\"target\"], oof_df[\"preds\"])\n",
    "        Jbl.save(oof_df, f\"{OutputPath.model}/oof_df_{self.cfg.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9c6ec55-378b-402c-8f5b-00172c78fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceRunner(BaseRunner):\n",
    "    def _test_batch(self, test_loader, model):\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for step, image_label_dict in enumerate(test_loader):\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "        predictions = np.concatenate(preds)\n",
    "        return predictions\n",
    "\n",
    "    def _test(self, test: pd.DataFrame, n_fold: int):\n",
    "        print(f\"fold: {n_fold}\")\n",
    "        test_dataset = AtmaDataset(\n",
    "            test,\n",
    "            is_train=False,\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.params.test_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        model = build_model(model_config=self.cfg, is_use_simsiam=self.params.is_use_simsiam)\n",
    "        model_state = torch.load(f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\")[\"model\"]\n",
    "        model.load_state_dict(model_state)\n",
    "        model.to(self.cfg.basic.device)\n",
    "        preds = self._test_batch(test_loader, model)\n",
    "        return preds\n",
    "    \n",
    "    def _submit(self, preds: np.array) -> None:\n",
    "        df_sub = load_csv(input_path.sub)\n",
    "        df_sub = df_sub.assign(target=preds)\n",
    "        path = f\"{OutputPath.submission}/submission_{self.cfg.basic.run_name}.csv\"\n",
    "        df_sub.to_csv(path, index=False)\n",
    "        print(\"submission.csv created\")\n",
    "\n",
    "    def run_cv(self, test: pd.DataFrame) -> None:\n",
    "        oof_df = pd.DataFrame()\n",
    "        preds: List[np.array] = []\n",
    "        for n_fold in range(self.cfg.kfold.number):\n",
    "            preds_fold = self._test(test, n_fold)\n",
    "            preds.append(preds_fold)\n",
    "        Jbl.save(preds, f\"{OutputPath.model}/preds_test_{self.cfg.basic.run_name}.jbl\")\n",
    "        \n",
    "        preds_mean = np.concatenate(preds, axis=1).mean(axis=1)\n",
    "        self._submit(preds_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7eac973-5dac-48a9-8f5d-4976784cf6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightly\n",
    "\n",
    "\n",
    "def run_simsiam(train: pd.DataFrame, model_config: ModelConfig):\n",
    "    # define the augmentations for self-supervised learning\n",
    "    collate_fn = lightly.data.ImageCollateFunction(\n",
    "        input_size=model_config.params.image_size,\n",
    "        # require invariance to flips and rotations\n",
    "        hf_prob=0.5,\n",
    "#         vf_prob=0.5,\n",
    "#         rr_prob=0.5,\n",
    "        # satellite images are all taken from the same height\n",
    "        # so we use only slight random cropping\n",
    "#         min_scale=0.5,\n",
    "        # use a weak color jitter for invariance w.r.t small color changes\n",
    "        cj_prob=0.2,\n",
    "        cj_bright=0.1,\n",
    "        cj_contrast=0.1,\n",
    "        cj_hue=0.1,\n",
    "        cj_sat=0.1,\n",
    "    )\n",
    "\n",
    "    dataset_train_simsiam = lightly.data.LightlyDataset(\n",
    "        input_dir=InputPath.photos_prefix\n",
    "    )\n",
    "    dataloader_train_simsiam = DataLoader(\n",
    "        dataset_train_simsiam,\n",
    "        batch_size=model_config.params.ssl_batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=model_config.params.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    \n",
    "    resnet = models.resnet34(pretrained=model_config.params.pretrained)\n",
    "    backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "    model = lightly.models.SimSiam(\n",
    "        backbone,\n",
    "        num_ftrs=512,\n",
    "#         proj_hidden_dim=512,\n",
    "#         pred_hidden_dim=128,\n",
    "        out_dim=512,\n",
    "        num_mlp_layers=3,\n",
    "    )\n",
    "    \n",
    "    criterion = lightly.loss.SymNegCosineSimilarityLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=model_config.params.optimizer.lr,\n",
    "        weight_decay=model_config.params.optimizer.weight_decay,\n",
    "        amsgrad=model_config.params.optimizer.amsgrad,\n",
    "    )\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=model_config.params.scheduler.mode,\n",
    "        factor=model_config.params.scheduler.factor,\n",
    "        patience=model_config.params.scheduler.patience,\n",
    "        verbose=model_config.params.scheduler.verbose,\n",
    "        eps=model_config.params.scheduler.eps,\n",
    "    )\n",
    "    \n",
    "    avg_loss = 0.\n",
    "    avg_output_std = 0.\n",
    "    model.to(model_config.basic.device)\n",
    "    for e in range(model_config.params.epochs):\n",
    "        for (x0, x1), _, _ in dataloader_train_simsiam:\n",
    "            # move images to the gpu\n",
    "            x0 = x0.to(model_config.basic.device)\n",
    "            x1 = x1.to(model_config.basic.device)\n",
    "\n",
    "            # run the model on both transforms of the images\n",
    "            # the output of the simsiam model is a y containing the predictions\n",
    "            # and projections for each input x\n",
    "            y0, y1 = model(x0, x1)\n",
    "\n",
    "            # backpropagation\n",
    "            loss = criterion(y0, y1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # calculate the per-dimension standard deviation of the outputs\n",
    "            # we can use this later to check whether the embeddings are collapsing\n",
    "            output, _ = y0\n",
    "            output = output.detach()\n",
    "            output = torch.nn.functional.normalize(output, dim=1)\n",
    "\n",
    "            output_std = torch.std(output, 0)\n",
    "            output_std = output_std.mean()\n",
    "\n",
    "            # use moving averages to track the loss and standard deviation\n",
    "            w = 0.9\n",
    "            avg_loss = w * avg_loss + (1 - w) * loss.item()\n",
    "            avg_output_std = w * avg_output_std + (1 - w) * output_std.item()\n",
    "            \n",
    "        scheduler.step(avg_loss)\n",
    "\n",
    "        # the level of collapse is large if the standard deviation of the l2\n",
    "        # normalized output is much smaller than 1 / sqrt(dim)\n",
    "        collapse_level = max(0., 1 - math.sqrt(512) * avg_output_std)\n",
    "        # print intermediate results\n",
    "        print(f'[Epoch {e:3d}] '\n",
    "            f'Loss = {avg_loss:.2f} | '\n",
    "            f'Collapse Level: {collapse_level:.2f} / 1.00')\n",
    "    \n",
    "    torch.save(\n",
    "        model.backbone.state_dict(),\n",
    "        f\"{OutputPath.model}/{model_config.basic.run_name}_simsiam.pth\",\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eae1cb89-4ee0-4293-b935-888a14f628da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed()\n",
    "input_path = InputPath()\n",
    "model_config = ModelConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c99fafc2-2ace-488f-b2a3-1f6f3297af69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3937, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>sorting_date</th>\n",
       "      <th>art_series_id</th>\n",
       "      <th>target</th>\n",
       "      <th>object_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002bff09b09998d0be65</td>\n",
       "      <td>1631</td>\n",
       "      <td>509357f67692a6a45626</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/photos/002bff09b09998d0be65.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00309fb1ef05416f9c1f</td>\n",
       "      <td>1900</td>\n",
       "      <td>7987b47bbe5dc3039179</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/00309fb1ef05416f9c1f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003a1562e97f79ba96dc</td>\n",
       "      <td>1834</td>\n",
       "      <td>ded7c3c9636708e5b14c</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/003a1562e97f79ba96dc.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              object_id  sorting_date         art_series_id  target  \\\n",
       "0  002bff09b09998d0be65          1631  509357f67692a6a45626       1   \n",
       "1  00309fb1ef05416f9c1f          1900  7987b47bbe5dc3039179       3   \n",
       "2  003a1562e97f79ba96dc          1834  ded7c3c9636708e5b14c       3   \n",
       "\n",
       "                                object_path  \n",
       "0  ../input/photos/002bff09b09998d0be65.jpg  \n",
       "1  ../input/photos/00309fb1ef05416f9c1f.jpg  \n",
       "2  ../input/photos/003a1562e97f79ba96dc.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = load_csv(input_path.train)\n",
    "train = train.assign(object_path = train[\"object_id\"].apply(lambda x: to_img_path(input_path.photos_prefix, x)))\n",
    "print(train.shape)\n",
    "display(train.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8796a89d-9fce-49b6-8d53-3c315b65722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 - [0 1 2 3 4]~[3928 3930 3933 3934 3935]\t[ 8 14 16 19 21]~[3922 3929 3931 3932 3936]\n",
      "fold: 1 - [0 1 2 4 5]~[3931 3932 3933 3934 3936]\t[ 3  9 20 23 24]~[3899 3907 3912 3925 3935]\n",
      "fold: 2 - [0 1 2 3 5]~[3931 3932 3934 3935 3936]\t[ 4  6 10 11 12]~[3913 3915 3924 3927 3933]\n",
      "fold: 3 - [2 3 4 5 6]~[3932 3933 3934 3935 3936]\t[ 0  1  7 17 29]~[3914 3916 3919 3923 3926]\n",
      "fold: 4 - [0 1 3 4 6]~[3931 3932 3933 3935 3936]\t[ 2  5 22 31 32]~[3909 3918 3928 3930 3934]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "fold target     \n",
       "0    0        95\n",
       "     1       180\n",
       "     2       302\n",
       "     3       211\n",
       "1    0        95\n",
       "     1       179\n",
       "     2       303\n",
       "     3       211\n",
       "2    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211\n",
       "3    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211\n",
       "4    0        95\n",
       "     1       179\n",
       "     2       302\n",
       "     3       211"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kf = generate_kf(model_config)\n",
    "if model_config.kfold.method.endswith(\"gkf\"):\n",
    "    kf_generator = kf.split(\n",
    "        train,\n",
    "        train[self.fe_cfg.column.target],\n",
    "        groups=train[self.kfold.columns],\n",
    "    )\n",
    "else:\n",
    "    kf_generator = kf.split(train, train[\"target\"])\n",
    "for fold_i, (tr_idx, val_idx) in enumerate(kf_generator):\n",
    "    print(\n",
    "        f\"fold: {fold_i} - {tr_idx[:5]}~{tr_idx[-5:]}\\t{val_idx[:5]}~{val_idx[-5:]}\"\n",
    "    )\n",
    "    train.loc[val_idx, \"fold\"] = fold_i\n",
    "train = train.assign(fold = train[\"fold\"].astype(int))\n",
    "if model_config.kfold.method == \"skf\":\n",
    "    display(train.groupby([\"fold\", \"target\"]).size().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f31800b5-e7c9-4305-aa90-3891b166f692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   0] Loss = -0.87 | Collapse Level: 0.22 / 1.00\n",
      "[Epoch   1] Loss = -0.90 | Collapse Level: 0.22 / 1.00\n",
      "[Epoch   2] Loss = -0.90 | Collapse Level: 0.19 / 1.00\n",
      "[Epoch   3] Loss = -0.90 | Collapse Level: 0.18 / 1.00\n",
      "[Epoch   4] Loss = -0.85 | Collapse Level: 0.07 / 1.00\n",
      "[Epoch   5] Loss = -0.85 | Collapse Level: 0.09 / 1.00\n",
      "[Epoch   6] Loss = -0.88 | Collapse Level: 0.13 / 1.00\n",
      "[Epoch   7] Loss = -0.89 | Collapse Level: 0.10 / 1.00\n",
      "[Epoch   8] Loss = -0.87 | Collapse Level: 0.10 / 1.00\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-05.\n",
      "[Epoch   9] Loss = -0.88 | Collapse Level: 0.09 / 1.00\n",
      "[Epoch  10] Loss = -0.88 | Collapse Level: 0.08 / 1.00\n",
      "[Epoch  11] Loss = -0.89 | Collapse Level: 0.06 / 1.00\n",
      "[Epoch  12] Loss = -0.89 | Collapse Level: 0.06 / 1.00\n",
      "[Epoch  13] Loss = -0.88 | Collapse Level: 0.07 / 1.00\n",
      "[Epoch  14] Loss = -0.89 | Collapse Level: 0.07 / 1.00\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-06.\n",
      "[Epoch  15] Loss = -0.89 | Collapse Level: 0.08 / 1.00\n",
      "[Epoch  16] Loss = -0.88 | Collapse Level: 0.08 / 1.00\n",
      "[Epoch  17] Loss = -0.88 | Collapse Level: 0.08 / 1.00\n",
      "[Epoch  18] Loss = -0.89 | Collapse Level: 0.08 / 1.00\n",
      "[Epoch  19] Loss = -0.88 | Collapse Level: 0.08 / 1.00\n",
      "[Epoch  20] Loss = -0.88 | Collapse Level: 0.08 / 1.00\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-07.\n",
      "[Epoch  21] Loss = -0.88 | Collapse Level: 0.08 / 1.00\n",
      "[Epoch  22] Loss = -0.87 | Collapse Level: 0.08 / 1.00\n",
      "[Epoch  23] Loss = -0.88 | Collapse Level: 0.09 / 1.00\n",
      "[Epoch  24] Loss = -0.89 | Collapse Level: 0.08 / 1.00\n",
      "[Epoch  25] Loss = -0.88 | Collapse Level: 0.08 / 1.00\n",
      "[Epoch  26] Loss = -0.89 | Collapse Level: 0.09 / 1.00\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-08.\n",
      "[Epoch  27] Loss = -0.89 | Collapse Level: 0.08 / 1.00\n",
      "[Epoch  28] Loss = -0.88 | Collapse Level: 0.08 / 1.00\n",
      "[Epoch  29] Loss = -0.88 | Collapse Level: 0.08 / 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimSiam(\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (projection_mlp): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (prediction_mlp): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_simsiam(train, model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b4ff32c-e413-4148-88d6-a69f99c135c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug mode: False\n",
      "start time: 2021-07-22 03:05:22.013063\n",
      "fold: 0\n",
      "Epoch 1 - avg_train_loss: 1.2815  avg_val_loss: 0.9718  time: 137s\n",
      "Epoch 1 - RMSE: 0.9684758820015803\n",
      "Epoch 1 - Best Score: 0.9685\n",
      "Epoch 2 - avg_train_loss: 0.8882  avg_val_loss: 0.8559  time: 136s\n",
      "Epoch 2 - RMSE: 0.9050532809554791\n",
      "Epoch 2 - Best Score: 0.9051\n",
      "Epoch 3 - avg_train_loss: 0.8694  avg_val_loss: 0.8875  time: 137s\n",
      "Epoch 3 - RMSE: 0.9154829958963981\n",
      "Epoch 3 - Best Score: 0.9051\n",
      "Epoch 4 - avg_train_loss: 0.8487  avg_val_loss: 0.8720  time: 137s\n",
      "Epoch 4 - RMSE: 0.9048001699610339\n",
      "Epoch 4 - Best Score: 0.9048\n",
      "Epoch 5 - avg_train_loss: 0.8274  avg_val_loss: 1.0187  time: 137s\n",
      "Epoch 5 - RMSE: 0.9769899478479811\n",
      "Epoch 5 - Best Score: 0.9048\n",
      "Epoch 6 - avg_train_loss: 0.8353  avg_val_loss: 0.9766  time: 137s\n",
      "Epoch 6 - RMSE: 0.9626348535923572\n",
      "Epoch 6 - Best Score: 0.9048\n",
      "Epoch 7 - avg_train_loss: 0.8349  avg_val_loss: 0.8335  time: 138s\n",
      "Epoch 7 - RMSE: 0.8880173254902319\n",
      "Epoch 7 - Best Score: 0.8880\n",
      "Epoch 8 - avg_train_loss: 0.8084  avg_val_loss: 0.9164  time: 137s\n",
      "Epoch 8 - RMSE: 0.9102082360585133\n",
      "Epoch 8 - Best Score: 0.8880\n",
      "Epoch 9 - avg_train_loss: 0.8153  avg_val_loss: 0.8337  time: 137s\n",
      "Epoch 9 - RMSE: 0.8840814428627237\n",
      "Epoch 9 - Best Score: 0.8841\n",
      "Epoch 10 - avg_train_loss: 0.7949  avg_val_loss: 0.8017  time: 137s\n",
      "Epoch 10 - RMSE: 0.8649981725644409\n",
      "Epoch 10 - Best Score: 0.8650\n",
      "Epoch 11 - avg_train_loss: 0.7824  avg_val_loss: 0.8920  time: 138s\n",
      "Epoch 11 - RMSE: 0.9037910980603228\n",
      "Epoch 11 - Best Score: 0.8650\n",
      "Epoch 12 - avg_train_loss: 0.7889  avg_val_loss: 0.9052  time: 138s\n",
      "Epoch 12 - RMSE: 0.9073823505206604\n",
      "Epoch 12 - Best Score: 0.8650\n",
      "Epoch 13 - avg_train_loss: 0.7708  avg_val_loss: 0.7992  time: 137s\n",
      "Epoch 13 - RMSE: 0.8564344143040897\n",
      "Epoch 13 - Best Score: 0.8564\n",
      "Epoch 14 - avg_train_loss: 0.7637  avg_val_loss: 1.0073  time: 137s\n",
      "Epoch 14 - RMSE: 0.9330600013268967\n",
      "Epoch 14 - Best Score: 0.8564\n",
      "Epoch 15 - avg_train_loss: 0.7574  avg_val_loss: 0.9190  time: 138s\n",
      "Epoch 15 - RMSE: 0.9101143902733762\n",
      "Epoch 15 - Best Score: 0.8564\n",
      "Epoch 16 - avg_train_loss: 0.7475  avg_val_loss: 0.9255  time: 137s\n",
      "Epoch 16 - RMSE: 0.9010626117400249\n",
      "Epoch 16 - Best Score: 0.8564\n",
      "Epoch 17 - avg_train_loss: 0.7507  avg_val_loss: 0.7976  time: 137s\n",
      "Epoch 17 - RMSE: 0.8512776882056433\n",
      "Epoch 17 - Best Score: 0.8513\n",
      "Epoch 18 - avg_train_loss: 0.7395  avg_val_loss: 0.7842  time: 137s\n",
      "Epoch 18 - RMSE: 0.8524880240325893\n",
      "Epoch 18 - Best Score: 0.8513\n",
      "Epoch 19 - avg_train_loss: 0.7363  avg_val_loss: 0.7873  time: 137s\n",
      "Epoch 19 - RMSE: 0.8447891187013408\n",
      "Epoch 19 - Best Score: 0.8448\n",
      "Epoch 20 - avg_train_loss: 0.7302  avg_val_loss: 0.8188  time: 137s\n",
      "Epoch 20 - RMSE: 0.8612978210291102\n",
      "Epoch 20 - Best Score: 0.8448\n",
      "Epoch 21 - avg_train_loss: 0.7379  avg_val_loss: 0.8090  time: 138s\n",
      "Epoch 21 - RMSE: 0.8493908712103178\n",
      "Epoch 21 - Best Score: 0.8448\n",
      "Epoch 22 - avg_train_loss: 0.7236  avg_val_loss: 0.7616  time: 137s\n",
      "Epoch 22 - RMSE: 0.8285090284954102\n",
      "Epoch 22 - Best Score: 0.8285\n",
      "Epoch 23 - avg_train_loss: 0.7112  avg_val_loss: 0.7663  time: 138s\n",
      "Epoch 23 - RMSE: 0.8387164171959213\n",
      "Epoch 23 - Best Score: 0.8285\n",
      "Epoch 24 - avg_train_loss: 0.7053  avg_val_loss: 0.8147  time: 137s\n",
      "Epoch 24 - RMSE: 0.8610766256950765\n",
      "Epoch 24 - Best Score: 0.8285\n",
      "Epoch 25 - avg_train_loss: 0.7033  avg_val_loss: 0.7814  time: 137s\n",
      "Epoch 25 - RMSE: 0.8334686342835456\n",
      "Epoch 25 - Best Score: 0.8285\n",
      "Epoch 26 - avg_train_loss: 0.6973  avg_val_loss: 0.7769  time: 137s\n",
      "Epoch 26 - RMSE: 0.8230553279974988\n",
      "Epoch 26 - Best Score: 0.8231\n",
      "Epoch 27 - avg_train_loss: 0.6830  avg_val_loss: 0.7862  time: 137s\n",
      "Epoch 27 - RMSE: 0.8338344352658137\n",
      "Epoch 27 - Best Score: 0.8231\n",
      "Epoch 28 - avg_train_loss: 0.6879  avg_val_loss: 0.7605  time: 137s\n",
      "Epoch 28 - RMSE: 0.8247444356244517\n",
      "Epoch 28 - Best Score: 0.8231\n",
      "Epoch 29 - avg_train_loss: 0.6707  avg_val_loss: 0.8130  time: 137s\n",
      "Epoch 29 - RMSE: 0.8505889083871663\n",
      "Epoch 29 - Best Score: 0.8231\n",
      "Epoch 30 - avg_train_loss: 0.6675  avg_val_loss: 0.7706  time: 137s\n",
      "Epoch 30 - RMSE: 0.8169452029372462\n",
      "Epoch 30 - Best Score: 0.8169\n",
      "========== fold: 0 result ==========\n",
      "Score: 0.81695\n",
      "fold: 1\n",
      "Epoch 1 - avg_train_loss: 0.9677  avg_val_loss: 0.9630  time: 137s\n",
      "Epoch 1 - RMSE: 0.959898195082015\n",
      "Epoch 1 - Best Score: 0.9599\n",
      "Epoch 2 - avg_train_loss: 0.8777  avg_val_loss: 0.8682  time: 137s\n",
      "Epoch 2 - RMSE: 0.9162490526362013\n",
      "Epoch 2 - Best Score: 0.9162\n",
      "Epoch 3 - avg_train_loss: 0.8412  avg_val_loss: 0.9220  time: 138s\n",
      "Epoch 3 - RMSE: 0.9386211963845142\n",
      "Epoch 3 - Best Score: 0.9162\n",
      "Epoch 4 - avg_train_loss: 0.8248  avg_val_loss: 0.8915  time: 137s\n",
      "Epoch 4 - RMSE: 0.8982995442426384\n",
      "Epoch 4 - Best Score: 0.8983\n",
      "Epoch 5 - avg_train_loss: 0.8266  avg_val_loss: 0.8642  time: 137s\n",
      "Epoch 5 - RMSE: 0.9037881901831614\n",
      "Epoch 5 - Best Score: 0.8983\n",
      "Epoch 6 - avg_train_loss: 0.8126  avg_val_loss: 0.9932  time: 137s\n",
      "Epoch 6 - RMSE: 0.9607123007152755\n",
      "Epoch 6 - Best Score: 0.8983\n",
      "Epoch 7 - avg_train_loss: 0.8019  avg_val_loss: 0.8512  time: 137s\n",
      "Epoch 7 - RMSE: 0.8953397101799111\n",
      "Epoch 7 - Best Score: 0.8953\n",
      "Epoch 8 - avg_train_loss: 0.8025  avg_val_loss: 0.8325  time: 137s\n",
      "Epoch 8 - RMSE: 0.8742888827045587\n",
      "Epoch 8 - Best Score: 0.8743\n",
      "Epoch 9 - avg_train_loss: 0.7958  avg_val_loss: 0.8255  time: 137s\n",
      "Epoch 9 - RMSE: 0.8731428898553847\n",
      "Epoch 9 - Best Score: 0.8731\n",
      "Epoch 10 - avg_train_loss: 0.7794  avg_val_loss: 0.8076  time: 137s\n",
      "Epoch 10 - RMSE: 0.8612659835944756\n",
      "Epoch 10 - Best Score: 0.8613\n",
      "Epoch 11 - avg_train_loss: 0.7764  avg_val_loss: 0.8141  time: 137s\n",
      "Epoch 11 - RMSE: 0.8663939849543324\n",
      "Epoch 11 - Best Score: 0.8613\n",
      "Epoch 12 - avg_train_loss: 0.7698  avg_val_loss: 0.8071  time: 137s\n",
      "Epoch 12 - RMSE: 0.866270717156221\n",
      "Epoch 12 - Best Score: 0.8613\n",
      "Epoch 13 - avg_train_loss: 0.7569  avg_val_loss: 0.8088  time: 138s\n",
      "Epoch 13 - RMSE: 0.8585841433848928\n",
      "Epoch 13 - Best Score: 0.8586\n",
      "Epoch 14 - avg_train_loss: 0.7557  avg_val_loss: 0.7894  time: 137s\n",
      "Epoch 14 - RMSE: 0.8505569970842188\n",
      "Epoch 14 - Best Score: 0.8506\n",
      "Epoch 15 - avg_train_loss: 0.7378  avg_val_loss: 0.8152  time: 137s\n",
      "Epoch 15 - RMSE: 0.860253257581983\n",
      "Epoch 15 - Best Score: 0.8506\n",
      "Epoch 16 - avg_train_loss: 0.7511  avg_val_loss: 0.8716  time: 137s\n",
      "Epoch 16 - RMSE: 0.8879926468971934\n",
      "Epoch 16 - Best Score: 0.8506\n",
      "Epoch 17 - avg_train_loss: 0.7403  avg_val_loss: 0.8035  time: 137s\n",
      "Epoch 17 - RMSE: 0.848668631789921\n",
      "Epoch 17 - Best Score: 0.8487\n",
      "Epoch 18 - avg_train_loss: 0.7247  avg_val_loss: 0.8165  time: 137s\n",
      "Epoch 18 - RMSE: 0.8615131105199982\n",
      "Epoch 18 - Best Score: 0.8487\n",
      "Epoch 19 - avg_train_loss: 0.7128  avg_val_loss: 0.8122  time: 137s\n",
      "Epoch 19 - RMSE: 0.8551593071419633\n",
      "Epoch 19 - Best Score: 0.8487\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 20 - avg_train_loss: 0.7064  avg_val_loss: 0.8083  time: 137s\n",
      "Epoch 20 - RMSE: 0.8458140824709004\n",
      "Epoch 20 - Best Score: 0.8458\n",
      "Epoch 21 - avg_train_loss: 0.6837  avg_val_loss: 0.7322  time: 137s\n",
      "Epoch 21 - RMSE: 0.8064671759534113\n",
      "Epoch 21 - Best Score: 0.8065\n",
      "Epoch 22 - avg_train_loss: 0.6657  avg_val_loss: 0.7295  time: 137s\n",
      "Epoch 22 - RMSE: 0.8029287178286545\n",
      "Epoch 22 - Best Score: 0.8029\n",
      "Epoch 23 - avg_train_loss: 0.6511  avg_val_loss: 0.7091  time: 138s\n",
      "Epoch 23 - RMSE: 0.7907690801111202\n",
      "Epoch 23 - Best Score: 0.7908\n",
      "Epoch 24 - avg_train_loss: 0.6583  avg_val_loss: 0.7318  time: 138s\n",
      "Epoch 24 - RMSE: 0.8046844520789287\n",
      "Epoch 24 - Best Score: 0.7908\n",
      "Epoch 26 - avg_train_loss: 0.6439  avg_val_loss: 0.7337  time: 137s\n",
      "Epoch 26 - RMSE: 0.8009173030138221\n",
      "Epoch 26 - Best Score: 0.7908\n",
      "Epoch 27 - avg_train_loss: 0.6464  avg_val_loss: 0.7278  time: 137s\n",
      "Epoch 27 - RMSE: 0.8023172514439454\n",
      "Epoch 27 - Best Score: 0.7908\n",
      "Epoch 28 - avg_train_loss: 0.6385  avg_val_loss: 0.7471  time: 137s\n",
      "Epoch 28 - RMSE: 0.8099211921337557\n",
      "Epoch 28 - Best Score: 0.7908\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 29 - avg_train_loss: 0.6431  avg_val_loss: 0.7276  time: 137s\n",
      "Epoch 29 - RMSE: 0.8010139420444637\n",
      "Epoch 29 - Best Score: 0.7908\n",
      "Epoch 30 - avg_train_loss: 0.6394  avg_val_loss: 0.7237  time: 137s\n",
      "Epoch 30 - RMSE: 0.7992663189494685\n",
      "Epoch 30 - Best Score: 0.7908\n",
      "========== fold: 1 result ==========\n",
      "Score: 0.79927\n",
      "fold: 2\n",
      "Epoch 1 - avg_train_loss: 1.0950  avg_val_loss: 0.8989  time: 137s\n",
      "Epoch 1 - RMSE: 0.9321615444131228\n",
      "Epoch 1 - Best Score: 0.9322\n",
      "Epoch 2 - avg_train_loss: 0.8879  avg_val_loss: 0.9484  time: 137s\n",
      "Epoch 2 - RMSE: 0.9504935434589137\n",
      "Epoch 2 - Best Score: 0.9322\n",
      "Epoch 3 - avg_train_loss: 0.8498  avg_val_loss: 0.9100  time: 137s\n",
      "Epoch 3 - RMSE: 0.9307096564777015\n",
      "Epoch 3 - Best Score: 0.9307\n",
      "Epoch 4 - avg_train_loss: 0.8303  avg_val_loss: 0.8615  time: 137s\n",
      "Epoch 4 - RMSE: 0.9034518378034758\n",
      "Epoch 4 - Best Score: 0.9035\n",
      "Epoch 5 - avg_train_loss: 0.8232  avg_val_loss: 0.9195  time: 137s\n",
      "Epoch 5 - RMSE: 0.909652533800802\n",
      "Epoch 5 - Best Score: 0.9035\n",
      "Epoch 6 - avg_train_loss: 0.8070  avg_val_loss: 1.0171  time: 137s\n",
      "Epoch 6 - RMSE: 0.9687829167482995\n",
      "Epoch 6 - Best Score: 0.9035\n",
      "Epoch 7 - avg_train_loss: 0.8038  avg_val_loss: 0.9481  time: 137s\n",
      "Epoch 7 - RMSE: 0.9196732811436555\n",
      "Epoch 7 - Best Score: 0.9035\n",
      "Epoch 8 - avg_train_loss: 0.7999  avg_val_loss: 0.8985  time: 137s\n",
      "Epoch 8 - RMSE: 0.9127794074495618\n",
      "Epoch 8 - Best Score: 0.9035\n",
      "Epoch 10 - avg_train_loss: 0.7769  avg_val_loss: 0.8797  time: 137s\n",
      "Epoch 10 - RMSE: 0.9027285849745991\n",
      "Epoch 10 - Best Score: 0.8733\n",
      "Epoch 11 - avg_train_loss: 0.7674  avg_val_loss: 0.8138  time: 137s\n",
      "Epoch 11 - RMSE: 0.869444638262637\n",
      "Epoch 11 - Best Score: 0.8694\n",
      "Epoch 12 - avg_train_loss: 0.7624  avg_val_loss: 0.8301  time: 137s\n",
      "Epoch 12 - RMSE: 0.8713295442676884\n",
      "Epoch 12 - Best Score: 0.8694\n",
      "Epoch 13 - avg_train_loss: 0.7627  avg_val_loss: 0.8633  time: 137s\n",
      "Epoch 13 - RMSE: 0.8969836852524508\n",
      "Epoch 13 - Best Score: 0.8694\n",
      "Epoch 14 - avg_train_loss: 0.7433  avg_val_loss: 0.8033  time: 138s\n",
      "Epoch 14 - RMSE: 0.8571623416735342\n",
      "Epoch 14 - Best Score: 0.8572\n",
      "Epoch 15 - avg_train_loss: 0.7427  avg_val_loss: 0.8365  time: 137s\n",
      "Epoch 15 - RMSE: 0.8801703887464677\n",
      "Epoch 15 - Best Score: 0.8572\n",
      "Epoch 16 - avg_train_loss: 0.7394  avg_val_loss: 0.8040  time: 137s\n",
      "Epoch 16 - RMSE: 0.8645547015391156\n",
      "Epoch 16 - Best Score: 0.8572\n",
      "Epoch 17 - avg_train_loss: 0.7286  avg_val_loss: 0.8244  time: 136s\n",
      "Epoch 17 - RMSE: 0.8714615151084859\n",
      "Epoch 17 - Best Score: 0.8572\n",
      "Epoch 18 - avg_train_loss: 0.7180  avg_val_loss: 0.8016  time: 137s\n",
      "Epoch 18 - RMSE: 0.8498545114538959\n",
      "Epoch 18 - Best Score: 0.8499\n",
      "Epoch 19 - avg_train_loss: 0.7182  avg_val_loss: 0.7765  time: 137s\n",
      "Epoch 19 - RMSE: 0.8380024356979512\n",
      "Epoch 19 - Best Score: 0.8380\n",
      "Epoch 20 - avg_train_loss: 0.7149  avg_val_loss: 0.8081  time: 137s\n",
      "Epoch 20 - RMSE: 0.8518186884563604\n",
      "Epoch 20 - Best Score: 0.8380\n",
      "Epoch 21 - avg_train_loss: 0.6933  avg_val_loss: 0.7762  time: 137s\n",
      "Epoch 21 - RMSE: 0.8346205438047479\n",
      "Epoch 21 - Best Score: 0.8346\n",
      "Epoch 22 - avg_train_loss: 0.6862  avg_val_loss: 0.8237  time: 137s\n",
      "Epoch 22 - RMSE: 0.8555399182289594\n",
      "Epoch 22 - Best Score: 0.8346\n",
      "Epoch 23 - avg_train_loss: 0.6954  avg_val_loss: 0.7754  time: 137s\n",
      "Epoch 23 - RMSE: 0.824626674108705\n",
      "Epoch 23 - Best Score: 0.8246\n",
      "Epoch 24 - avg_train_loss: 0.6853  avg_val_loss: 0.8125  time: 138s\n",
      "Epoch 24 - RMSE: 0.8452567105409122\n",
      "Epoch 24 - Best Score: 0.8246\n",
      "Epoch 25 - avg_train_loss: 0.6763  avg_val_loss: 0.7812  time: 137s\n",
      "Epoch 25 - RMSE: 0.8452150920760961\n",
      "Epoch 25 - Best Score: 0.8246\n",
      "Epoch 26 - avg_train_loss: 0.6583  avg_val_loss: 0.8672  time: 137s\n",
      "Epoch 26 - RMSE: 0.8689714336585508\n",
      "Epoch 26 - Best Score: 0.8246\n",
      "Epoch 27 - avg_train_loss: 0.6726  avg_val_loss: 0.7867  time: 137s\n",
      "Epoch 27 - RMSE: 0.8272777817778678\n",
      "Epoch 27 - Best Score: 0.8246\n",
      "Epoch 28 - avg_train_loss: 0.6568  avg_val_loss: 0.8016  time: 138s\n",
      "Epoch 28 - RMSE: 0.8386736190725349\n",
      "Epoch 28 - Best Score: 0.8246\n",
      "Epoch 30 - avg_train_loss: 0.6200  avg_val_loss: 0.7255  time: 138s\n",
      "Epoch 30 - RMSE: 0.7973583832303875\n",
      "Epoch 30 - Best Score: 0.7974\n",
      "========== fold: 2 result ==========\n",
      "Score: 0.79736\n",
      "fold: 3\n",
      "Epoch 1 - avg_train_loss: 1.0542  avg_val_loss: 0.8853  time: 138s\n",
      "Epoch 1 - RMSE: 0.9200639736108235\n",
      "Epoch 1 - Best Score: 0.9201\n",
      "Epoch 2 - avg_train_loss: 0.8682  avg_val_loss: 0.9884  time: 138s\n",
      "Epoch 2 - RMSE: 0.972360704213803\n",
      "Epoch 2 - Best Score: 0.9201\n",
      "Epoch 3 - avg_train_loss: 0.8630  avg_val_loss: 0.8462  time: 137s\n",
      "Epoch 3 - RMSE: 0.9021483226194543\n",
      "Epoch 3 - Best Score: 0.9021\n",
      "Epoch 4 - avg_train_loss: 0.8323  avg_val_loss: 0.8600  time: 137s\n",
      "Epoch 4 - RMSE: 0.9074388916345326\n",
      "Epoch 4 - Best Score: 0.9021\n",
      "Epoch 5 - avg_train_loss: 0.8232  avg_val_loss: 0.8385  time: 137s\n",
      "Epoch 5 - RMSE: 0.8883806286402817\n",
      "Epoch 5 - Best Score: 0.8884\n",
      "Epoch 6 - avg_train_loss: 0.8106  avg_val_loss: 0.8968  time: 137s\n",
      "Epoch 6 - RMSE: 0.9101875125463527\n",
      "Epoch 6 - Best Score: 0.8884\n",
      "Epoch 7 - avg_train_loss: 0.8158  avg_val_loss: 0.9155  time: 137s\n",
      "Epoch 7 - RMSE: 0.8935427374058533\n",
      "Epoch 7 - Best Score: 0.8884\n",
      "Epoch 8 - avg_train_loss: 0.8023  avg_val_loss: 0.8846  time: 137s\n",
      "Epoch 8 - RMSE: 0.9094557984873071\n",
      "Epoch 8 - Best Score: 0.8884\n",
      "Epoch 9 - avg_train_loss: 0.7974  avg_val_loss: 0.9586  time: 137s\n",
      "Epoch 9 - RMSE: 0.9251741199268955\n",
      "Epoch 9 - Best Score: 0.8884\n",
      "Epoch 10 - avg_train_loss: 0.7745  avg_val_loss: 0.9595  time: 137s\n",
      "Epoch 10 - RMSE: 0.9277936514840734\n",
      "Epoch 10 - Best Score: 0.8884\n",
      "Epoch 11 - avg_train_loss: 0.7744  avg_val_loss: 0.8066  time: 137s\n",
      "Epoch 11 - RMSE: 0.8566153159209674\n",
      "Epoch 11 - Best Score: 0.8566\n",
      "Epoch 12 - avg_train_loss: 0.7720  avg_val_loss: 0.8294  time: 137s\n",
      "Epoch 12 - RMSE: 0.8814789361145771\n",
      "Epoch 12 - Best Score: 0.8566\n",
      "Epoch 13 - avg_train_loss: 0.7612  avg_val_loss: 0.8834  time: 137s\n",
      "Epoch 13 - RMSE: 0.8929824694755724\n",
      "Epoch 13 - Best Score: 0.8566\n",
      "Epoch 14 - avg_train_loss: 0.7597  avg_val_loss: 0.8345  time: 137s\n",
      "Epoch 14 - RMSE: 0.8665017806917736\n",
      "Epoch 14 - Best Score: 0.8566\n",
      "Epoch 15 - avg_train_loss: 0.7483  avg_val_loss: 0.8544  time: 137s\n",
      "Epoch 15 - RMSE: 0.8782491524370599\n",
      "Epoch 15 - Best Score: 0.8566\n",
      "Epoch 16 - avg_train_loss: 0.7457  avg_val_loss: 0.8144  time: 137s\n",
      "Epoch 16 - RMSE: 0.8657541898822346\n",
      "Epoch 16 - Best Score: 0.8566\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 17 - avg_train_loss: 0.7367  avg_val_loss: 0.8080  time: 137s\n",
      "Epoch 17 - RMSE: 0.8589960737464335\n",
      "Epoch 17 - Best Score: 0.8566\n",
      "Epoch 18 - avg_train_loss: 0.7001  avg_val_loss: 0.7803  time: 137s\n",
      "Epoch 18 - RMSE: 0.8416483042821682\n",
      "Epoch 18 - Best Score: 0.8416\n",
      "Epoch 19 - avg_train_loss: 0.6968  avg_val_loss: 0.7629  time: 137s\n",
      "Epoch 19 - RMSE: 0.8309479918809264\n",
      "Epoch 19 - Best Score: 0.8309\n",
      "Epoch 20 - avg_train_loss: 0.6906  avg_val_loss: 0.7772  time: 137s\n",
      "Epoch 20 - RMSE: 0.8369165713044692\n",
      "Epoch 20 - Best Score: 0.8309\n",
      "Epoch 21 - avg_train_loss: 0.6799  avg_val_loss: 0.7571  time: 137s\n",
      "Epoch 21 - RMSE: 0.8258819370076156\n",
      "Epoch 21 - Best Score: 0.8259\n",
      "Epoch 22 - avg_train_loss: 0.6743  avg_val_loss: 0.7574  time: 137s\n",
      "Epoch 22 - RMSE: 0.8215260238930336\n",
      "Epoch 22 - Best Score: 0.8215\n",
      "Epoch 23 - avg_train_loss: 0.6710  avg_val_loss: 0.7500  time: 137s\n",
      "Epoch 23 - RMSE: 0.8224105197287332\n",
      "Epoch 23 - Best Score: 0.8215\n",
      "Epoch 24 - avg_train_loss: 0.6660  avg_val_loss: 0.7524  time: 137s\n",
      "Epoch 24 - RMSE: 0.8201447390989333\n",
      "Epoch 24 - Best Score: 0.8201\n",
      "Epoch 25 - avg_train_loss: 0.6627  avg_val_loss: 0.7566  time: 137s\n",
      "Epoch 25 - RMSE: 0.8210916877422156\n",
      "Epoch 25 - Best Score: 0.8201\n",
      "Epoch 26 - avg_train_loss: 0.6707  avg_val_loss: 0.7630  time: 137s\n",
      "Epoch 26 - RMSE: 0.8276259500983123\n",
      "Epoch 26 - Best Score: 0.8201\n",
      "Epoch 27 - avg_train_loss: 0.6618  avg_val_loss: 0.7616  time: 137s\n",
      "Epoch 27 - RMSE: 0.8249391873732458\n",
      "Epoch 27 - Best Score: 0.8201\n",
      "Epoch 28 - avg_train_loss: 0.6675  avg_val_loss: 0.7471  time: 137s\n",
      "Epoch 28 - RMSE: 0.8177542608709036\n",
      "Epoch 28 - Best Score: 0.8178\n",
      "Epoch 29 - avg_train_loss: 0.6490  avg_val_loss: 0.7501  time: 137s\n",
      "Epoch 29 - RMSE: 0.8174035899660143\n",
      "Epoch 29 - Best Score: 0.8174\n",
      "Epoch 30 - avg_train_loss: 0.6593  avg_val_loss: 0.7599  time: 136s\n",
      "Epoch 30 - RMSE: 0.8219023028387883\n",
      "Epoch 30 - Best Score: 0.8174\n",
      "========== fold: 3 result ==========\n",
      "Score: 0.82190\n",
      "fold: 4\n",
      "Epoch 1 - avg_train_loss: 0.9768  avg_val_loss: 0.9950  time: 137s\n",
      "Epoch 1 - RMSE: 0.9701880786413118\n",
      "Epoch 1 - Best Score: 0.9702\n",
      "Epoch 2 - avg_train_loss: 0.8593  avg_val_loss: 0.9146  time: 137s\n",
      "Epoch 2 - RMSE: 0.9262826273691208\n",
      "Epoch 2 - Best Score: 0.9263\n",
      "Epoch 3 - avg_train_loss: 0.8495  avg_val_loss: 0.9033  time: 137s\n",
      "Epoch 3 - RMSE: 0.9233735919410802\n",
      "Epoch 3 - Best Score: 0.9234\n",
      "Epoch 4 - avg_train_loss: 0.8385  avg_val_loss: 0.8938  time: 137s\n",
      "Epoch 4 - RMSE: 0.9007548311420865\n",
      "Epoch 4 - Best Score: 0.9008\n",
      "Epoch 5 - avg_train_loss: 0.8223  avg_val_loss: 0.8347  time: 137s\n",
      "Epoch 5 - RMSE: 0.8812294902073368\n",
      "Epoch 5 - Best Score: 0.8812\n",
      "Epoch 6 - avg_train_loss: 0.7937  avg_val_loss: 0.8725  time: 137s\n",
      "Epoch 6 - RMSE: 0.9043337333400616\n",
      "Epoch 6 - Best Score: 0.8812\n",
      "Epoch 7 - avg_train_loss: 0.8123  avg_val_loss: 0.9443  time: 137s\n",
      "Epoch 7 - RMSE: 0.9206061813455487\n",
      "Epoch 7 - Best Score: 0.8812\n",
      "Epoch 8 - avg_train_loss: 0.8010  avg_val_loss: 0.9457  time: 137s\n",
      "Epoch 8 - RMSE: 0.9406569739390459\n",
      "Epoch 8 - Best Score: 0.8812\n",
      "Epoch 9 - avg_train_loss: 0.7807  avg_val_loss: 0.8730  time: 137s\n",
      "Epoch 9 - RMSE: 0.8883498698021348\n",
      "Epoch 9 - Best Score: 0.8812\n",
      "Epoch 10 - avg_train_loss: 0.7720  avg_val_loss: 1.0051  time: 137s\n",
      "Epoch 10 - RMSE: 0.9616910371604178\n",
      "Epoch 10 - Best Score: 0.8812\n",
      "Epoch 11 - avg_train_loss: 0.7619  avg_val_loss: 0.8062  time: 136s\n",
      "Epoch 11 - RMSE: 0.8664651045530252\n",
      "Epoch 11 - Best Score: 0.8665\n",
      "Epoch 12 - avg_train_loss: 0.7560  avg_val_loss: 0.8142  time: 136s\n",
      "Epoch 12 - RMSE: 0.8596001410955909\n",
      "Epoch 12 - Best Score: 0.8596\n",
      "Epoch 13 - avg_train_loss: 0.7538  avg_val_loss: 0.7961  time: 136s\n",
      "Epoch 13 - RMSE: 0.8521240481013374\n",
      "Epoch 13 - Best Score: 0.8521\n",
      "Epoch 14 - avg_train_loss: 0.7516  avg_val_loss: 0.8116  time: 136s\n",
      "Epoch 14 - RMSE: 0.8546915204181128\n",
      "Epoch 14 - Best Score: 0.8521\n",
      "Epoch 15 - avg_train_loss: 0.7333  avg_val_loss: 0.7821  time: 136s\n",
      "Epoch 15 - RMSE: 0.8445348348315337\n",
      "Epoch 15 - Best Score: 0.8445\n",
      "Epoch 16 - avg_train_loss: 0.7302  avg_val_loss: 0.7921  time: 136s\n",
      "Epoch 16 - RMSE: 0.8504183373469812\n",
      "Epoch 16 - Best Score: 0.8445\n",
      "Epoch 17 - avg_train_loss: 0.7171  avg_val_loss: 0.8175  time: 137s\n",
      "Epoch 17 - RMSE: 0.8679251706335082\n",
      "Epoch 17 - Best Score: 0.8445\n",
      "Epoch 18 - avg_train_loss: 0.7161  avg_val_loss: 0.8018  time: 137s\n",
      "Epoch 18 - RMSE: 0.8523164111721112\n",
      "Epoch 18 - Best Score: 0.8445\n",
      "Epoch 19 - avg_train_loss: 0.7179  avg_val_loss: 0.8124  time: 137s\n",
      "Epoch 19 - RMSE: 0.8476890975183826\n",
      "Epoch 19 - Best Score: 0.8445\n",
      "Epoch 20 - avg_train_loss: 0.7023  avg_val_loss: 0.7971  time: 137s\n",
      "Epoch 20 - RMSE: 0.8504800672041836\n",
      "Epoch 20 - Best Score: 0.8445\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 21 - avg_train_loss: 0.7056  avg_val_loss: 0.8041  time: 137s\n",
      "Epoch 21 - RMSE: 0.84248455504051\n",
      "Epoch 21 - Best Score: 0.8425\n",
      "Epoch 22 - avg_train_loss: 0.6704  avg_val_loss: 0.7362  time: 137s\n",
      "Epoch 22 - RMSE: 0.8116078226311789\n",
      "Epoch 22 - Best Score: 0.8116\n",
      "Epoch 23 - avg_train_loss: 0.6585  avg_val_loss: 0.7187  time: 137s\n",
      "Epoch 23 - RMSE: 0.8006896187921562\n",
      "Epoch 23 - Best Score: 0.8007\n",
      "Epoch 24 - avg_train_loss: 0.6481  avg_val_loss: 0.7378  time: 137s\n",
      "Epoch 24 - RMSE: 0.8112195772621967\n",
      "Epoch 24 - Best Score: 0.8007\n",
      "Epoch 25 - avg_train_loss: 0.6353  avg_val_loss: 0.7334  time: 137s\n",
      "Epoch 25 - RMSE: 0.8027377094528643\n",
      "Epoch 25 - Best Score: 0.8007\n",
      "Epoch 26 - avg_train_loss: 0.6367  avg_val_loss: 0.7158  time: 136s\n",
      "Epoch 26 - RMSE: 0.793150085684448\n",
      "Epoch 26 - Best Score: 0.7932\n",
      "Epoch 27 - avg_train_loss: 0.6390  avg_val_loss: 0.7010  time: 136s\n",
      "Epoch 27 - RMSE: 0.7841954482166562\n",
      "Epoch 27 - Best Score: 0.7842\n",
      "Epoch 28 - avg_train_loss: 0.6310  avg_val_loss: 0.7306  time: 136s\n",
      "Epoch 28 - RMSE: 0.8016919491711397\n",
      "Epoch 28 - Best Score: 0.7842\n",
      "Epoch 29 - avg_train_loss: 0.6298  avg_val_loss: 0.7234  time: 137s\n",
      "Epoch 29 - RMSE: 0.7947880076034652\n",
      "Epoch 29 - Best Score: 0.7842\n",
      "Epoch 30 - avg_train_loss: 0.6243  avg_val_loss: 0.7179  time: 136s\n",
      "Epoch 30 - RMSE: 0.7913183431401244\n",
      "Epoch 30 - Best Score: 0.7842\n",
      "========== fold: 4 result ==========\n",
      "Score: 0.79132\n",
      "========== CV ==========\n",
      "Score: 0.80545\n",
      "CPU times: user 1d 11h 10min 33s, sys: 47min 42s, total: 1d 11h 58min 15s\n",
      "Wall time: 5h 42min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TrainRunner(model_config).run_cv(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ba9ba8b-317b-42a0-9a0b-c6bd8e07f462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>sorting_date</th>\n",
       "      <th>art_series_id</th>\n",
       "      <th>target</th>\n",
       "      <th>object_path</th>\n",
       "      <th>fold</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00bf812ffe8a62d45661</td>\n",
       "      <td>1720</td>\n",
       "      <td>3bfd41016d864e3fd8b5</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/00bf812ffe8a62d45661.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2.273412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0110115b8b6036d9ab3c</td>\n",
       "      <td>1741</td>\n",
       "      <td>baa4a20f0372d74dfc80</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/0110115b8b6036d9ab3c.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2.358466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01273c00c46a84c50468</td>\n",
       "      <td>1757</td>\n",
       "      <td>51024cb4c6256ccce827</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/01273c00c46a84c50468.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.522445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0160840d9a4620b08fbd</td>\n",
       "      <td>1874</td>\n",
       "      <td>a56504999a8157a25d16</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/0160840d9a4620b08fbd.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2.554238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0169c493b09c8758a1b3</td>\n",
       "      <td>1734</td>\n",
       "      <td>550c62dd363fea62581c</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/0169c493b09c8758a1b3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.604211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>fe4d591332b08ab81361</td>\n",
       "      <td>1600</td>\n",
       "      <td>0782dfafa355acaf888c</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/photos/fe4d591332b08ab81361.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.198530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>fecae40c488e4c8c5ba5</td>\n",
       "      <td>1600</td>\n",
       "      <td>9ac00be75c55b1653a94</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/photos/fecae40c488e4c8c5ba5.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.544810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>ff37540e22e1ef455368</td>\n",
       "      <td>1765</td>\n",
       "      <td>9971eebf0f583a5e51da</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/ff37540e22e1ef455368.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2.417129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>ff9124278e0f7086738f</td>\n",
       "      <td>1630</td>\n",
       "      <td>b4d508f53d16f7bcaf55</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/photos/ff9124278e0f7086738f.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2.339016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>ffd794b7b311b7b7fd92</td>\n",
       "      <td>1789</td>\n",
       "      <td>f030a01b480b18a27be2</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/ffd794b7b311b7b7fd92.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.943572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3937 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                object_id  sorting_date         art_series_id  target  \\\n",
       "0    00bf812ffe8a62d45661          1720  3bfd41016d864e3fd8b5       2   \n",
       "1    0110115b8b6036d9ab3c          1741  baa4a20f0372d74dfc80       2   \n",
       "2    01273c00c46a84c50468          1757  51024cb4c6256ccce827       2   \n",
       "3    0160840d9a4620b08fbd          1874  a56504999a8157a25d16       3   \n",
       "4    0169c493b09c8758a1b3          1734  550c62dd363fea62581c       2   \n",
       "..                    ...           ...                   ...     ...   \n",
       "782  fe4d591332b08ab81361          1600  0782dfafa355acaf888c       0   \n",
       "783  fecae40c488e4c8c5ba5          1600  9ac00be75c55b1653a94       0   \n",
       "784  ff37540e22e1ef455368          1765  9971eebf0f583a5e51da       2   \n",
       "785  ff9124278e0f7086738f          1630  b4d508f53d16f7bcaf55       1   \n",
       "786  ffd794b7b311b7b7fd92          1789  f030a01b480b18a27be2       2   \n",
       "\n",
       "                                  object_path  fold     preds  \n",
       "0    ../input/photos/00bf812ffe8a62d45661.jpg     0  2.273412  \n",
       "1    ../input/photos/0110115b8b6036d9ab3c.jpg     0  2.358466  \n",
       "2    ../input/photos/01273c00c46a84c50468.jpg     0  1.522445  \n",
       "3    ../input/photos/0160840d9a4620b08fbd.jpg     0  2.554238  \n",
       "4    ../input/photos/0169c493b09c8758a1b3.jpg     0  1.604211  \n",
       "..                                        ...   ...       ...  \n",
       "782  ../input/photos/fe4d591332b08ab81361.jpg     4  1.198530  \n",
       "783  ../input/photos/fecae40c488e4c8c5ba5.jpg     4  1.544810  \n",
       "784  ../input/photos/ff37540e22e1ef455368.jpg     4  2.417129  \n",
       "785  ../input/photos/ff9124278e0f7086738f.jpg     4  2.339016  \n",
       "786  ../input/photos/ffd794b7b311b7b7fd92.jpg     4  1.943572  \n",
       "\n",
       "[3937 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oof_df = Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")\n",
    "# print(\"========== CV ==========\")\n",
    "# TrainRunner(model_config)._evaluate(oof_df[\"target\"], oof_df[\"preds\"])\n",
    "\n",
    "Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72e174df-3c50-4bae-a0be-dc59445ea40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")[\"preds\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e2e35b9-f7b8-4ea9-96e4-6053d8dc537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "fold: 1\n",
      "fold: 2\n",
      "fold: 3\n",
      "fold: 4\n",
      "submission.csv created\n"
     ]
    }
   ],
   "source": [
    "test = load_csv(input_path.test)\n",
    "test = test.assign(object_path = test[\"object_id\"].apply(lambda x: to_img_path(input_path.photos_prefix, x)))\n",
    "InferenceRunner(model_config).run_cv(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa73ab9-d584-426e-9bac-a21e3b86a54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

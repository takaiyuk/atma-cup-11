{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a9074a-5044-4ae5-a622-79637a6e0c68",
   "metadata": {},
   "source": [
    "File Changed\n",
    "- base version: exp005\n",
    "- more augmentations and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08317bb-fa4d-45c8-9729-46910b084d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce6b088f-2dd0-471b-8d65-5474a0047688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InputPath:\n",
    "    _prefix: str = \"../input\"\n",
    "    train: str = f\"{_prefix}/train.csv\"\n",
    "    materials: str = f\"{_prefix}/materials.csv\"\n",
    "    techniques: str = f\"{_prefix}/techniques.csv\"\n",
    "    test: str = f\"{_prefix}/test.csv\"\n",
    "    sub: str = f\"{_prefix}/atmaCup#11_sample_submission.csv\"\n",
    "    photos_prefix: str = f\"{_prefix}/photos\"\n",
    "    photos: List[str] = field(default_factory=lambda: glob(f\"../input/photos/*.jpg\"))\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class OutputPath:\n",
    "    _prefix: str = \"../output/\"\n",
    "    model: str = f\"{_prefix}/model\"\n",
    "    submission: str = f\"{_prefix}/submission\"\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Basic:\n",
    "    run_name: str = \"exp008\"\n",
    "    is_debug: bool = False\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Kfold:\n",
    "    number: int = 5\n",
    "    method: str = \"skf\"\n",
    "    shuffle: bool = True\n",
    "    columns: List[str] = field(default_factory=lambda: [\"target\"])\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Adam:\n",
    "    name: str = \"Adam\"\n",
    "    lr: float = 1e-4\n",
    "    weight_decay: float = 0\n",
    "    amsgrad: bool = False\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class ReduceLROnPlateau:\n",
    "    name: str = \"ReduceLROnPlateau\"\n",
    "    mode: str = \"min\"\n",
    "    factor: float = 0.1\n",
    "    patience: int = 5\n",
    "    verbose: bool = True\n",
    "    eps: float = 1e-8\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Params:\n",
    "    batch_size: int = 256\n",
    "#     ssl_batch_size: int =128\n",
    "    test_batch_size: int = 1024\n",
    "    epochs: int = 3 if Basic.is_debug else 10\n",
    "    image_size: int = 224\n",
    "#     max_grad_norm: int = 1000\n",
    "    num_workers: int = 0\n",
    "#     print_freq: int = 10000\n",
    "    target_size: int = 1\n",
    "    # Union[Adam]\n",
    "    optimizer: Adam = Adam()\n",
    "    # Union[CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau]\n",
    "    scheduler: ReduceLROnPlateau = ReduceLROnPlateau()\n",
    "    pretrained: bool = False\n",
    "    num_aug: int = 10\n",
    "    num_tta: int = 10\n",
    "#     is_use_simsiam: bool = False\n",
    "        \n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    basic: Basic = Basic()\n",
    "    kfold: Kfold = Kfold()\n",
    "    params: Params = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72fec5d5-f634-46bc-9cb6-437c0f3b4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in os.listdir(OutputPath.model) if x.startswith(\"exp???_\"):\n",
    "#     os.remove(f\"{OutputPath.model}/{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e688a697-6d8e-40a5-89a3-56833b01cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_sessions = [x.split(\"_\")[0] for x in os.listdir(OutputPath.model) if x.endswith(\"_0.pth\")]\n",
    "assert Basic.run_name not in past_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b0b95d9-6d21-48a4-8ef9-d085e183e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class Jbl:\n",
    "    @staticmethod\n",
    "    def load(filepath: str) -> Any:\n",
    "        return joblib.load(filepath)\n",
    "\n",
    "    @staticmethod\n",
    "    def save(obj_: Any, filepath: str) -> None:\n",
    "        joblib.dump(obj_, filepath, compress=3)\n",
    "\n",
    "\n",
    "def RMSE(y: np.array, p: np.array) -> float:\n",
    "    return metrics.mean_squared_error(y, p) ** 0.5\n",
    "\n",
    "\n",
    "def fix_seed(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    \n",
    "def time_since(since: time.time, percent: float) -> str:\n",
    "    def as_minutes(s):\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return \"%dm %ds\" % (m, s)\n",
    "\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adac7d51-f744-4349-a639-7a6661370d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def to_img_path(photo_dir: str, object_id: str) -> str:\n",
    "    return os.path.join(photo_dir, f'{object_id}.jpg')\n",
    "\n",
    "def read_image(object_id: str):\n",
    "    return Image.open(to_img_path(object_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52cc936d-6003-4e02-ba1f-d42cf039cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_csv(path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "169f341c-c861-4c5d-918c-201017c494da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    GroupKFold,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    TimeSeriesSplit,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_kf(cfg: ModelConfig) -> Generator:\n",
    "    if cfg.kfold.method == \"kf\":\n",
    "        kf = KFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"skf\":\n",
    "        kf = StratifiedKFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"gkf\":\n",
    "        kf = GroupKFold(n_splits=cfg.kfold.number)\n",
    "    elif cfg.kfold.method == \"sgkf\":\n",
    "        kf = StratifiedGroupKFold(\n",
    "            n_splits=cfg.kfold.number, random_state=cfg.basic.seed\n",
    "        )\n",
    "    elif cfg.kfold.method == \"tskf\":\n",
    "        kf = TimeSeriesSplit(n_splits=cfg.kfold.number)\n",
    "    else:\n",
    "        raise ValueError(f\"{cfg.kfold.method} is not supported\")\n",
    "    return kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e1e049a-17be-4901-a59d-8d475c180753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "\n",
    "\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "class AtmaDataset(data.Dataset):\n",
    "    \"\"\"atmaCup用にデータ読み込み等を行なうデータ・セット\"\"\"\n",
    "    object_path_key = \"object_path\"\n",
    "    label_key = \"target\"\n",
    "\n",
    "    def __init__(self, meta_df: pd.DataFrame, is_train: bool = True) -> None:\n",
    "        self.is_train = is_train\n",
    "        self.meta_df = meta_df.reset_index(drop=True)\n",
    "        self.index_to_data = self.meta_df.to_dict(orient=\"index\")\n",
    "        \n",
    "        size = (ModelConfig.params.image_size, ModelConfig.params.image_size)\n",
    "        additional_items = (\n",
    "            [T.Resize(size)]\n",
    "            if not is_train\n",
    "            else [\n",
    "                T.RandomGrayscale(p=0.2),\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.ColorJitter(\n",
    "                    brightness=0.3,\n",
    "                    contrast=0.5,\n",
    "                    saturation=[0.8, 1.3],\n",
    "                    hue=[-0.05, 0.05],\n",
    "                ),\n",
    "                T.RandomResizedCrop(size),\n",
    "            ]\n",
    "        )\n",
    "        self.transformer = T.Compose(\n",
    "            [*additional_items, T.ToTensor(), T.Normalize(mean=IMG_MEAN, std=IMG_STD)]\n",
    "        )\n",
    "        \n",
    "        self._validate_meta_df(meta_df)\n",
    "\n",
    "    def __getitem__(self, index) -> Dict[str, Any]:\n",
    "        data = self.index_to_data[index]\n",
    "        obj_path, label = data.get(self.object_path_key), data.get(self.label_key, -1)\n",
    "        img = self.transformer(Image.open(obj_path))\n",
    "        return {\"image\": img, \"label\": label}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.meta_df)\n",
    "    \n",
    "    def _validate_meta_df(self, meta_df: pd.DataFrame) -> None:\n",
    "        for k in self.meta_keys:\n",
    "            if k not in meta_df:\n",
    "                raise ValueError(f\"meta df must have {k}\")\n",
    "                \n",
    "    @property\n",
    "    def meta_keys(self) -> List[str]:\n",
    "        retval = [self.object_path_key]\n",
    "        if self.is_train:\n",
    "            retval += [self.label_key]\n",
    "        return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb29cd98-7770-4f3e-813f-461679503034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from logging import Logger\n",
    "from typing import Dict, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "def build_model(model_config: ModelConfig, fold: int):\n",
    "    model = models.resnet34(pretrained=model_config.params.pretrained)\n",
    "    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)\n",
    "    model_state = torch.load(f\"{OutputPath.model}/exp005_{fold}.pth\")[\"model\"]\n",
    "    model.load_state_dict(model_state)\n",
    "    return model\n",
    "\n",
    "\n",
    "class BaseRunner:\n",
    "    def __init__(self, cfg: ModelConfig):\n",
    "        self.cfg = cfg\n",
    "        self.params = cfg.params\n",
    "\n",
    "    def _get_scheduler(\n",
    "        self, optimizer: Union[optim.Adam]\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if self.params.scheduler.name == \"ReduceLROnPlateau\":\n",
    "            scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode=self.params.scheduler.mode,\n",
    "                factor=self.params.scheduler.factor,\n",
    "                patience=self.params.scheduler.patience,\n",
    "                verbose=self.params.scheduler.verbose,\n",
    "                eps=self.params.scheduler.eps,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.scheduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _step_scheduler(\n",
    "        self,\n",
    "        scheduler: Union[\n",
    "            lr_scheduler.ReduceLROnPlateau,\n",
    "        ],\n",
    "        avg_val_loss,\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.shceduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _evaluate(self, y_true: np.array, y_pred: np.array):\n",
    "        score = RMSE(y_true, y_pred)\n",
    "        print(f\"Score: {score:<.5f}\")\n",
    "\n",
    "\n",
    "class TrainRunner(BaseRunner):\n",
    "    def _train_batch(self, train_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "        losses = AverageMeter()\n",
    "        model.train()\n",
    "        for _ in range(self.cfg.params.num_aug):\n",
    "            for step, image_label_dict in enumerate(train_loader):\n",
    "                images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "                labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "                batch_size = labels.size(0)\n",
    "\n",
    "                y_preds = model(images)\n",
    "                loss = criterion(y_preds.squeeze(), labels.float())\n",
    "                losses.update(loss.item(), batch_size)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        return losses.avg\n",
    "\n",
    "    def _valid_batch(self, valid_loader, model, criterion):\n",
    "        losses = AverageMeter()\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for _, image_label_dict in enumerate(valid_loader):\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            loss = criterion(y_preds.squeeze(), labels.float())\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "        predictions = np.concatenate(preds)\n",
    "        return losses.avg, predictions\n",
    "\n",
    "    def _train(self, train: pd.DataFrame, n_fold: int) -> pd.DataFrame:\n",
    "        print(f\"fold: {n_fold}\")\n",
    "        \n",
    "        is_tta_mode = self.params.num_tta > 0\n",
    "        num_times_tta = 1 if not is_tta_mode else self.params.num_tta\n",
    "\n",
    "        trn_idx = train[train[\"fold\"] != n_fold].index\n",
    "        val_idx = train[train[\"fold\"] == n_fold].index\n",
    "        train_folds = train.loc[trn_idx].reset_index(drop=True)\n",
    "        valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "        train_dataset = AtmaDataset(\n",
    "            train_folds,\n",
    "            is_train=True,\n",
    "#             transform=get_transforms(self.params, data=\"train\"),\n",
    "        )\n",
    "        valid_dataset = AtmaDataset(\n",
    "            valid_folds,\n",
    "            is_train=is_tta_mode,\n",
    "#             transform=get_transforms(self.params, data=\"valid\"),\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        model = build_model(model_config=self.cfg, fold=n_fold)\n",
    "        model.to(self.cfg.basic.device)\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=self.params.optimizer.lr,\n",
    "            weight_decay=self.params.optimizer.weight_decay,\n",
    "            amsgrad=self.params.optimizer.amsgrad,\n",
    "        )\n",
    "        scheduler = self._get_scheduler(optimizer)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        best_model = None\n",
    "        best_score = np.inf\n",
    "        scores: List[float] = []\n",
    "        for epoch in range(self.params.epochs):\n",
    "            start_time = time.time()\n",
    "\n",
    "            avg_loss = self._train_batch(\n",
    "                train_loader, model, criterion, optimizer, scheduler, epoch\n",
    "            )\n",
    "            avg_val_loss_list: List[float] = []\n",
    "            preds_list: List[np.array] = []\n",
    "            for _ in range(num_times_tta):\n",
    "                avg_val_loss, preds = self._valid_batch(valid_loader, model, criterion)\n",
    "                avg_val_loss_list.append(avg_val_loss)\n",
    "                preds_list.append(preds)\n",
    "            avg_val_loss = np.mean(avg_val_loss_list)\n",
    "            preds = np.concatenate(preds_list, axis=1).mean(axis=1)\n",
    "            valid_labels = valid_folds[\"target\"].values\n",
    "            scheduler = self._step_scheduler(scheduler, avg_val_loss)\n",
    "            score = RMSE(valid_labels, preds)\n",
    "\n",
    "            scores.append(score)\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "            )\n",
    "            print(f\"Epoch {epoch+1} - RMSE: {score}\")\n",
    "            if best_score > score:\n",
    "                best_model = model\n",
    "                best_score = score\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - Best Score: {best_score:.4f}\"\n",
    "            )\n",
    "\n",
    "        torch.save(\n",
    "            {\"model\": best_model.state_dict(), \"preds\": preds, \"best_score\": best_score, \"scores\": scores},\n",
    "            f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\",\n",
    "        )\n",
    "        check_point: Dict[str, Union[OrderedDict, torch.Tensor]] = torch.load(\n",
    "            f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\"\n",
    "        )\n",
    "        valid_folds[\"preds\"] = check_point[\"preds\"]\n",
    "        return valid_folds\n",
    "\n",
    "    def run_cv(self, train: pd.DataFrame) -> None:\n",
    "        print(f\"debug mode: {self.cfg.basic.is_debug}\")\n",
    "        print(f\"start time: {datetime.datetime.now()}\")\n",
    "        oof_df = pd.DataFrame()\n",
    "        for n_fold in range(self.cfg.kfold.number):\n",
    "            _oof_df = self._train(train, n_fold)\n",
    "            print(f\"========== fold: {n_fold} result ==========\")\n",
    "            self._evaluate(_oof_df[\"target\"], _oof_df[\"preds\"])\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "        print(\"========== CV ==========\")\n",
    "        self._evaluate(oof_df[\"target\"], oof_df[\"preds\"])\n",
    "        Jbl.save(oof_df, f\"{OutputPath.model}/oof_df_{self.cfg.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9c6ec55-378b-402c-8f5b-00172c78fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceRunner(BaseRunner):\n",
    "    def _test_batch(self, test_loader, model):\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for step, image_label_dict in enumerate(test_loader):\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "        predictions = np.concatenate(preds)\n",
    "        return predictions\n",
    "\n",
    "    def _test(self, test: pd.DataFrame, n_fold: int):\n",
    "        print(f\"fold: {n_fold}\")\n",
    "        test_dataset = AtmaDataset(\n",
    "            test,\n",
    "            is_train=False,\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.params.test_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        model = build_model(model_config=self.cfg, fold=n_fold)\n",
    "        model_state = torch.load(f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\")[\"model\"]\n",
    "        model.load_state_dict(model_state)\n",
    "        model.to(self.cfg.basic.device)\n",
    "        preds = self._test_batch(test_loader, model)\n",
    "        return preds\n",
    "    \n",
    "    def _submit(self, preds: np.array) -> None:\n",
    "        df_sub = load_csv(input_path.sub)\n",
    "        df_sub = df_sub.assign(target=np.clip(preds, 0, 3))\n",
    "        path = f\"{OutputPath.submission}/submission_{self.cfg.basic.run_name}.csv\"\n",
    "        df_sub.to_csv(path, index=False)\n",
    "        print(\"submission.csv created\")\n",
    "\n",
    "    def run_cv(self, test: pd.DataFrame) -> None:\n",
    "        oof_df = pd.DataFrame()\n",
    "        preds: List[np.array] = []\n",
    "        for n_fold in range(self.cfg.kfold.number):\n",
    "            preds_fold = self._test(test, n_fold)\n",
    "            preds.append(preds_fold)\n",
    "        Jbl.save(preds, f\"{OutputPath.model}/preds_test_{self.cfg.basic.run_name}.jbl\")\n",
    "        \n",
    "        preds_mean = np.concatenate(preds, axis=1).mean(axis=1)\n",
    "        self._submit(preds_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae1cb89-4ee0-4293-b935-888a14f628da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed()\n",
    "input_path = InputPath()\n",
    "model_config = ModelConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c99fafc2-2ace-488f-b2a3-1f6f3297af69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3937, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>sorting_date</th>\n",
       "      <th>art_series_id</th>\n",
       "      <th>target</th>\n",
       "      <th>object_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002bff09b09998d0be65</td>\n",
       "      <td>1631</td>\n",
       "      <td>509357f67692a6a45626</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/photos/002bff09b09998d0be65.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00309fb1ef05416f9c1f</td>\n",
       "      <td>1900</td>\n",
       "      <td>7987b47bbe5dc3039179</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/00309fb1ef05416f9c1f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003a1562e97f79ba96dc</td>\n",
       "      <td>1834</td>\n",
       "      <td>ded7c3c9636708e5b14c</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/003a1562e97f79ba96dc.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              object_id  sorting_date         art_series_id  target  \\\n",
       "0  002bff09b09998d0be65          1631  509357f67692a6a45626       1   \n",
       "1  00309fb1ef05416f9c1f          1900  7987b47bbe5dc3039179       3   \n",
       "2  003a1562e97f79ba96dc          1834  ded7c3c9636708e5b14c       3   \n",
       "\n",
       "                                object_path  \n",
       "0  ../input/photos/002bff09b09998d0be65.jpg  \n",
       "1  ../input/photos/00309fb1ef05416f9c1f.jpg  \n",
       "2  ../input/photos/003a1562e97f79ba96dc.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = load_csv(input_path.train)\n",
    "train = train.assign(object_path = train[\"object_id\"].apply(lambda x: to_img_path(input_path.photos_prefix, x)))\n",
    "print(train.shape)\n",
    "display(train.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8796a89d-9fce-49b6-8d53-3c315b65722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 - [0 1 2 3 4]~[3928 3930 3933 3934 3935]\t[ 8 14 16 19 21]~[3922 3929 3931 3932 3936]\n",
      "fold: 1 - [0 1 2 4 5]~[3931 3932 3933 3934 3936]\t[ 3  9 20 23 24]~[3899 3907 3912 3925 3935]\n",
      "fold: 2 - [0 1 2 3 5]~[3931 3932 3934 3935 3936]\t[ 4  6 10 11 12]~[3913 3915 3924 3927 3933]\n",
      "fold: 3 - [2 3 4 5 6]~[3932 3933 3934 3935 3936]\t[ 0  1  7 17 29]~[3914 3916 3919 3923 3926]\n",
      "fold: 4 - [0 1 3 4 6]~[3931 3932 3933 3935 3936]\t[ 2  5 22 31 32]~[3909 3918 3928 3930 3934]\n"
     ]
    }
   ],
   "source": [
    "kf = generate_kf(model_config)\n",
    "if model_config.kfold.method.endswith(\"gkf\"):\n",
    "    kf_generator = kf.split(\n",
    "        train,\n",
    "        train[self.fe_cfg.column.target],\n",
    "        groups=train[self.kfold.columns],\n",
    "    )\n",
    "else:\n",
    "    kf_generator = kf.split(train, train[\"target\"])\n",
    "for fold_i, (tr_idx, val_idx) in enumerate(kf_generator):\n",
    "    print(\n",
    "        f\"fold: {fold_i} - {tr_idx[:5]}~{tr_idx[-5:]}\\t{val_idx[:5]}~{val_idx[-5:]}\"\n",
    "    )\n",
    "    train.loc[val_idx, \"fold\"] = fold_i\n",
    "train = train.assign(fold = train[\"fold\"].astype(int))\n",
    "# if model_config.kfold.method == \"skf\":\n",
    "#     display(train.groupby([\"fold\", \"target\"]).size().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b4ff32c-e413-4148-88d6-a69f99c135c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug mode: False\n",
      "start time: 2021-07-22 11:32:45.413824\n",
      "fold: 0\n",
      "Epoch 1 - avg_train_loss: 0.6771  avg_val_loss: 0.8515  time: 233s\n",
      "Epoch 1 - RMSE: 0.8802213064353289\n",
      "Epoch 1 - Best Score: 0.8802\n",
      "Epoch 2 - avg_train_loss: 0.6614  avg_val_loss: 0.7941  time: 232s\n",
      "Epoch 2 - RMSE: 0.8484408435316759\n",
      "Epoch 2 - Best Score: 0.8484\n",
      "Epoch 3 - avg_train_loss: 0.6439  avg_val_loss: 0.7917  time: 233s\n",
      "Epoch 3 - RMSE: 0.8364625910156359\n",
      "Epoch 3 - Best Score: 0.8365\n",
      "Epoch 4 - avg_train_loss: 0.6296  avg_val_loss: 0.7811  time: 233s\n",
      "Epoch 4 - RMSE: 0.8199010464637821\n",
      "Epoch 4 - Best Score: 0.8199\n",
      "Epoch 5 - avg_train_loss: 0.6215  avg_val_loss: 0.7685  time: 233s\n",
      "Epoch 5 - RMSE: 0.8325459854248077\n",
      "Epoch 5 - Best Score: 0.8199\n",
      "Epoch 6 - avg_train_loss: 0.6091  avg_val_loss: 0.7453  time: 232s\n",
      "Epoch 6 - RMSE: 0.8065422947131118\n",
      "Epoch 6 - Best Score: 0.8065\n",
      "Epoch 7 - avg_train_loss: 0.5870  avg_val_loss: 0.7546  time: 233s\n",
      "Epoch 7 - RMSE: 0.7975022951310106\n",
      "Epoch 7 - Best Score: 0.7975\n",
      "Epoch 8 - avg_train_loss: 0.5779  avg_val_loss: 0.7968  time: 233s\n",
      "Epoch 8 - RMSE: 0.8243288092615082\n",
      "Epoch 8 - Best Score: 0.7975\n",
      "Epoch 9 - avg_train_loss: 0.5650  avg_val_loss: 0.7334  time: 233s\n",
      "Epoch 9 - RMSE: 0.7908254211621809\n",
      "Epoch 9 - Best Score: 0.7908\n",
      "Epoch 10 - avg_train_loss: 0.5522  avg_val_loss: 0.7533  time: 233s\n",
      "Epoch 10 - RMSE: 0.8039497359819263\n",
      "Epoch 10 - Best Score: 0.7908\n",
      "========== fold: 0 result ==========\n",
      "Score: 0.80395\n",
      "fold: 1\n",
      "Epoch 1 - avg_train_loss: 0.5969  avg_val_loss: 0.7568  time: 234s\n",
      "Epoch 1 - RMSE: 0.8036153506193943\n",
      "Epoch 1 - Best Score: 0.8036\n",
      "Epoch 2 - avg_train_loss: 0.5755  avg_val_loss: 0.7674  time: 233s\n",
      "Epoch 2 - RMSE: 0.8041352887587212\n",
      "Epoch 2 - Best Score: 0.8036\n",
      "Epoch 3 - avg_train_loss: 0.5620  avg_val_loss: 0.7683  time: 233s\n",
      "Epoch 3 - RMSE: 0.8074315306146584\n",
      "Epoch 3 - Best Score: 0.8036\n",
      "Epoch 4 - avg_train_loss: 0.5387  avg_val_loss: 0.8655  time: 233s\n",
      "Epoch 4 - RMSE: 0.8573198642152906\n",
      "Epoch 4 - Best Score: 0.8036\n",
      "Epoch 5 - avg_train_loss: 0.5295  avg_val_loss: 0.8281  time: 232s\n",
      "Epoch 5 - RMSE: 0.8294368553599363\n",
      "Epoch 5 - Best Score: 0.8036\n",
      "Epoch 6 - avg_train_loss: 0.5153  avg_val_loss: 0.8226  time: 234s\n",
      "Epoch 6 - RMSE: 0.8387315924391604\n",
      "Epoch 6 - Best Score: 0.8036\n",
      "Epoch 7 - avg_train_loss: 0.5032  avg_val_loss: 0.7526  time: 233s\n",
      "Epoch 7 - RMSE: 0.7980322501511526\n",
      "Epoch 7 - Best Score: 0.7980\n",
      "Epoch 8 - avg_train_loss: 0.4829  avg_val_loss: 0.7740  time: 233s\n",
      "Epoch 8 - RMSE: 0.8118448775776262\n",
      "Epoch 8 - Best Score: 0.7980\n",
      "Epoch 9 - avg_train_loss: 0.4793  avg_val_loss: 0.8358  time: 232s\n",
      "Epoch 9 - RMSE: 0.8300600397397537\n",
      "Epoch 9 - Best Score: 0.7980\n",
      "Epoch 10 - avg_train_loss: 0.4596  avg_val_loss: 0.7779  time: 233s\n",
      "Epoch 10 - RMSE: 0.808020567076278\n",
      "Epoch 10 - Best Score: 0.7980\n",
      "========== fold: 1 result ==========\n",
      "Score: 0.80802\n",
      "fold: 2\n",
      "Epoch 1 - avg_train_loss: 0.6003  avg_val_loss: 0.7618  time: 233s\n",
      "Epoch 1 - RMSE: 0.8116602585687234\n",
      "Epoch 1 - Best Score: 0.8117\n",
      "Epoch 2 - avg_train_loss: 0.5808  avg_val_loss: 0.8148  time: 233s\n",
      "Epoch 2 - RMSE: 0.8504975194999146\n",
      "Epoch 2 - Best Score: 0.8117\n",
      "Epoch 3 - avg_train_loss: 0.5678  avg_val_loss: 0.7740  time: 233s\n",
      "Epoch 3 - RMSE: 0.8228385241317023\n",
      "Epoch 3 - Best Score: 0.8117\n",
      "Epoch 4 - avg_train_loss: 0.5493  avg_val_loss: 0.7370  time: 233s\n",
      "Epoch 4 - RMSE: 0.7893217929686407\n",
      "Epoch 4 - Best Score: 0.7893\n",
      "Epoch 5 - avg_train_loss: 0.5357  avg_val_loss: 0.7600  time: 234s\n",
      "Epoch 5 - RMSE: 0.8010846652906718\n",
      "Epoch 5 - Best Score: 0.7893\n",
      "Epoch 6 - avg_train_loss: 0.5331  avg_val_loss: 0.7302  time: 234s\n",
      "Epoch 6 - RMSE: 0.7912953182073365\n",
      "Epoch 6 - Best Score: 0.7893\n",
      "Epoch 7 - avg_train_loss: 0.5219  avg_val_loss: 0.7428  time: 233s\n",
      "Epoch 7 - RMSE: 0.7954528051408548\n",
      "Epoch 7 - Best Score: 0.7893\n",
      "Epoch 8 - avg_train_loss: 0.5106  avg_val_loss: 0.7508  time: 233s\n",
      "Epoch 8 - RMSE: 0.8088517091380536\n",
      "Epoch 8 - Best Score: 0.7893\n",
      "Epoch 9 - avg_train_loss: 0.4958  avg_val_loss: 0.8075  time: 233s\n",
      "Epoch 9 - RMSE: 0.8177272357701733\n",
      "Epoch 9 - Best Score: 0.7893\n",
      "Epoch 10 - avg_train_loss: 0.4797  avg_val_loss: 0.7936  time: 233s\n",
      "Epoch 10 - RMSE: 0.813561524649611\n",
      "Epoch 10 - Best Score: 0.7893\n",
      "========== fold: 2 result ==========\n",
      "Score: 0.81356\n",
      "fold: 3\n",
      "Epoch 1 - avg_train_loss: 0.5844  avg_val_loss: 0.7384  time: 232s\n",
      "Epoch 1 - RMSE: 0.7991586580997804\n",
      "Epoch 1 - Best Score: 0.7992\n",
      "Epoch 2 - avg_train_loss: 0.5577  avg_val_loss: 0.7296  time: 233s\n",
      "Epoch 2 - RMSE: 0.7951171039269394\n",
      "Epoch 2 - Best Score: 0.7951\n",
      "Epoch 3 - avg_train_loss: 0.5417  avg_val_loss: 0.7497  time: 233s\n",
      "Epoch 3 - RMSE: 0.8027812773012297\n",
      "Epoch 3 - Best Score: 0.7951\n",
      "Epoch 4 - avg_train_loss: 0.5311  avg_val_loss: 0.7659  time: 234s\n",
      "Epoch 4 - RMSE: 0.8007227576455209\n",
      "Epoch 4 - Best Score: 0.7951\n",
      "Epoch 5 - avg_train_loss: 0.5175  avg_val_loss: 0.7885  time: 232s\n",
      "Epoch 5 - RMSE: 0.8087313706156718\n",
      "Epoch 5 - Best Score: 0.7951\n",
      "Epoch 6 - avg_train_loss: 0.5159  avg_val_loss: 0.7670  time: 233s\n",
      "Epoch 6 - RMSE: 0.8143079225922677\n",
      "Epoch 6 - Best Score: 0.7951\n",
      "Epoch 7 - avg_train_loss: 0.4913  avg_val_loss: 0.7688  time: 232s\n",
      "Epoch 7 - RMSE: 0.7956457009594619\n",
      "Epoch 7 - Best Score: 0.7951\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 8 - avg_train_loss: 0.4833  avg_val_loss: 0.7560  time: 232s\n",
      "Epoch 8 - RMSE: 0.7916299706698297\n",
      "Epoch 8 - Best Score: 0.7916\n",
      "Epoch 9 - avg_train_loss: 0.4422  avg_val_loss: 0.7384  time: 233s\n",
      "Epoch 9 - RMSE: 0.7706995670537296\n",
      "Epoch 9 - Best Score: 0.7707\n",
      "Epoch 10 - avg_train_loss: 0.4286  avg_val_loss: 0.7166  time: 232s\n",
      "Epoch 10 - RMSE: 0.759436897495898\n",
      "Epoch 10 - Best Score: 0.7594\n",
      "========== fold: 3 result ==========\n",
      "Score: 0.75944\n",
      "fold: 4\n",
      "Epoch 1 - avg_train_loss: 0.6353  avg_val_loss: 0.8329  time: 233s\n",
      "Epoch 1 - RMSE: 0.8621608562531339\n",
      "Epoch 1 - Best Score: 0.8622\n",
      "Epoch 2 - avg_train_loss: 0.6087  avg_val_loss: 0.8679  time: 233s\n",
      "Epoch 2 - RMSE: 0.8711800093511622\n",
      "Epoch 2 - Best Score: 0.8622\n",
      "Epoch 3 - avg_train_loss: 0.5981  avg_val_loss: 0.7387  time: 233s\n",
      "Epoch 3 - RMSE: 0.7976067064458949\n",
      "Epoch 3 - Best Score: 0.7976\n",
      "Epoch 4 - avg_train_loss: 0.5849  avg_val_loss: 0.7381  time: 233s\n",
      "Epoch 4 - RMSE: 0.7958877576191927\n",
      "Epoch 4 - Best Score: 0.7959\n",
      "Epoch 5 - avg_train_loss: 0.5728  avg_val_loss: 0.7520  time: 233s\n",
      "Epoch 5 - RMSE: 0.8126119657063071\n",
      "Epoch 5 - Best Score: 0.7959\n",
      "Epoch 6 - avg_train_loss: 0.5611  avg_val_loss: 0.7642  time: 233s\n",
      "Epoch 6 - RMSE: 0.8047813777251367\n",
      "Epoch 6 - Best Score: 0.7959\n",
      "Epoch 7 - avg_train_loss: 0.5459  avg_val_loss: 0.7344  time: 233s\n",
      "Epoch 7 - RMSE: 0.7790348057944961\n",
      "Epoch 7 - Best Score: 0.7790\n",
      "Epoch 9 - avg_train_loss: 0.5214  avg_val_loss: 0.7693  time: 233s\n",
      "Epoch 9 - RMSE: 0.7880484556601288\n",
      "Epoch 9 - Best Score: 0.7790\n",
      "Epoch 10 - avg_train_loss: 0.5020  avg_val_loss: 0.7753  time: 233s\n",
      "Epoch 10 - RMSE: 0.8094949874172451\n",
      "Epoch 10 - Best Score: 0.7790\n",
      "========== fold: 4 result ==========\n",
      "Score: 0.80949\n",
      "========== CV ==========\n",
      "Score: 0.79915\n",
      "CPU times: user 19h 33min 34s, sys: 24min 8s, total: 19h 57min 43s\n",
      "Wall time: 3h 14min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TrainRunner(model_config).run_cv(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ba9ba8b-317b-42a0-9a0b-c6bd8e07f462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>sorting_date</th>\n",
       "      <th>art_series_id</th>\n",
       "      <th>target</th>\n",
       "      <th>object_path</th>\n",
       "      <th>fold</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00bf812ffe8a62d45661</td>\n",
       "      <td>1720</td>\n",
       "      <td>3bfd41016d864e3fd8b5</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/00bf812ffe8a62d45661.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.577693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0110115b8b6036d9ab3c</td>\n",
       "      <td>1741</td>\n",
       "      <td>baa4a20f0372d74dfc80</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/0110115b8b6036d9ab3c.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.907111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01273c00c46a84c50468</td>\n",
       "      <td>1757</td>\n",
       "      <td>51024cb4c6256ccce827</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/01273c00c46a84c50468.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.885419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0160840d9a4620b08fbd</td>\n",
       "      <td>1874</td>\n",
       "      <td>a56504999a8157a25d16</td>\n",
       "      <td>3</td>\n",
       "      <td>../input/photos/0160840d9a4620b08fbd.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2.222040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0169c493b09c8758a1b3</td>\n",
       "      <td>1734</td>\n",
       "      <td>550c62dd363fea62581c</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/0169c493b09c8758a1b3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.738003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>fe4d591332b08ab81361</td>\n",
       "      <td>1600</td>\n",
       "      <td>0782dfafa355acaf888c</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/photos/fe4d591332b08ab81361.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.468988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>fecae40c488e4c8c5ba5</td>\n",
       "      <td>1600</td>\n",
       "      <td>9ac00be75c55b1653a94</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/photos/fecae40c488e4c8c5ba5.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.917201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>ff37540e22e1ef455368</td>\n",
       "      <td>1765</td>\n",
       "      <td>9971eebf0f583a5e51da</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/ff37540e22e1ef455368.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2.214027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>ff9124278e0f7086738f</td>\n",
       "      <td>1630</td>\n",
       "      <td>b4d508f53d16f7bcaf55</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/photos/ff9124278e0f7086738f.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2.066338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>ffd794b7b311b7b7fd92</td>\n",
       "      <td>1789</td>\n",
       "      <td>f030a01b480b18a27be2</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/photos/ffd794b7b311b7b7fd92.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1.971256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3937 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                object_id  sorting_date         art_series_id  target  \\\n",
       "0    00bf812ffe8a62d45661          1720  3bfd41016d864e3fd8b5       2   \n",
       "1    0110115b8b6036d9ab3c          1741  baa4a20f0372d74dfc80       2   \n",
       "2    01273c00c46a84c50468          1757  51024cb4c6256ccce827       2   \n",
       "3    0160840d9a4620b08fbd          1874  a56504999a8157a25d16       3   \n",
       "4    0169c493b09c8758a1b3          1734  550c62dd363fea62581c       2   \n",
       "..                    ...           ...                   ...     ...   \n",
       "782  fe4d591332b08ab81361          1600  0782dfafa355acaf888c       0   \n",
       "783  fecae40c488e4c8c5ba5          1600  9ac00be75c55b1653a94       0   \n",
       "784  ff37540e22e1ef455368          1765  9971eebf0f583a5e51da       2   \n",
       "785  ff9124278e0f7086738f          1630  b4d508f53d16f7bcaf55       1   \n",
       "786  ffd794b7b311b7b7fd92          1789  f030a01b480b18a27be2       2   \n",
       "\n",
       "                                  object_path  fold     preds  \n",
       "0    ../input/photos/00bf812ffe8a62d45661.jpg     0  1.577693  \n",
       "1    ../input/photos/0110115b8b6036d9ab3c.jpg     0  1.907111  \n",
       "2    ../input/photos/01273c00c46a84c50468.jpg     0  1.885419  \n",
       "3    ../input/photos/0160840d9a4620b08fbd.jpg     0  2.222040  \n",
       "4    ../input/photos/0169c493b09c8758a1b3.jpg     0  1.738003  \n",
       "..                                        ...   ...       ...  \n",
       "782  ../input/photos/fe4d591332b08ab81361.jpg     4  1.468988  \n",
       "783  ../input/photos/fecae40c488e4c8c5ba5.jpg     4  1.917201  \n",
       "784  ../input/photos/ff37540e22e1ef455368.jpg     4  2.214027  \n",
       "785  ../input/photos/ff9124278e0f7086738f.jpg     4  2.066338  \n",
       "786  ../input/photos/ffd794b7b311b7b7fd92.jpg     4  1.971256  \n",
       "\n",
       "[3937 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oof_df = Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")\n",
    "# print(\"========== CV ==========\")\n",
    "# TrainRunner(model_config)._evaluate(oof_df[\"target\"], oof_df[\"preds\"])\n",
    "\n",
    "Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72e174df-3c50-4bae-a0be-dc59445ea40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")[\"preds\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e2e35b9-f7b8-4ea9-96e4-6053d8dc537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "fold: 1\n",
      "fold: 2\n",
      "fold: 3\n",
      "fold: 4\n",
      "submission.csv created\n"
     ]
    }
   ],
   "source": [
    "test = load_csv(input_path.test)\n",
    "test = test.assign(object_path = test[\"object_id\"].apply(lambda x: to_img_path(input_path.photos_prefix, x)))\n",
    "InferenceRunner(model_config).run_cv(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa73ab9-d584-426e-9bac-a21e3b86a54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
